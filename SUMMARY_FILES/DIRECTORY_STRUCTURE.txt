DIRECTORY STRUCTURE SUMMARY
===========================

Project Root: /home/narthana/MinimalEMbeddingDimension_of_PhoneticFeatures_01/

SOURCE CODE
===========

src/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ build_dataset_for_probe.py          - Dataset preparation from model embeddings
â”œâ”€â”€ build_probe.py                      - Legacy probe training pipeline (JSON-based)
â”œâ”€â”€ compute.py                          - Computation utilities
â”œâ”€â”€ is_subset_existence.py              - Subset validation utilities
â”œâ”€â”€ utils.py                            - General helper functions
â”œâ”€â”€ plot_evaluation_results.py          - Generate 72 plots from evaluation JSONs
â””â”€â”€ create_dashboard.py                 - Generate interactive HTML dashboard

configs/
â”œâ”€â”€ model_config.py                     - Model configuration and paths
â”œâ”€â”€ phoneme_features.py                 - Phonetic feature definitions (voiced, fricative, nasal)
â”œâ”€â”€ probe_models.py                     - Class-based probe definitions (LinearProbe, MLPProbe_1x200)
â”œâ”€â”€ probe_architectures.py              - JSON-based architecture loader (legacy)
â””â”€â”€ probe_architectures.json            - Architecture specifications (legacy)


OUTPUTS
=======

02_OUTPUTS/TIMIT_Outputs/

datasets/                               - Model layer embeddings
â”œâ”€â”€ HUBERT_BASE/
â”‚   â”œâ”€â”€ layer_00_train.pkl
â”‚   â”œâ”€â”€ layer_00_test.pkl
â”‚   â””â”€â”€ ... (up to layer_12)
â”œâ”€â”€ HUBERT_LARGE/                       (layers 0-24)
â”œâ”€â”€ WAV2VEC2_BASE/                      (layers 0-12)
â”œâ”€â”€ WAV2VEC2_LARGE/                     (layers 0-24)
â”œâ”€â”€ WAVLM_BASE/                         (layers 0-12)
â””â”€â”€ WAVLM_LARGE/                        (layers 0-24)

probes/
â”œâ”€â”€ linear/
â”‚   â”œâ”€â”€ linear_evaluation_summary.json  - 342 evaluation records (6 models Ã— layers Ã— 3 features)
â”‚   â””â”€â”€ probes/                         - Individual trained probe files
â”‚       â”œâ”€â”€ HUBERT_BASE/
â”‚       â”‚   â”œâ”€â”€ layer_00/
â”‚       â”‚   â”‚   â”œâ”€â”€ voiced.pt
â”‚       â”‚   â”‚   â”œâ”€â”€ fricative.pt
â”‚       â”‚   â”‚   â””â”€â”€ nasal.pt
â”‚       â”‚   â””â”€â”€ ... (layers 1-12)
â”‚       â””â”€â”€ ... (other models)
â”‚
â””â”€â”€ mlp_1x200/
    â”œâ”€â”€ mlp_1x200_evaluation_summary.json  - 342 evaluation records
    â””â”€â”€ probes/                            - Individual trained probe files (same structure)

plots/
â”œâ”€â”€ evaluation_dashboard.html           - â˜… INTERACTIVE DASHBOARD (Open in browser)
â”‚
â””â”€â”€ 01_Evaluation_plots/
    â”œâ”€â”€ 01_Accuracy/                    [36 PNG plots]
    â”‚   â”œâ”€â”€ linear/                     [15 plots]
    â”‚   â”‚   â”œâ”€â”€ HUBERT_BASE.png         (Variant 1: All 3 features per model)
    â”‚   â”‚   â”œâ”€â”€ HUBERT_LARGE.png
    â”‚   â”‚   â”œâ”€â”€ WAV2VEC2_BASE.png
    â”‚   â”‚   â”œâ”€â”€ WAV2VEC2_LARGE.png
    â”‚   â”‚   â”œâ”€â”€ WAVLM_BASE.png
    â”‚   â”‚   â”œâ”€â”€ WAVLM_LARGE.png
    â”‚   â”‚   â”œâ”€â”€ voiced.png              (Variant 2: All 6 models per feature)
    â”‚   â”‚   â”œâ”€â”€ fricative.png
    â”‚   â”‚   â””â”€â”€ nasal.png
    â”‚   â”‚
    â”‚   â”œâ”€â”€ mlp_1x200/                  [15 plots - same structure as linear/]
    â”‚   â”‚
    â”‚   â”œâ”€â”€ HUBERT_BASE/                [3 plots]
    â”‚   â”‚   â”œâ”€â”€ voiced.png              (Variant 3: Both architectures comparison)
    â”‚   â”‚   â”œâ”€â”€ fricative.png
    â”‚   â”‚   â””â”€â”€ nasal.png
    â”‚   â”œâ”€â”€ HUBERT_LARGE/               [3 plots]
    â”‚   â”œâ”€â”€ WAV2VEC2_BASE/              [3 plots]
    â”‚   â”œâ”€â”€ WAV2VEC2_LARGE/             [3 plots]
    â”‚   â”œâ”€â”€ WAVLM_BASE/                 [3 plots]
    â”‚   â””â”€â”€ WAVLM_LARGE/                [3 plots]
    â”‚
    â””â”€â”€ 02_F1_Score/                    [36 PNG plots - same structure as 01_Accuracy/]


SUMMARIES
=========

SUMMARY_FILES/
â”œâ”€â”€ plot_summary.txt                    - Plot generation statistics and structure
â””â”€â”€ EVALUATION_DASHBOARD_GUIDE.md       - Comprehensive dashboard usage guide


CONFIGURATION & DATA
====================

01_Raw_Phonetic_Annotated_Datasets/
â”œâ”€â”€ 01_TIMIT_raw_dataset_sample/        - Sample TIMIT files
â”œâ”€â”€ 01_TIMIT_raw_dataset_whole/         - Complete TIMIT dataset
â””â”€â”€ 02_Buckeye_raw_dataset/             - Buckeye corpus

examples/
â””â”€â”€ example_usage.py                    - Usage examples

logs/                                   - Training and execution logs
notebooks/                              - Jupyter notebooks (if any)


ROOT FILES
==========

main.py                                 - Main entry point
quick_start.py                          - Quick start script
verify_setup.py                         - Setup verification
requirements.txt                        - Python dependencies
README.md                               - Project documentation
train_class_probes.py                   - Class-based probe training script


KEY FILES TO ACCESS
===================

1. Interactive Dashboard (â˜… PRIMARY VISUALIZATION):
   /home/narthana/MinimalEMbeddingDimension_of_PhoneticFeatures_01/02_OUTPUTS/TIMIT_Outputs/plots/evaluation_dashboard.html
   
   Open in browser for interactive exploration of all 72 plots with:
   - Tab-based navigation (3 visualization variants + overview)
   - Dynamic filtering (metric, architecture, model, feature)
   - Click-to-enlarge functionality
   - Performance statistics summary

2. Evaluation Summaries (JSON):
   /home/narthana/MinimalEMbeddingDimension_of_PhoneticFeatures_01/02_OUTPUTS/TIMIT_Outputs/probes/linear/linear_evaluation_summary.json
   /home/narthana/MinimalEMbeddingDimension_of_PhoneticFeatures_01/02_OUTPUTS/TIMIT_Outputs/probes/mlp_1x200/mlp_1x200_evaluation_summary.json

3. Static Plots (PNG):
   /home/narthana/MinimalEMbeddingDimension_of_PhoneticFeatures_01/02_OUTPUTS/TIMIT_Outputs/plots/01_Evaluation_plots/
   
   Browse by metric (01_Accuracy / 02_F1_Score) and variant


QUICK ACCESS COMMANDS
======================

# Navigate to project root
cd /home/narthana/MinimalEMbeddingDimension_of_PhoneticFeatures_01

# Open dashboard in browser
firefox 02_OUTPUTS/TIMIT_Outputs/plots/evaluation_dashboard.html &
# or
google-chrome 02_OUTPUTS/TIMIT_Outputs/plots/evaluation_dashboard.html &

# Regenerate plots
./venv/bin/python src/plot_evaluation_results.py

# Regenerate dashboard
./venv/bin/python src/create_dashboard.py

# View plot directory structure
find 02_OUTPUTS/TIMIT_Outputs/plots/01_Evaluation_plots -name "*.png" | sort

# Count files
echo "Total plots: $(find 02_OUTPUTS/TIMIT_Outputs/plots/01_Evaluation_plots -name '*.png' | wc -l)"


STATISTICS
==========

Total Probes Trained:    684
  - Linear:              342 (6 models Ã— 57 layers Ã— 3 features)
  - MLP 1Ã—200:           342 (6 models Ã— 57 layers Ã— 3 features)

Total Plots Generated:   72
  - Accuracy plots:      36
  - F1 Score plots:      36

Models:                  6
  - Base models (13 layers):  HUBERT_BASE, WAV2VEC2_BASE, WAVLM_BASE
  - Large models (25 layers): HUBERT_LARGE, WAV2VEC2_LARGE, WAVLM_LARGE

Features:                3 (Voiced, Fricative, Nasal)
Architectures:           2 (Linear, MLP 1Ã—200)


NOTES
=====

- All scripts are organized in src/ directory
- All summary documentation in SUMMARY_FILES/ directory
- Dashboard provides the best interactive exploration experience
- JSON summaries contain complete metadata (hyperparameters, loss history, metrics)
- PNG plots are high-resolution (150 DPI) for publication quality


================================================================================
â˜… NEW: CENTRALIZED OUTPUT PATH CONFIGURATION â˜…
================================================================================

PROBLEM SOLVED: No more confusion about where files are saved!

All output paths are now centralized in:
  configs/output_paths.py

BENEFITS:
  âœ… Single source of truth for all file paths
  âœ… Consistent directory structure across all datasets
  âœ… Easy to switch between TIMIT, BUCKEYE, or add new datasets
  âœ… Automatic directory creation
  âœ… Type-safe Path objects (not strings)
  âœ… Discovery functions to find existing data

USAGE:
------
from configs.output_paths import (
    get_dataset_dir,          # Get dataset base directory
    get_layer_file_path,      # Get embedding file path
    get_probe_file_path,      # Get probe file path
    get_dashboard_path,       # Get dashboard path
    ensure_directory_exists   # Create directories automatically
)

# Example: Get paths for any dataset
dataset_dir = get_dataset_dir("TIMIT")
probe_path = get_probe_file_path("linear", "HUBERT_BASE", 5, "voiced", "TIMIT")
dashboard = get_dashboard_path("TIMIT")

# Switch to BUCKEYE? Just change the name!
buckeye_dir = get_dataset_dir("BUCKEYE")
buckeye_dashboard = get_dashboard_path("BUCKEYE")

DOCUMENTATION:
-------------
  ðŸ“– Full Guide:         SUMMARY_FILES/OUTPUT_PATH_GUIDE.md
  ðŸ“‹ Quick Reference:    SUMMARY_FILES/OUTPUT_PATHS_QUICK_REFERENCE.txt
  ðŸ’» Working Examples:   examples/output_paths_usage.py
  ï¿½ï¿½ Source Code:        configs/output_paths.py

TESTING:
--------
  # See the complete path structure:
  python configs/output_paths.py

  # Run usage examples:
  python examples/output_paths_usage.py

NOW YOU CAN:
-----------
  â€¢ Work with TIMIT without confusion âœ“
  â€¢ Add BUCKEYE dataset easily âœ“
  â€¢ Create new datasets with consistent structure âœ“
  â€¢ Know exactly where every file is saved âœ“
  â€¢ Never wonder "where did that file go?" âœ“


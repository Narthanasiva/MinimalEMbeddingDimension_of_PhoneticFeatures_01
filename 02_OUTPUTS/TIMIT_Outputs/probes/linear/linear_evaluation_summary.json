[
  {
    "model": "HUBERT_BASE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6814055028866413,
      0.5970058127990654,
      0.5283415590608597,
      0.4736307142674518,
      0.429958398655142,
      0.3950709717190761,
      0.36692291890256074,
      0.34393983418347235,
      0.3252056268010654,
      0.309434848753257,
      0.2960008008789841,
      0.2845349483643579,
      0.2744652270525491,
      0.26571556187803635,
      0.25782335011911767
    ],
    "metrics": {
      "accuracy": 0.8888888888888888,
      "precision": 0.9012987012987013,
      "recall": 0.910761154855643,
      "f1": 0.9060052219321149
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_00/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6532833314065085,
      0.5566306184024453,
      0.4822681308213898,
      0.4263612586102689,
      0.3844718138268863,
      0.35215675899696663,
      0.3269061016611963,
      0.30634453687761165,
      0.28932715469192116,
      0.27493331987399644,
      0.2625303225823154,
      0.25195793623621615,
      0.24251850985029075,
      0.23437461148837105,
      0.22700722584033603
    ],
    "metrics": {
      "accuracy": 0.9012345679012346,
      "precision": 0.7066666666666667,
      "recall": 0.5578947368421052,
      "f1": 0.6235294117647059
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_00/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6160407743398247,
      0.5130246859038774,
      0.43323493835782834,
      0.37243851566483194,
      0.3271787327798562,
      0.2925423274434886,
      0.2656072957801184,
      0.24398212080563692,
      0.22622246020803896,
      0.21134479890280555,
      0.19873565719742656,
      0.18770719149670675,
      0.17822950600071036,
      0.16994150528508575,
      0.16238341652430022
    ],
    "metrics": {
      "accuracy": 0.9320987654320988,
      "precision": 0.8518518518518519,
      "recall": 0.36507936507936506,
      "f1": 0.5111111111111111
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_00/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6702172314223144,
      0.5963680124632785,
      0.5364319106002449,
      0.4877566754915171,
      0.4479236678443353,
      0.41512939397100845,
      0.38749805110633034,
      0.36399005296341136,
      0.34379988682759327,
      0.3263804102744315,
      0.31121627553450926,
      0.2979659228164173,
      0.28615233141723356,
      0.27558227265357454,
      0.2662147634434097
    ],
    "metrics": {
      "accuracy": 0.8765432098765432,
      "precision": 0.8829516539440203,
      "recall": 0.910761154855643,
      "f1": 0.896640826873385
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_01/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6487249815130273,
      0.5666415770762185,
      0.5006267339857936,
      0.4487981134926894,
      0.4082978996740602,
      0.37655865744294986,
      0.35102320672474857,
      0.3296792920386218,
      0.31157319886459545,
      0.2957487954381174,
      0.28200199104061785,
      0.26974667682048903,
      0.25900116546642005,
      0.24924612950131633,
      0.24048847423425412
    ],
    "metrics": {
      "accuracy": 0.9089506172839507,
      "precision": 0.86,
      "recall": 0.45263157894736844,
      "f1": 0.593103448275862
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_01/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6473858007661478,
      0.5557457840808807,
      0.48047735268054176,
      0.42005092495321805,
      0.37171534189843525,
      0.3330374916437755,
      0.30163349017205204,
      0.2757745283668733,
      0.254093909586017,
      0.23559032340482644,
      0.2196425699238286,
      0.20569854487897132,
      0.19346921945450973,
      0.18271760356170258,
      0.17305270252133167
    ],
    "metrics": {
      "accuracy": 0.9367283950617284,
      "precision": 0.9583333333333334,
      "recall": 0.36507936507936506,
      "f1": 0.5287356321839081
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_01/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6365310832611015,
      0.56410617605115,
      0.506420531061299,
      0.4602451078445894,
      0.4224909706166271,
      0.39104833119944016,
      0.3647870258262346,
      0.3424561474351787,
      0.32323359439443655,
      0.3066804880485421,
      0.29233003474344665,
      0.27967103919635555,
      0.26852538685138927,
      0.25869947786919606,
      0.2498239800961778
    ],
    "metrics": {
      "accuracy": 0.8765432098765432,
      "precision": 0.8771929824561403,
      "recall": 0.9186351706036745,
      "f1": 0.8974358974358975
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_02/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6587579958171228,
      0.5694787060478907,
      0.5008792516069912,
      0.448679471038612,
      0.40925606886761834,
      0.3780121738154398,
      0.35255811760593414,
      0.3313883211292563,
      0.3129176751901093,
      0.29678897199568527,
      0.28258871340369296,
      0.26978909883462854,
      0.25835175582995784,
      0.24786956538224744,
      0.2384616625587653
    ],
    "metrics": {
      "accuracy": 0.8950617283950617,
      "precision": 0.7872340425531915,
      "recall": 0.3894736842105263,
      "f1": 0.5211267605633803
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_02/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6419927196743761,
      0.5382315093860512,
      0.45448452710586906,
      0.3906712128387647,
      0.3419329372476903,
      0.3043821689453291,
      0.27493065403236194,
      0.25074103050142504,
      0.2307808684181603,
      0.21369073146482823,
      0.19890900651667875,
      0.18609382549149409,
      0.17456820933236866,
      0.1646262742994142,
      0.15564682020558454
    ],
    "metrics": {
      "accuracy": 0.9197530864197531,
      "precision": 0.7619047619047619,
      "recall": 0.25396825396825395,
      "f1": 0.38095238095238093
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_02/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6798302135282186,
      0.6045201545696149,
      0.5423324535838545,
      0.49081120654823146,
      0.4484584492391528,
      0.41326350036863724,
      0.38372612219039565,
      0.35869330910600766,
      0.3371871847291782,
      0.3185792046417585,
      0.3022233949516998,
      0.2877238182415292,
      0.27501037817313706,
      0.26364911878423286,
      0.2534502524863316
    ],
    "metrics": {
      "accuracy": 0.8641975308641975,
      "precision": 0.8581907090464548,
      "recall": 0.9212598425196851,
      "f1": 0.8886075949367088
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_03/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6628625002462082,
      0.5851960286850448,
      0.5206366955067483,
      0.4673959194690386,
      0.42418982078440004,
      0.3887532479528436,
      0.3597102953902273,
      0.3351155437020771,
      0.3141341775242613,
      0.29595693495488096,
      0.27994193789200084,
      0.26592102783728827,
      0.25337989118378523,
      0.24207578987879544,
      0.23184510739836625
    ],
    "metrics": {
      "accuracy": 0.9012345679012346,
      "precision": 0.8163265306122449,
      "recall": 0.42105263157894735,
      "f1": 0.5555555555555556
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_03/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6686578728997795,
      0.5797137206713445,
      0.5050127388310517,
      0.443479207124876,
      0.39339160435580145,
      0.3528016659431919,
      0.31917163179632957,
      0.2912102658144642,
      0.2675378411627555,
      0.24732103772900876,
      0.229683375684228,
      0.2143225115411273,
      0.20076508025787357,
      0.18861489589284314,
      0.17784514652626382
    ],
    "metrics": {
      "accuracy": 0.9305555555555556,
      "precision": 0.7142857142857143,
      "recall": 0.47619047619047616,
      "f1": 0.5714285714285714
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_03/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6624523461205248,
      0.5920779915988753,
      0.5330889135574834,
      0.4839207011741541,
      0.4430063740411314,
      0.4089891623141617,
      0.3804031400681838,
      0.3559248704614118,
      0.3349335664525308,
      0.3165665871992031,
      0.30052826407163746,
      0.2863639444477307,
      0.27357987696206193,
      0.2622053087705437,
      0.2520004219984872
    ],
    "metrics": {
      "accuracy": 0.8703703703703703,
      "precision": 0.8613138686131386,
      "recall": 0.9291338582677166,
      "f1": 0.8939393939393939
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_04/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6403692215478559,
      0.5699825884531814,
      0.5112276414905952,
      0.46150105546012654,
      0.42023125462604627,
      0.3857030894614394,
      0.35645694529663513,
      0.33130275363927303,
      0.3095774945356691,
      0.2907060505288164,
      0.2740653241400033,
      0.25945394848085807,
      0.24635222077078067,
      0.23465233310534597,
      0.22409476227622926
    ],
    "metrics": {
      "accuracy": 0.9151234567901234,
      "precision": 0.8703703703703703,
      "recall": 0.49473684210526314,
      "f1": 0.6308724832214765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_04/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6508860344729951,
      0.572507347238229,
      0.5058658378835151,
      0.4497782033514996,
      0.40307252555802064,
      0.36395066502658724,
      0.33099203964846713,
      0.3030123783619257,
      0.27914016180856294,
      0.25845226493987355,
      0.24035704354612553,
      0.22438535568959753,
      0.21013802110533183,
      0.19746749843064454,
      0.18610190471558832
    ],
    "metrics": {
      "accuracy": 0.9429012345679012,
      "precision": 0.7708333333333334,
      "recall": 0.5873015873015873,
      "f1": 0.6666666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_04/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.658816472655828,
      0.5921805934207405,
      0.5367364368869028,
      0.49028280600966173,
      0.45148249941372487,
      0.41861672400942185,
      0.3906253800585919,
      0.36651528810767836,
      0.34537765165812684,
      0.32684523289247064,
      0.3102069245421002,
      0.2953203984838233,
      0.28186288783815316,
      0.2697458273935461,
      0.25872032042996784
    ],
    "metrics": {
      "accuracy": 0.8811728395061729,
      "precision": 0.8636363636363636,
      "recall": 0.94750656167979,
      "f1": 0.9036295369211514
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_05/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6691518019450426,
      0.594887388306618,
      0.5332752304998679,
      0.4813864840765173,
      0.43839176831507237,
      0.40246937336659877,
      0.37197496347305536,
      0.3457351378219612,
      0.32315929205270527,
      0.3032966581869138,
      0.28582547448289947,
      0.2702411377306832,
      0.25640074291463194,
      0.2438930458480102,
      0.2326581665487126
    ],
    "metrics": {
      "accuracy": 0.9135802469135802,
      "precision": 0.8679245283018868,
      "recall": 0.4842105263157895,
      "f1": 0.6216216216216216
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_05/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6766040582441707,
      0.589401645532734,
      0.5164451086835454,
      0.4564111571770124,
      0.40679045947844256,
      0.36608063968895377,
      0.33239431511970213,
      0.30404668195022777,
      0.27983287907579923,
      0.2590252416399258,
      0.24088638570928222,
      0.22484849513257513,
      0.21058195253434664,
      0.19792129912270123,
      0.18652331230432387
    ],
    "metrics": {
      "accuracy": 0.9398148148148148,
      "precision": 0.8157894736842105,
      "recall": 0.49206349206349204,
      "f1": 0.6138613861386139
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_05/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6782303054749431,
      0.6109563110638779,
      0.5542518305823867,
      0.5056451894677052,
      0.46522406166453306,
      0.4309980525096236,
      0.4015747484029328,
      0.37611731562027306,
      0.35392264280185715,
      0.3343043746540617,
      0.31678449154937033,
      0.3010956718403867,
      0.2871483549876652,
      0.274480649855643,
      0.2629272734529138
    ],
    "metrics": {
      "accuracy": 0.8765432098765432,
      "precision": 0.8716049382716049,
      "recall": 0.926509186351706,
      "f1": 0.8982188295165394
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_06/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6581586889029521,
      0.5869292802187243,
      0.5276371887372414,
      0.47803399690178044,
      0.4370876054752129,
      0.40261838977412706,
      0.37332332569252186,
      0.3481247940524242,
      0.32585840898060414,
      0.3063951449959328,
      0.2890859132763743,
      0.27347601854985876,
      0.2595013636436499,
      0.2469850608384878,
      0.23549674835727408
    ],
    "metrics": {
      "accuracy": 0.9151234567901234,
      "precision": 0.8703703703703703,
      "recall": 0.49473684210526314,
      "f1": 0.6308724832214765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_06/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6491350672367507,
      0.5686500495495631,
      0.5015959034198716,
      0.44549329239053875,
      0.3997280644913606,
      0.36183193745610504,
      0.3301242698580391,
      0.30345371393899484,
      0.28055422369731964,
      0.2605512708822454,
      0.24294488624520003,
      0.22741835387578052,
      0.21357944765292486,
      0.20119774431500562,
      0.18998862444528195
    ],
    "metrics": {
      "accuracy": 0.9305555555555556,
      "precision": 0.78125,
      "recall": 0.3968253968253968,
      "f1": 0.5263157894736842
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_06/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.665979446957182,
      0.6030570961399291,
      0.5500550035971538,
      0.5050722465190463,
      0.46721360958215497,
      0.43463433026198167,
      0.40662906072845467,
      0.3821955480372073,
      0.36087727178111934,
      0.3419594275834736,
      0.32506494325734764,
      0.30984119327698884,
      0.2960449276361883,
      0.28337256152706325,
      0.27183861936943526
    ],
    "metrics": {
      "accuracy": 0.8533950617283951,
      "precision": 0.8341121495327103,
      "recall": 0.937007874015748,
      "f1": 0.8825710754017305
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_07/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6415188827408368,
      0.5709133971058243,
      0.5130060175476789,
      0.46516746333611664,
      0.4258783296030091,
      0.39281166467403517,
      0.3649335423705694,
      0.34081050736582064,
      0.3197282712545107,
      0.3013707000410858,
      0.2849057112076452,
      0.27020901149140325,
      0.257091716332875,
      0.24525143358006882,
      0.2343684119653624
    ],
    "metrics": {
      "accuracy": 0.9182098765432098,
      "precision": 0.9375,
      "recall": 0.47368421052631576,
      "f1": 0.6293706293706294
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_07/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6188043210129921,
      0.5418662983264959,
      0.4787170586053947,
      0.4270598075901176,
      0.3849449772149786,
      0.35037848734926935,
      0.32146123557124456,
      0.2968828127367336,
      0.27553792643738234,
      0.2568859931817681,
      0.24025345511266671,
      0.22534788765071948,
      0.21203042174704406,
      0.1997994550360257,
      0.18891151859388303
    ],
    "metrics": {
      "accuracy": 0.933641975308642,
      "precision": 0.8846153846153846,
      "recall": 0.36507936507936506,
      "f1": 0.5168539325842697
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_07/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.665680181610743,
      0.6035252862988881,
      0.5522160254829959,
      0.5089621090733445,
      0.47246240718949906,
      0.44167213543305806,
      0.4151445429232432,
      0.3918764201656377,
      0.37128678310108626,
      0.35315551312924337,
      0.33670511243135326,
      0.32189699037789843,
      0.3083995115209384,
      0.2960591318410322,
      0.2848137714319107
    ],
    "metrics": {
      "accuracy": 0.8410493827160493,
      "precision": 0.8202764976958525,
      "recall": 0.9343832020997376,
      "f1": 0.8736196319018404
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_08/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6532489205061272,
      0.5795276525973885,
      0.5182713263382824,
      0.4683207822707918,
      0.4270430210897799,
      0.39289037405747895,
      0.36398858826715813,
      0.33932813806001116,
      0.3179902052808048,
      0.29940418225489546,
      0.2829787258416228,
      0.2682301109050661,
      0.2551376912120115,
      0.243213422071937,
      0.23250469572682134
    ],
    "metrics": {
      "accuracy": 0.9120370370370371,
      "precision": 0.9130434782608695,
      "recall": 0.4421052631578947,
      "f1": 0.5957446808510638
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_08/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6684538754764929,
      0.585804506127813,
      0.5176096464846244,
      0.4625185914469271,
      0.41758408718829765,
      0.3804418336408687,
      0.3498898047602478,
      0.3237778640418767,
      0.3011706516401831,
      0.28127331894420676,
      0.263613389072356,
      0.24760295984925831,
      0.23315780787048018,
      0.22007892796221426,
      0.20826729711273761
    ],
    "metrics": {
      "accuracy": 0.9305555555555556,
      "precision": 0.875,
      "recall": 0.3333333333333333,
      "f1": 0.4827586206896552
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_08/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6562297061332771,
      0.5978184358909682,
      0.5488537220275735,
      0.5071532637180599,
      0.4714194946993496,
      0.4404597790725985,
      0.4134317786028023,
      0.3896665364447156,
      0.36874476083273083,
      0.34995255218507415,
      0.3331058919591792,
      0.3179456206662851,
      0.304242309222373,
      0.2917210158607693,
      0.2801835283649198
    ],
    "metrics": {
      "accuracy": 0.8487654320987654,
      "precision": 0.8283062645011601,
      "recall": 0.937007874015748,
      "f1": 0.8793103448275862
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_09/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6751675934174619,
      0.5975701522004122,
      0.5344643397608604,
      0.48421259215099066,
      0.4430673704519321,
      0.4089080007885033,
      0.37972220601870915,
      0.35452348017342616,
      0.3326217950961939,
      0.3131845650724109,
      0.29591017161157024,
      0.28040176613818824,
      0.2666036932242892,
      0.2540292591950141,
      0.2425662512792521
    ],
    "metrics": {
      "accuracy": 0.9027777777777778,
      "precision": 0.8333333333333334,
      "recall": 0.42105263157894735,
      "f1": 0.5594405594405595
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_09/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6946146755997465,
      0.6012883821107927,
      0.5248807337855023,
      0.4625403693461749,
      0.4128157805492451,
      0.3722029949180715,
      0.33885309393394897,
      0.3109654590596839,
      0.2871360090576653,
      0.2664793048800253,
      0.2483945820327685,
      0.23215506675208383,
      0.2177990332274179,
      0.20488484886700967,
      0.19333081733973073
    ],
    "metrics": {
      "accuracy": 0.9320987654320988,
      "precision": 0.9130434782608695,
      "recall": 0.3333333333333333,
      "f1": 0.4883720930232558
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_09/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6858895198098017,
      0.6154877556086429,
      0.5563639620783278,
      0.5069868731074244,
      0.46528265737230023,
      0.4299490935179033,
      0.399589335887644,
      0.37320313372829744,
      0.3501167476792866,
      0.32996604825109527,
      0.3119277825949146,
      0.2958978299425166,
      0.281442838822995,
      0.26843729283489526,
      0.25660803006796384
    ],
    "metrics": {
      "accuracy": 0.8796296296296297,
      "precision": 0.8598574821852731,
      "recall": 0.9501312335958005,
      "f1": 0.9027431421446384
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_10/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6482905817278121,
      0.5667050551966372,
      0.5016589345783603,
      0.4503268626728405,
      0.40862650391231836,
      0.37456776509144996,
      0.3458430189644393,
      0.3211751763880269,
      0.2997637774332544,
      0.2811110382512329,
      0.26467423992786887,
      0.24998328932182529,
      0.23693038396826901,
      0.22504630848485901,
      0.2143057326027543
    ],
    "metrics": {
      "accuracy": 0.9027777777777778,
      "precision": 0.8076923076923077,
      "recall": 0.4421052631578947,
      "f1": 0.5714285714285714
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_10/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6754497548554637,
      0.5761467972084309,
      0.4955834441451995,
      0.4317009140046014,
      0.38049503209053676,
      0.3397807849023808,
      0.30626887350375315,
      0.27849194220337864,
      0.25482129780907253,
      0.23448644772062616,
      0.2166450172217199,
      0.20116213868496438,
      0.18755322965745466,
      0.1753069433173786,
      0.16449667305183593
    ],
    "metrics": {
      "accuracy": 0.9506172839506173,
      "precision": 0.8974358974358975,
      "recall": 0.5555555555555556,
      "f1": 0.6862745098039216
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_10/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6485199408707459,
      0.5730155165119643,
      0.5109475586896488,
      0.45975691555602033,
      0.41735208618572855,
      0.3823011699546514,
      0.35272881063827843,
      0.32748399621023044,
      0.3055876719057317,
      0.2865574949540726,
      0.26988839880381305,
      0.255178722804835,
      0.24207826131677848,
      0.2303404176679115,
      0.219773987002851
    ],
    "metrics": {
      "accuracy": 0.8873456790123457,
      "precision": 0.8928571428571429,
      "recall": 0.9186351706036745,
      "f1": 0.9055627425614489
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_11/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6369740862534014,
      0.5573609016064102,
      0.4926219072216197,
      0.4408742792744389,
      0.39812884554489697,
      0.3628231392554143,
      0.33315519654384673,
      0.3076565518801094,
      0.28580117893951296,
      0.2666356800188348,
      0.249893181420889,
      0.23509615108868973,
      0.22175210014848354,
      0.2099659717473429,
      0.19927866187439758
    ],
    "metrics": {
      "accuracy": 0.9135802469135802,
      "precision": 0.8545454545454545,
      "recall": 0.49473684210526314,
      "f1": 0.6266666666666667
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_11/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.689997910837597,
      0.588453970628771,
      0.505355009949379,
      0.4382224712043912,
      0.3844708152101169,
      0.34115179785894095,
      0.3057834530417833,
      0.27643109964154666,
      0.2516089480559636,
      0.23067032305012905,
      0.21250585700124786,
      0.19670495077396546,
      0.18290523021044242,
      0.17083277854056875,
      0.15997805155775216
    ],
    "metrics": {
      "accuracy": 0.9552469135802469,
      "precision": 0.8695652173913043,
      "recall": 0.6349206349206349,
      "f1": 0.7339449541284404
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_11/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6276823781890434,
      0.5402714475304836,
      0.4776466872161353,
      0.42880972191897965,
      0.3896228301683889,
      0.35722802546595256,
      0.3302263199845615,
      0.30726577515315673,
      0.2875413531824829,
      0.27037773764742623,
      0.2554386316085516,
      0.24222242355460089,
      0.23031459035481988,
      0.21974933903626884,
      0.21023397714701578
    ],
    "metrics": {
      "accuracy": 0.8873456790123457,
      "precision": 0.8811881188118812,
      "recall": 0.9343832020997376,
      "f1": 0.9070063694267516
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_12/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6168176725397424,
      0.4882174300966006,
      0.4111161622365359,
      0.36401829810432845,
      0.33214589782498655,
      0.30568259077151205,
      0.28198818668427433,
      0.26140367207108517,
      0.24345735050018924,
      0.22769239256079996,
      0.21405518008383373,
      0.2020016866117173,
      0.19118502353335504,
      0.18140010472531876,
      0.17267559032930763
    ],
    "metrics": {
      "accuracy": 0.9182098765432098,
      "precision": 0.9565217391304348,
      "recall": 0.4631578947368421,
      "f1": 0.624113475177305
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_12/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.584873325719753,
      0.4473848716254855,
      0.36024405901831885,
      0.3056080257983336,
      0.2690115658225622,
      0.24100327152747697,
      0.21785108386238947,
      0.19798169557038583,
      0.1809333777437394,
      0.1655998366962603,
      0.1526964848319873,
      0.14154910732219647,
      0.13132656631132092,
      0.12258894197778489,
      0.11481361426301676
    ],
    "metrics": {
      "accuracy": 0.9475308641975309,
      "precision": 0.8372093023255814,
      "recall": 0.5714285714285714,
      "f1": 0.6792452830188679
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_BASE/layer_12/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9568553153925431,
      0.40044553123224547,
      0.2921795294160568,
      0.22931297596478267,
      0.21185153875574073,
      0.19391340661964085,
      0.1836986285643472,
      0.17769123278151175,
      0.17204642212751634,
      0.1685410629979834,
      0.16440021244375336,
      0.16126445785444568,
      0.15819534043548955,
      0.15553527899685612,
      0.15313217692279654
    ],
    "metrics": {
      "accuracy": 0.871160409556314,
      "precision": 0.8845618915159944,
      "recall": 0.9034090909090909,
      "f1": 0.8938861560084329
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_00/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2945524150206616,
      0.19866447821656139,
      0.1689916513954167,
      0.15243269103970905,
      0.14115906166292166,
      0.13237227337279886,
      0.12568230880019912,
      0.12078426195881085,
      0.11732949864909441,
      0.11626347458957123,
      0.11008712284018526,
      0.10722145231106128,
      0.10437258715830319,
      0.10274743679133273,
      0.1005042892969199
    ],
    "metrics": {
      "accuracy": 0.9010238907849829,
      "precision": 0.7860262008733624,
      "recall": 0.728744939271255,
      "f1": 0.7563025210084033
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_00/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3514838915565629,
      0.19187884501179717,
      0.13064353659427544,
      0.1057277826008325,
      0.09274587622624747,
      0.08532773231543156,
      0.0773605690654769,
      0.07375858671092693,
      0.06827084492692663,
      0.06584098008449554,
      0.06254572975982903,
      0.060303378174888816,
      0.059226172949318194,
      0.05706715489651316,
      0.055004850263754575
    ],
    "metrics": {
      "accuracy": 0.9633105802047781,
      "precision": 0.7183098591549296,
      "recall": 0.6891891891891891,
      "f1": 0.7034482758620689
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_00/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3408471102948682,
      0.23216501264536737,
      0.18701599158386317,
      0.16939387926620475,
      0.15962793756747118,
      0.15087818900688452,
      0.14282647254137004,
      0.1386673604450028,
      0.13263397064486884,
      0.12810426819354553,
      0.12448165862792078,
      0.12192280182203147,
      0.11872586472448965,
      0.1163775447800935,
      0.11399356903115318
    ],
    "metrics": {
      "accuracy": 0.8831058020477816,
      "precision": 0.8805369127516779,
      "recall": 0.9318181818181818,
      "f1": 0.9054520358868184
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_01/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.538139457761423,
      0.29861935895091846,
      0.22628363376156094,
      0.18350235683622731,
      0.16712529561071376,
      0.14946328688482838,
      0.14048942023380426,
      0.1315288739766885,
      0.125923218096495,
      0.12082843704613092,
      0.1163894893655292,
      0.11273629862150247,
      0.10930728207585791,
      0.10624995091384651,
      0.103776457998458
    ],
    "metrics": {
      "accuracy": 0.9027303754266212,
      "precision": 0.7929515418502202,
      "recall": 0.728744939271255,
      "f1": 0.759493670886076
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_01/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6284497719446996,
      0.38676641581271604,
      0.24342218134526145,
      0.13084378751278192,
      0.13049629103506136,
      0.09715299363412186,
      0.08949512745125617,
      0.07737263966989504,
      0.07294151717188914,
      0.0675969534530363,
      0.06438850924585607,
      0.061530518154781985,
      0.058934439354648975,
      0.056642227342446734,
      0.05490014558873547
    ],
    "metrics": {
      "accuracy": 0.962457337883959,
      "precision": 0.7142857142857143,
      "recall": 0.6756756756756757,
      "f1": 0.6944444444444444
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_01/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.42336121603166,
      0.22172173262727998,
      0.17617048265537183,
      0.15843097509022486,
      0.14394668263400692,
      0.1335056460840624,
      0.12695714567481853,
      0.12203899761580993,
      0.11725738362150054,
      0.11310710602445942,
      0.10920214671594618,
      0.10622801436708901,
      0.103518894176568,
      0.10134860061987938,
      0.09939595167628187
    ],
    "metrics": {
      "accuracy": 0.8882252559726962,
      "precision": 0.8908594815825375,
      "recall": 0.9275568181818182,
      "f1": 0.9088378566457899
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_02/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7596222929474886,
      0.3895818583435557,
      0.24783368563996072,
      0.18049845099449158,
      0.15793093104144043,
      0.13718208746186622,
      0.1261472696222889,
      0.11567715312226141,
      0.1099663710028025,
      0.10364000860400212,
      0.09927110359360772,
      0.09510531795854894,
      0.0918636344483868,
      0.08902604258354387,
      0.08636397219783086
    ],
    "metrics": {
      "accuracy": 0.893344709897611,
      "precision": 0.7606837606837606,
      "recall": 0.7206477732793523,
      "f1": 0.7401247401247402
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_02/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3700706755565508,
      0.16580257806733864,
      0.11173781722525182,
      0.07630937550249271,
      0.06231192555763902,
      0.05378905135661188,
      0.04779099654870796,
      0.044353693894860324,
      0.04137160038770197,
      0.039238184926372245,
      0.03745647814489106,
      0.03606081290317203,
      0.03493999479597909,
      0.03369905548282417,
      0.032605488376227974
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.75,
      "recall": 0.7702702702702703,
      "f1": 0.76
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_02/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5422901605133518,
      0.2695497161377108,
      0.19697630680986866,
      0.16433652777002453,
      0.15095570779925604,
      0.13725894901240765,
      0.12813912214109563,
      0.12128242121737488,
      0.1161760723797104,
      0.1116975683413089,
      0.10862628827703938,
      0.10461896650845946,
      0.10188107706061529,
      0.10043613911176069,
      0.09771350635704656
    ],
    "metrics": {
      "accuracy": 0.8822525597269625,
      "precision": 0.8733509234828496,
      "recall": 0.9403409090909091,
      "f1": 0.905608755129959
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_03/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.45351672116599184,
      0.2370804629052978,
      0.18352888822221528,
      0.14216982613561133,
      0.12253216048663455,
      0.1050509327694327,
      0.09536903084961097,
      0.08832577520782589,
      0.08253915548850656,
      0.07766442458046421,
      0.07388635487633614,
      0.07070004439535145,
      0.06778852988747396,
      0.06542965884167262,
      0.06331010167527412
    ],
    "metrics": {
      "accuracy": 0.9001706484641638,
      "precision": 0.782608695652174,
      "recall": 0.728744939271255,
      "f1": 0.7547169811320755
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_03/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.20715577586854864,
      0.07531856060545797,
      0.051012051483038494,
      0.04141764030586975,
      0.03720051754223228,
      0.03412352042921403,
      0.03111089729388477,
      0.028815938589865336,
      0.026904792038728524,
      0.025167469545869008,
      0.02395803456759129,
      0.022541662839127292,
      0.021461432357129512,
      0.02034654925165306,
      0.019670729946817928
    ],
    "metrics": {
      "accuracy": 0.9684300341296929,
      "precision": 0.7283950617283951,
      "recall": 0.7972972972972973,
      "f1": 0.7612903225806451
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_03/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5335245635971098,
      0.240530990124684,
      0.18146204985584255,
      0.15440165718068058,
      0.13432835590258202,
      0.12321260123067157,
      0.11481353289842539,
      0.10836478290386847,
      0.1033356182755259,
      0.0983862350800519,
      0.09445034790837353,
      0.09109192984123864,
      0.08834056331600987,
      0.08513209059872057,
      0.08266004733375956
    ],
    "metrics": {
      "accuracy": 0.8890784982935154,
      "precision": 0.8847184986595175,
      "recall": 0.9375,
      "f1": 0.9103448275862069
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_04/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6964091353471221,
      0.2944250994785455,
      0.19864414403521402,
      0.14381670913014236,
      0.1263189319908435,
      0.10750635439865594,
      0.09713519817391976,
      0.08745847423643116,
      0.08093665726848195,
      0.07569027597198937,
      0.0709959382217917,
      0.06736340313005862,
      0.06405284934415975,
      0.06171300734632588,
      0.05892840470167795
    ],
    "metrics": {
      "accuracy": 0.8976109215017065,
      "precision": 0.777292576419214,
      "recall": 0.7206477732793523,
      "f1": 0.7478991596638656
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_04/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3474244233664427,
      0.11158479009899781,
      0.06193539934557972,
      0.043360487821765825,
      0.03932356088988234,
      0.035636418251413095,
      0.033662816345729256,
      0.03167847438218815,
      0.029754356443819362,
      0.028206605665671722,
      0.02687609375136912,
      0.025637702306622417,
      0.024402690213721618,
      0.023398664618956337,
      0.022343150174318826
    ],
    "metrics": {
      "accuracy": 0.9684300341296929,
      "precision": 0.7534246575342466,
      "recall": 0.7432432432432432,
      "f1": 0.7482993197278912
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_04/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.591422556060541,
      0.2560238393039789,
      0.18219359484614694,
      0.14662629238996028,
      0.12819397670359597,
      0.11623214695442956,
      0.10761649235060115,
      0.10103528808648929,
      0.09546793526329224,
      0.0908194349973801,
      0.08705384556896115,
      0.08329063413456463,
      0.08013903317489221,
      0.07728520064969863,
      0.07464656286081468
    ],
    "metrics": {
      "accuracy": 0.8737201365187713,
      "precision": 0.8696808510638298,
      "recall": 0.9289772727272727,
      "f1": 0.8983516483516484
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_05/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9864587641189866,
      0.5617138567876668,
      0.24751112019107202,
      0.21915286117222638,
      0.14629487988076378,
      0.125818324818869,
      0.10619351941268629,
      0.08973931275886392,
      0.08148595342727294,
      0.07413171105447955,
      0.06920065897190461,
      0.06509857265078811,
      0.06165343886682319,
      0.058886027379542315,
      0.056071516574180635
    ],
    "metrics": {
      "accuracy": 0.9155290102389079,
      "precision": 0.8032786885245902,
      "recall": 0.7935222672064778,
      "f1": 0.7983706720977597
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_05/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5250484721354658,
      0.2165581619069001,
      0.08314050590626229,
      0.07205889581523378,
      0.04830965352040875,
      0.04357554784535727,
      0.03982043002321627,
      0.03552189486873153,
      0.033733739920271545,
      0.031764044834503895,
      0.02975880161489332,
      0.028359798217152107,
      0.026704901370615743,
      0.02558104912250708,
      0.02459665785970792
    ],
    "metrics": {
      "accuracy": 0.9709897610921502,
      "precision": 0.7631578947368421,
      "recall": 0.7837837837837838,
      "f1": 0.7733333333333333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_05/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6364407040352045,
      0.28292781274904555,
      0.19158769071386053,
      0.15931040099536248,
      0.13442008311707088,
      0.11987262825633205,
      0.1093206399147268,
      0.10239385912634806,
      0.09544421439746677,
      0.09052503535680058,
      0.08686404859996302,
      0.08219767232866773,
      0.07852437017753232,
      0.07548776986252263,
      0.0725600851554101
    ],
    "metrics": {
      "accuracy": 0.8839590443686007,
      "precision": 0.8796791443850267,
      "recall": 0.9346590909090909,
      "f1": 0.90633608815427
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_06/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.36028754554582465,
      0.16026606590482625,
      0.10818935461022934,
      0.08350816199440654,
      0.06765046399467697,
      0.06006060974475682,
      0.053116671263996246,
      0.048405108980168546,
      0.04422869555167822,
      0.04126849266708014,
      0.03913626194826927,
      0.03636154029742781,
      0.034597674984371135,
      0.03263505124929289,
      0.030675212201592167
    ],
    "metrics": {
      "accuracy": 0.9172354948805461,
      "precision": 0.8048780487804879,
      "recall": 0.8016194331983806,
      "f1": 0.8032454361054767
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_06/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4551500963476667,
      0.11935047281117425,
      0.06952406926945365,
      0.04581647674621204,
      0.042725018426279085,
      0.0371519514044048,
      0.03351588541071399,
      0.03091116561237321,
      0.028202053183482522,
      0.02601714465693036,
      0.02404648794550694,
      0.02240981232206856,
      0.021050445016804413,
      0.01986629241212689,
      0.018685809250228978
    ],
    "metrics": {
      "accuracy": 0.9709897610921502,
      "precision": 0.7857142857142857,
      "recall": 0.7432432432432432,
      "f1": 0.7638888888888888
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_06/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.4603767324041739,
      0.6716564202732851,
      0.30850280969541727,
      0.23350041917256195,
      0.17559953703620448,
      0.15764271013875006,
      0.13708968930265822,
      0.12685829327533343,
      0.11854600984030125,
      0.11212293983850201,
      0.10637898799726093,
      0.10165509315816652,
      0.09772986596365141,
      0.09399644187115327,
      0.09061656093381974
    ],
    "metrics": {
      "accuracy": 0.8771331058020477,
      "precision": 0.8804347826086957,
      "recall": 0.9204545454545454,
      "f1": 0.9
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_07/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4882462760937184,
      0.20839920575694232,
      0.14747111639177543,
      0.10372752727798201,
      0.08699911728221583,
      0.07170550730815285,
      0.06416050778505147,
      0.057556082435843654,
      0.05343557473582091,
      0.04920574293609392,
      0.04598418656714693,
      0.042968808241453646,
      0.0407724648851846,
      0.038612500472950916,
      0.03619514541420225
    ],
    "metrics": {
      "accuracy": 0.909556313993174,
      "precision": 0.7831325301204819,
      "recall": 0.7894736842105263,
      "f1": 0.7862903225806451
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_07/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3895517514345859,
      0.14208855718983826,
      0.07116053108534047,
      0.05317848478881008,
      0.04259910931224648,
      0.03961287418411172,
      0.03522173238776752,
      0.03177803200553465,
      0.029327258290229776,
      0.027005969580919446,
      0.024903516743606666,
      0.023403394122890612,
      0.021848938708384353,
      0.020661935674193093,
      0.0195508533073644
    ],
    "metrics": {
      "accuracy": 0.9667235494880546,
      "precision": 0.7215189873417721,
      "recall": 0.7702702702702703,
      "f1": 0.7450980392156863
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_07/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4230659875082482,
      0.17800227011342315,
      0.12478082656701696,
      0.10412374526496093,
      0.09206122711288324,
      0.08228712770894783,
      0.07514528976949066,
      0.0695357832647432,
      0.06489552419687994,
      0.0609030686475443,
      0.05741493951066865,
      0.05436835183223679,
      0.05163658256664701,
      0.04937998304792264,
      0.04686368873374707
    ],
    "metrics": {
      "accuracy": 0.8873720136518771,
      "precision": 0.8875338753387534,
      "recall": 0.9303977272727273,
      "f1": 0.9084604715672677
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_08/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.36528271130651746,
      0.1384951768969581,
      0.0810128200238711,
      0.059240480882300155,
      0.04852077792562768,
      0.04134870208037872,
      0.03672511561291747,
      0.03293521706308177,
      0.029685782097983542,
      0.02724829690181748,
      0.02501775487332609,
      0.023319518014592394,
      0.02178805908430905,
      0.02047824320553247,
      0.019360799351266098
    ],
    "metrics": {
      "accuracy": 0.9206484641638225,
      "precision": 0.8155737704918032,
      "recall": 0.805668016194332,
      "f1": 0.8105906313645621
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_08/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5440535463599405,
      0.21655223513391045,
      0.06559178148495212,
      0.0575296878146671,
      0.04157535373772116,
      0.03280695516205896,
      0.030934945747786526,
      0.028498593948491316,
      0.025889659678298874,
      0.024241132780170534,
      0.02293610176539665,
      0.021496425120540445,
      0.020246286404445146,
      0.019207375921031347,
      0.01846160323344198
    ],
    "metrics": {
      "accuracy": 0.9658703071672355,
      "precision": 0.7073170731707317,
      "recall": 0.7837837837837838,
      "f1": 0.7435897435897436
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_08/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6834350734840557,
      0.27204167494238773,
      0.17371459836784817,
      0.1295991773033683,
      0.1053369725287445,
      0.08897751676632129,
      0.08068385451372413,
      0.07431870506245003,
      0.06866183393298494,
      0.06385599369009391,
      0.06039947921942015,
      0.05731424032330813,
      0.05372359460435284,
      0.050965212984858656,
      0.04849123591951176
    ],
    "metrics": {
      "accuracy": 0.8796928327645052,
      "precision": 0.8788694481830417,
      "recall": 0.9275568181818182,
      "f1": 0.902557014512785
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_09/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7285020685924072,
      0.25796153603664934,
      0.1470590701421191,
      0.09456819009466912,
      0.07100849713045665,
      0.053843933888537504,
      0.04677903633507302,
      0.04130926695995452,
      0.037941435196964836,
      0.03462887443675151,
      0.032061951245896524,
      0.030057982359740137,
      0.02817788942980312,
      0.026359328188567843,
      0.024853314590632797
    ],
    "metrics": {
      "accuracy": 0.9325938566552902,
      "precision": 0.8589743589743589,
      "recall": 0.8137651821862348,
      "f1": 0.8357588357588358
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_09/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5449156783214301,
      0.2258888178176992,
      0.07240487088397893,
      0.06487541429596176,
      0.04709074227778676,
      0.0371511803997869,
      0.0351671301721942,
      0.032545717403346934,
      0.02951970547761243,
      0.027052460037929632,
      0.02496577830007678,
      0.023209866040283706,
      0.021587062895983774,
      0.020177438990864043,
      0.018927258309149115
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7435897435897436,
      "recall": 0.7837837837837838,
      "f1": 0.7631578947368421
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_09/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9916725367449618,
      0.37525265881179526,
      0.22913821807309137,
      0.14547522287971335,
      0.1208809408137163,
      0.09756690336187268,
      0.08860440147661235,
      0.08019677139599472,
      0.07302589547938076,
      0.06808640302672177,
      0.0634590911807617,
      0.05990025158538375,
      0.05707727134766349,
      0.05433123811148368,
      0.0515536202191388
    ],
    "metrics": {
      "accuracy": 0.8890784982935154,
      "precision": 0.8888888888888888,
      "recall": 0.9318181818181818,
      "f1": 0.9098474341192788
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_10/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7198333285976505,
      0.22333642986933702,
      0.1447385710936262,
      0.09090235437931685,
      0.0691044165573557,
      0.050711962392589696,
      0.04356934793103506,
      0.03815478735500839,
      0.03429380931329681,
      0.031327664203948086,
      0.02876277682109185,
      0.02695295810657711,
      0.02510114425819907,
      0.02354034119170565,
      0.022268398583215068
    ],
    "metrics": {
      "accuracy": 0.9172354948805461,
      "precision": 0.8177966101694916,
      "recall": 0.7813765182186235,
      "f1": 0.7991718426501035
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_10/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.4964869491908357,
      0.36913976443184626,
      0.2591928421499082,
      0.09686915930094389,
      0.055439624965658504,
      0.05211834386450365,
      0.045889563718641065,
      0.03899519417918206,
      0.03406672250311409,
      0.03094676427979468,
      0.0286970024776579,
      0.026729223784711657,
      0.025009456545722005,
      0.02305792950659481,
      0.02154856743163156
    ],
    "metrics": {
      "accuracy": 0.9701365187713311,
      "precision": 0.76,
      "recall": 0.7702702702702703,
      "f1": 0.7651006711409396
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_10/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.2264972387759014,
      0.38191885004928045,
      0.22822381459587793,
      0.1514647342755234,
      0.1205104673696219,
      0.09968019392300667,
      0.08973287308155972,
      0.08107844402590329,
      0.07451371359253972,
      0.06941553531436401,
      0.06482283123470081,
      0.06136248529408285,
      0.057447038246457,
      0.05490463454580066,
      0.051960072384374285
    ],
    "metrics": {
      "accuracy": 0.8856655290102389,
      "precision": 0.8914835164835165,
      "recall": 0.921875,
      "f1": 0.9064245810055865
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_11/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1195265284670806,
      0.5157668393310896,
      0.24012424588270234,
      0.18207008843580258,
      0.13789388143480175,
      0.09505761700347547,
      0.07879600236356743,
      0.06388191029984733,
      0.05553676316378397,
      0.04931182532659196,
      0.04437642528329219,
      0.040238858564631816,
      0.03720490749467151,
      0.034346563274990145,
      0.03205511621185196
    ],
    "metrics": {
      "accuracy": 0.931740614334471,
      "precision": 0.8553191489361702,
      "recall": 0.8137651821862348,
      "f1": 0.8340248962655602
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_11/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9621815223358499,
      0.42000555585465466,
      0.13490637686572243,
      0.08045900240853641,
      0.06136569761169845,
      0.04327073247994185,
      0.036826152940567514,
      0.03409108381199633,
      0.031238572934001025,
      0.02817952906325121,
      0.02563862285779517,
      0.023508704780204587,
      0.021899234351896963,
      0.020156238502599705,
      0.018724867147694918
    ],
    "metrics": {
      "accuracy": 0.9658703071672355,
      "precision": 0.717948717948718,
      "recall": 0.7567567567567568,
      "f1": 0.7368421052631579
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_11/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5751539837098248,
      0.20753442768073277,
      0.12867588338589062,
      0.1010979999385985,
      0.08171967386940542,
      0.07285156561300246,
      0.06373118419846288,
      0.058088614583708516,
      0.05240551731555727,
      0.048169124072992224,
      0.04401082275594507,
      0.04097426939796386,
      0.037813469964847,
      0.03539466413255164,
      0.03324627291758744
    ],
    "metrics": {
      "accuracy": 0.8856655290102389,
      "precision": 0.8904109589041096,
      "recall": 0.9232954545454546,
      "f1": 0.9065550906555091
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_12/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.47041438142102315,
      0.1603669081855034,
      0.08414036090858645,
      0.05070258749027351,
      0.0370300518394218,
      0.0294836665532124,
      0.0247060453170077,
      0.021066339610838095,
      0.01868187928763833,
      0.01603182465512317,
      0.014705532828007184,
      0.013199785557536642,
      0.01190114315754728,
      0.011064468349078834,
      0.01018229531999453
    ],
    "metrics": {
      "accuracy": 0.9249146757679181,
      "precision": 0.8767772511848341,
      "recall": 0.7489878542510121,
      "f1": 0.8078602620087336
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_12/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4611146736458992,
      0.11596062938187195,
      0.06331593601430253,
      0.03882471012548092,
      0.031053373873761954,
      0.027225992045555505,
      0.02365621222059419,
      0.020946576531415944,
      0.018654084218257313,
      0.016857822956039804,
      0.015027015754140435,
      0.013728521976167998,
      0.012552888821142458,
      0.011488107769207547,
      0.010663588074134842
    ],
    "metrics": {
      "accuracy": 0.9701365187713311,
      "precision": 0.76,
      "recall": 0.7702702702702703,
      "f1": 0.7651006711409396
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_12/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 13,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1511278891052374,
      0.31759319031696154,
      0.16221343268112964,
      0.11988856112774963,
      0.08946034746465312,
      0.07870454000688527,
      0.06647547593501543,
      0.057948170381664194,
      0.05197980655808681,
      0.047670303522688764,
      0.04308831612413823,
      0.039653741562272964,
      0.036812409184482725,
      0.03443632258635153,
      0.03182461630249264
    ],
    "metrics": {
      "accuracy": 0.8907849829351536,
      "precision": 0.9011142061281338,
      "recall": 0.9190340909090909,
      "f1": 0.909985935302391
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_13/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 13,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5560705170690863,
      0.2063435134800184,
      0.11350090136612187,
      0.06680760547230644,
      0.04708469231240086,
      0.03667457022334421,
      0.03077098922623944,
      0.026294498413938973,
      0.021691844037439883,
      0.019613984257241663,
      0.017354616303488498,
      0.015656902510375326,
      0.013812281871900802,
      0.012643395020981635,
      0.011630611227755872
    ],
    "metrics": {
      "accuracy": 0.9180887372013652,
      "precision": 0.8447488584474886,
      "recall": 0.7489878542510121,
      "f1": 0.7939914163090128
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_13/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 13,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.43605782837719437,
      0.11316759823817571,
      0.05429052877372705,
      0.03824461828922484,
      0.031967157370137646,
      0.023921871044808456,
      0.021641942416441712,
      0.01826842762863863,
      0.015766616035738173,
      0.01367693647150442,
      0.012078369105207081,
      0.011042567255728533,
      0.009420606265281363,
      0.00876311901784571,
      0.00766188175171931
    ],
    "metrics": {
      "accuracy": 0.9701365187713311,
      "precision": 0.7671232876712328,
      "recall": 0.7567567567567568,
      "f1": 0.7619047619047619
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_13/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 14,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.7237411516659331,
      0.6671219341275271,
      0.24792501005547893,
      0.20184289380745182,
      0.13147096617920254,
      0.10088159118038695,
      0.09078798487544494,
      0.07849054241855126,
      0.07127187481010686,
      0.06581625025682872,
      0.060999312455554275,
      0.056809980139391,
      0.05349082506944666,
      0.0504328100238821,
      0.047210210420214255
    ],
    "metrics": {
      "accuracy": 0.8839590443686007,
      "precision": 0.9,
      "recall": 0.9076704545454546,
      "f1": 0.9038189533239038
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_14/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 14,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0337268997888733,
      0.32858037656764416,
      0.15797281547917408,
      0.09348930218918512,
      0.061348293655082,
      0.047893369005161626,
      0.03880983393176927,
      0.03300367747181669,
      0.02798373217186396,
      0.025582836404375985,
      0.02239907911983098,
      0.020578426558135035,
      0.01858030808956458,
      0.01665539275379901,
      0.015219599312042432
    ],
    "metrics": {
      "accuracy": 0.9223549488054608,
      "precision": 0.8714285714285714,
      "recall": 0.7408906882591093,
      "f1": 0.8008752735229759
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_14/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 14,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1687450586129517,
      0.4718099811408459,
      0.1647167979322351,
      0.0767276062100132,
      0.06268626812644017,
      0.04166989433444759,
      0.03558697428947806,
      0.0323029617408672,
      0.0291896791944453,
      0.02737862521949002,
      0.025652268917124188,
      0.02411651089328215,
      0.022815966218789275,
      0.021653783238347036,
      0.020202509647626175
    ],
    "metrics": {
      "accuracy": 0.9590443686006825,
      "precision": 0.6666666666666666,
      "recall": 0.7027027027027027,
      "f1": 0.6842105263157895
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_14/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 15,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.2322572332264896,
      0.46997091652599493,
      0.2582713561495268,
      0.15367550997631862,
      0.12586511101215686,
      0.09807740296238475,
      0.08720151033136617,
      0.07569861621432827,
      0.06908128881953818,
      0.06240988277894638,
      0.05835529914061607,
      0.05414548391540467,
      0.05078075792036093,
      0.04784238161234737,
      0.045443279388430874
    ],
    "metrics": {
      "accuracy": 0.8754266211604096,
      "precision": 0.8801089918256131,
      "recall": 0.9176136363636364,
      "f1": 0.8984700973574409
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_15/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 15,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7538996123990347,
      0.23596917937435868,
      0.14648005102872513,
      0.0908061026959033,
      0.06040645089615256,
      0.046997062052981334,
      0.03858664405967181,
      0.031561705752743766,
      0.02680824826239003,
      0.023952393706717822,
      0.021095323246666516,
      0.02009985466250504,
      0.0177470951743735,
      0.01662653815142161,
      0.015081739629041867
    ],
    "metrics": {
      "accuracy": 0.9172354948805461,
      "precision": 0.8571428571428571,
      "recall": 0.728744939271255,
      "f1": 0.787746170678337
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_15/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 15,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6744834701448437,
      0.26380019485073686,
      0.07104643623212299,
      0.06912213747626295,
      0.040671789271845206,
      0.03474338642749742,
      0.028172781771327073,
      0.024651524135109657,
      0.021879792344957617,
      0.01976060140048148,
      0.01767840363454772,
      0.015815435851587237,
      0.014632465312626389,
      0.013346561063451572,
      0.012256924744301916
    ],
    "metrics": {
      "accuracy": 0.9650170648464164,
      "precision": 0.7037037037037037,
      "recall": 0.7702702702702703,
      "f1": 0.7354838709677419
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_15/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 16,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.170243376291376,
      0.3814197682505998,
      0.2118779170509813,
      0.15533478361204514,
      0.11982042520912664,
      0.10237196505771161,
      0.08876094599086118,
      0.0781709588385657,
      0.06988755876600793,
      0.06349982409149567,
      0.058421472165264915,
      0.05380574471540864,
      0.04987985406328764,
      0.04619327562467896,
      0.04345150960363504
    ],
    "metrics": {
      "accuracy": 0.8779863481228669,
      "precision": 0.891213389121339,
      "recall": 0.9076704545454546,
      "f1": 0.8993666432090077
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_16/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 16,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9278651843821846,
      0.28851182141301346,
      0.15549983352664873,
      0.09780903755741716,
      0.0661976984635509,
      0.050925298728848344,
      0.04163820941588831,
      0.03478705199395167,
      0.02924938042747036,
      0.025611792506039996,
      0.02317569969740192,
      0.0203515870330146,
      0.018798555737806488,
      0.017572196041833757,
      0.016046775662298212
    ],
    "metrics": {
      "accuracy": 0.9146757679180887,
      "precision": 0.8693467336683417,
      "recall": 0.7004048582995951,
      "f1": 0.7757847533632287
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_16/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 16,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.30052458310985675,
      0.07576504038345684,
      0.040971143134136634,
      0.03160326904206257,
      0.02518943555884817,
      0.019097610007534176,
      0.015957741712398242,
      0.01198681287745911,
      0.009536488391365047,
      0.007766464838388087,
      0.006625264090803966,
      0.005557634462867299,
      0.004259731791470942,
      0.003968976660894893,
      0.003446531667052848
    ],
    "metrics": {
      "accuracy": 0.9650170648464164,
      "precision": 0.6941176470588235,
      "recall": 0.7972972972972973,
      "f1": 0.7421383647798742
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_16/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 17,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.7145090153919411,
      0.5695981998826383,
      0.33261196467682036,
      0.23718240172397392,
      0.17604069144544096,
      0.1434855501118679,
      0.12491439052007551,
      0.1107790260154281,
      0.0986050128869965,
      0.08773437994940671,
      0.08008095461945135,
      0.0732779818552821,
      0.06869601608303856,
      0.06281074850657435,
      0.05852649794277206
    ],
    "metrics": {
      "accuracy": 0.8728668941979523,
      "precision": 0.8704939919893191,
      "recall": 0.9261363636363636,
      "f1": 0.8974535443909153
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_17/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 17,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.892256360790181,
      0.7048151541754925,
      0.3582319967651207,
      0.22445300117899103,
      0.16187170000930032,
      0.11217672698686156,
      0.08490198418502215,
      0.06698221894506648,
      0.056802738790887514,
      0.049285099206768386,
      0.04387307194452738,
      0.03908436729122056,
      0.03493071795157038,
      0.03202270405796537,
      0.029010127567571063
    ],
    "metrics": {
      "accuracy": 0.9155290102389079,
      "precision": 0.8457943925233645,
      "recall": 0.7327935222672065,
      "f1": 0.7852494577006508
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_17/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 17,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.4691921141208404,
      0.5597673552181247,
      0.20309537257524257,
      0.08719338307981232,
      0.06281309733707452,
      0.042003186095509085,
      0.03955623595804419,
      0.03083810883368822,
      0.028216339106042366,
      0.02511027817681962,
      0.022512953450267107,
      0.020728490977402193,
      0.018795346020535366,
      0.017013849299656773,
      0.01575977451374932
    ],
    "metrics": {
      "accuracy": 0.9650170648464164,
      "precision": 0.726027397260274,
      "recall": 0.7162162162162162,
      "f1": 0.7210884353741497
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_17/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 18,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9925367349367844,
      0.3235722841602576,
      0.19166507903234936,
      0.14023838516426007,
      0.11423586692027465,
      0.09266232825454526,
      0.0781446767578976,
      0.06955236565811222,
      0.0615991463336199,
      0.0540780017450431,
      0.05029875099237274,
      0.046197670747015314,
      0.0424656986388615,
      0.03967815754701858,
      0.03662959555345077
    ],
    "metrics": {
      "accuracy": 0.8720136518771331,
      "precision": 0.8703208556149733,
      "recall": 0.9247159090909091,
      "f1": 0.8966942148760331
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_18/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 18,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      3.5685476226344366,
      1.3589661282362742,
      0.770481439582371,
      0.31384348472683127,
      0.3021059457779465,
      0.19834493771592052,
      0.15310569691846737,
      0.11615048414871251,
      0.0962451342696835,
      0.08131322389299979,
      0.07136937347938781,
      0.064797365397599,
      0.057520505691165846,
      0.05213241971263066,
      0.04746401151832695
    ],
    "metrics": {
      "accuracy": 0.9069965870307167,
      "precision": 0.8136363636363636,
      "recall": 0.7246963562753036,
      "f1": 0.7665952890792291
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_18/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 18,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5110529056030283,
      0.11859291377113326,
      0.05830125557871953,
      0.039014519159659915,
      0.029517196494596415,
      0.023917678628261933,
      0.01958118794075195,
      0.016051664007485797,
      0.01306819051799528,
      0.011015805899345364,
      0.009546999790611539,
      0.008301730816476683,
      0.0071977661569903135,
      0.006252925978823724,
      0.005335124389316211
    ],
    "metrics": {
      "accuracy": 0.9650170648464164,
      "precision": 0.72,
      "recall": 0.7297297297297297,
      "f1": 0.7248322147651006
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_18/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 19,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9432308614487807,
      0.3476023680942003,
      0.2158646912476568,
      0.16147233390464072,
      0.12495468521392054,
      0.10462095673201498,
      0.08854007458329434,
      0.07719144557463618,
      0.06741091077920268,
      0.06012895497897654,
      0.055313774418742356,
      0.050512636118482626,
      0.046334930908265785,
      0.04170279211943208,
      0.03826414615554648
    ],
    "metrics": {
      "accuracy": 0.871160409556314,
      "precision": 0.879286694101509,
      "recall": 0.9105113636363636,
      "f1": 0.8946266573621773
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_19/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 19,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8051972340288266,
      0.24885149831179312,
      0.1402481076750945,
      0.08455563254360059,
      0.05774388628789743,
      0.04385492431391819,
      0.03659282239249488,
      0.028947914679424876,
      0.02430070243654765,
      0.020347257450840893,
      0.017956624645191804,
      0.015343343091955886,
      0.013202295179613735,
      0.011574198800833511,
      0.01053543234753881
    ],
    "metrics": {
      "accuracy": 0.9223549488054608,
      "precision": 0.8679245283018868,
      "recall": 0.7449392712550608,
      "f1": 0.8017429193899782
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_19/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 19,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.394109836443695,
      0.5411867761050796,
      0.25720525089767204,
      0.14783507420397768,
      0.07614145625427544,
      0.05064098914872785,
      0.04564182257342903,
      0.036088281638584206,
      0.029860987666442167,
      0.02587074088702502,
      0.022929365003236737,
      0.020055904346717845,
      0.01776142264007854,
      0.0158125711059572,
      0.014112787281023952
    ],
    "metrics": {
      "accuracy": 0.9633105802047781,
      "precision": 0.6781609195402298,
      "recall": 0.7972972972972973,
      "f1": 0.7329192546583851
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_19/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 20,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.6468333392024341,
      0.6047694088865576,
      0.367926454687693,
      0.2719830708798991,
      0.20511642619487316,
      0.15962711115007341,
      0.1316519730851476,
      0.11326616037189209,
      0.0970100565437978,
      0.086228243885554,
      0.07635909802616728,
      0.06855666734075706,
      0.06221154730575998,
      0.05711856299348992,
      0.053318886802907285
    ],
    "metrics": {
      "accuracy": 0.8575085324232082,
      "precision": 0.8633288227334236,
      "recall": 0.90625,
      "f1": 0.8842688842688843
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_20/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 20,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      4.914073234213671,
      1.3713790227732894,
      1.1867679502323383,
      0.4134831499672631,
      0.28072232382075063,
      0.24604758681219543,
      0.15408610699306385,
      0.11737104573981974,
      0.09281366163565685,
      0.07365033183738477,
      0.06457197600200618,
      0.05758559437033909,
      0.05098288554596981,
      0.046255527826693586,
      0.041754480007212345
    ],
    "metrics": {
      "accuracy": 0.9078498293515358,
      "precision": 0.8008658008658008,
      "recall": 0.7489878542510121,
      "f1": 0.7740585774058577
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_20/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 20,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.573158451625031,
      0.704770348425438,
      0.19435528506498506,
      0.14942365316958547,
      0.08462169952429653,
      0.06320208050133168,
      0.051164612369223046,
      0.04011953572209525,
      0.036485743170051425,
      0.03159306217251154,
      0.029723380640896472,
      0.02658611190948676,
      0.02455828930717092,
      0.02233032332031324,
      0.020991205858209155
    ],
    "metrics": {
      "accuracy": 0.9667235494880546,
      "precision": 0.7108433734939759,
      "recall": 0.7972972972972973,
      "f1": 0.7515923566878981
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_20/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 21,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.259768845153877,
      0.7018533313297765,
      0.3893963407154142,
      0.2784328081170929,
      0.18701350055144395,
      0.14980924803357593,
      0.12595364868298536,
      0.10851858218082296,
      0.09480197283860246,
      0.08517199843437206,
      0.07579931484847952,
      0.06842444894293104,
      0.06241461144576022,
      0.0574003088228774,
      0.052508717855299245
    ],
    "metrics": {
      "accuracy": 0.8668941979522184,
      "precision": 0.8784530386740331,
      "recall": 0.9034090909090909,
      "f1": 0.8907563025210085
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_21/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 21,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.3960335424848884,
      0.42866035863343793,
      0.20352061380104847,
      0.14256193232272446,
      0.1057500971586105,
      0.07364935714737912,
      0.05838813636275559,
      0.04830682684549199,
      0.0404176287192295,
      0.035109364133538004,
      0.030053275021752847,
      0.025902227659595718,
      0.022768277271488162,
      0.020034524683106528,
      0.018245756750862183
    ],
    "metrics": {
      "accuracy": 0.908703071672355,
      "precision": 0.7892561983471075,
      "recall": 0.7732793522267206,
      "f1": 0.7811860940695297
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_21/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 21,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      3.379107102021078,
      1.0856853354107467,
      0.7126342897055763,
      0.19808375812037782,
      0.1225177957651561,
      0.11484363997440172,
      0.07125557873071359,
      0.057013934932734725,
      0.04908179532674956,
      0.04096773258702917,
      0.03582883235740374,
      0.0323514585365231,
      0.02820860921113255,
      0.026102525732668132,
      0.023329892038931595
    ],
    "metrics": {
      "accuracy": 0.96160409556314,
      "precision": 0.6986301369863014,
      "recall": 0.6891891891891891,
      "f1": 0.6938775510204082
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_21/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 22,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      3.931430403142124,
      1.119850952807646,
      0.6026677829556587,
      0.3842006647292891,
      0.27905442308280676,
      0.21621596482528896,
      0.1877173680188977,
      0.15998239244907703,
      0.1442663304614199,
      0.12928967009608772,
      0.11086136300996693,
      0.10045983116686528,
      0.08872569132357226,
      0.08087093046555568,
      0.0736419453123064
    ],
    "metrics": {
      "accuracy": 0.8805460750853242,
      "precision": 0.8852459016393442,
      "recall": 0.9204545454545454,
      "f1": 0.9025069637883009
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_22/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 22,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      6.398333402800941,
      4.435713547957515,
      1.657913387255964,
      1.1587834029379396,
      0.6004898217787226,
      0.45517694377271223,
      0.3011654285814756,
      0.22513844796792237,
      0.1715822257550366,
      0.14647749489714498,
      0.11952057900624838,
      0.10695159178290857,
      0.09470318400599302,
      0.08515901419755022,
      0.07636991574103574
    ],
    "metrics": {
      "accuracy": 0.9035836177474402,
      "precision": 0.7863247863247863,
      "recall": 0.7449392712550608,
      "f1": 0.7650727650727651
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_22/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 22,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      4.162086762844865,
      3.0964568691381924,
      1.5439729962271447,
      0.37565631331533034,
      0.40874004652935036,
      0.18388467959685967,
      0.17262933280399348,
      0.11992477381152578,
      0.0903922242046438,
      0.08845348484160753,
      0.07492567170656639,
      0.0693639440612821,
      0.06275056138254742,
      0.056257326108930354,
      0.05202224549259933
    ],
    "metrics": {
      "accuracy": 0.96160409556314,
      "precision": 0.6705882352941176,
      "recall": 0.7702702702702703,
      "f1": 0.7169811320754716
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_22/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 23,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.373829370488236,
      0.6989683756293219,
      0.39258898088630756,
      0.2690083080060878,
      0.22267738905907278,
      0.1753657540250606,
      0.14652632649713418,
      0.12406859136272393,
      0.09960659374565128,
      0.08971405922573265,
      0.07547689561593028,
      0.06304786583989583,
      0.04912536159475066,
      0.04089793785425353,
      0.03275231705573
    ],
    "metrics": {
      "accuracy": 0.8822525597269625,
      "precision": 0.8887362637362637,
      "recall": 0.9190340909090909,
      "f1": 0.9036312849162011
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_23/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 23,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.221894698237865,
      0.6352656831023873,
      0.3332610353347333,
      0.20106613666078027,
      0.13289063816076485,
      0.10735999614325983,
      0.08526715656085387,
      0.06982651609654987,
      0.05898176668706053,
      0.04855389935850396,
      0.03832594735945063,
      0.032138827688205,
      0.025637295278210404,
      0.022015235853624398,
      0.018397627194310543
    ],
    "metrics": {
      "accuracy": 0.9197952218430034,
      "precision": 0.825531914893617,
      "recall": 0.7854251012145749,
      "f1": 0.8049792531120332
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_23/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 23,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0856571929917078,
      0.20477599020797888,
      0.11716255202417648,
      0.08558639196763021,
      0.06457402955340918,
      0.05641321108187738,
      0.042920404806645454,
      0.03389284982504916,
      0.024919080404206196,
      0.01985059767642102,
      0.01519494972304089,
      0.011159884634446775,
      0.006602095498743345,
      0.003944215233497474,
      0.002314970633077664
    ],
    "metrics": {
      "accuracy": 0.96160409556314,
      "precision": 0.6666666666666666,
      "recall": 0.7837837837837838,
      "f1": 0.7204968944099379
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_23/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 24,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.68194958737131,
      0.6112782232365244,
      0.5507320523696241,
      0.4995995554462405,
      0.45614383619150284,
      0.4192103649361456,
      0.38760564854312723,
      0.3606373876141179,
      0.3370891624921241,
      0.3165715129794978,
      0.2984622860445833,
      0.28239787805644895,
      0.26803631602498657,
      0.2551292544421311,
      0.24348065429924248
    ],
    "metrics": {
      "accuracy": 0.8754266211604096,
      "precision": 0.875,
      "recall": 0.9247159090909091,
      "f1": 0.899171270718232
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_24/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 24,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6370850807981152,
      0.5481718326189432,
      0.47759206580928676,
      0.4218128488139967,
      0.37764116829434974,
      0.3422120842455348,
      0.3130569304027755,
      0.28832671812817173,
      0.26720678833025985,
      0.24903065662201662,
      0.23306664160217147,
      0.2188893140957248,
      0.20627513468582845,
      0.19507862778229684,
      0.18481587364113142
    ],
    "metrics": {
      "accuracy": 0.8924914675767918,
      "precision": 0.9115646258503401,
      "recall": 0.5425101214574899,
      "f1": 0.6802030456852792
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_24/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 24,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6499039401323998,
      0.5475551478166011,
      0.4646471765369352,
      0.3999551470104671,
      0.3495562226874516,
      0.30976294832391277,
      0.27801836848793393,
      0.2519419544315632,
      0.23006635073454448,
      0.2112343841513922,
      0.195198684742919,
      0.1811907583298086,
      0.16886856192532423,
      0.15808333184713075,
      0.14846184062720613
    ],
    "metrics": {
      "accuracy": 0.9650170648464164,
      "precision": 0.8367346938775511,
      "recall": 0.5540540540540541,
      "f1": 0.6666666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/HUBERT_LARGE/layer_24/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6590299058936862,
      0.5617727779491732,
      0.4864462069507634,
      0.42852375565620837,
      0.3846538012298599,
      0.350820645780513,
      0.3245502819237022,
      0.3035346311889835,
      0.2865571140691815,
      0.272483137623952,
      0.2607287420306842,
      0.2506740136458348,
      0.24198835370877617,
      0.2343192205521988,
      0.22764634368362957
    ],
    "metrics": {
      "accuracy": 0.8404255319148937,
      "precision": 0.8181818181818182,
      "recall": 0.9,
      "f1": 0.8571428571428571
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_00/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6510399574490173,
      0.5414853678669294,
      0.45946378337817273,
      0.39985243089132927,
      0.35609935865377024,
      0.3233331868087915,
      0.2980306077349926,
      0.27791768761260666,
      0.26121071478255986,
      0.24737213981513775,
      0.23536800424835325,
      0.2250019376784996,
      0.21583064708322325,
      0.2077468232639242,
      0.20043608091938922
    ],
    "metrics": {
      "accuracy": 0.8404255319148937,
      "precision": 0.8409090909090909,
      "recall": 0.6166666666666667,
      "f1": 0.7115384615384616
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_00/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.645964851042396,
      0.5326906753420987,
      0.4454751578394614,
      0.3791253686502399,
      0.32884573082942786,
      0.29006011867145254,
      0.2594945009822417,
      0.23488466985710704,
      0.2144864106981411,
      0.19744926475313254,
      0.1829180896006613,
      0.17060313979889632,
      0.15992970990221284,
      0.1506029098714201,
      0.1423524740704457
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_00/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6726009776916655,
      0.5847801650216117,
      0.5150259580605884,
      0.4614517584659622,
      0.41860175320147835,
      0.38391098069861196,
      0.3556901606653609,
      0.33218645449516165,
      0.3123788539295625,
      0.2956881630373442,
      0.28145532980462834,
      0.26903694175193615,
      0.25808570869217773,
      0.24854549672676046,
      0.24002637014363842
    ],
    "metrics": {
      "accuracy": 0.8617021276595744,
      "precision": 0.8363636363636363,
      "recall": 0.92,
      "f1": 0.8761904761904762
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_01/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.631694409759073,
      0.5383882197316445,
      0.4682903248221273,
      0.4157966236929597,
      0.3765034925906157,
      0.3453811695033997,
      0.32030021241980466,
      0.29932206254969185,
      0.28139978144096417,
      0.26587953804506176,
      0.25244305992063476,
      0.2406209847728674,
      0.23012780111327355,
      0.22068705648931833,
      0.21222405993088075
    ],
    "metrics": {
      "accuracy": 0.851063829787234,
      "precision": 0.8809523809523809,
      "recall": 0.6166666666666667,
      "f1": 0.7254901960784313
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_01/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7028153778224829,
      0.5802014751194963,
      0.4840891496902098,
      0.41100233777511075,
      0.35567411231553697,
      0.3134362167694767,
      0.2803271476942135,
      0.25370693424103913,
      0.23174731534176174,
      0.21333868676006715,
      0.19754939821390052,
      0.18401858047969746,
      0.17214196110574856,
      0.16173287768266317,
      0.15260074966177442
    ],
    "metrics": {
      "accuracy": 0.9840425531914894,
      "precision": 1.0,
      "recall": 0.6666666666666666,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_01/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6521189378936193,
      0.5752396781819342,
      0.512474898507762,
      0.46122338838747345,
      0.41951801049347126,
      0.38504077278796084,
      0.3561502583354436,
      0.3317187407451388,
      0.3108287032954444,
      0.2930913134562922,
      0.27768073900057744,
      0.2644109084946319,
      0.2526505110010288,
      0.2422073416461088,
      0.23287882028120513
    ],
    "metrics": {
      "accuracy": 0.9148936170212766,
      "precision": 0.8962264150943396,
      "recall": 0.95,
      "f1": 0.9223300970873787
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_02/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6529222637218087,
      0.5695879050573553,
      0.5026918963523018,
      0.4488205327068011,
      0.4059635018263027,
      0.3712831435304337,
      0.3427061522810116,
      0.31861090882136295,
      0.298064996937937,
      0.2806577175816268,
      0.26543576033537425,
      0.25215040153603574,
      0.24038753881558403,
      0.2298190454865069,
      0.22036719134020838
    ],
    "metrics": {
      "accuracy": 0.8617021276595744,
      "precision": 0.925,
      "recall": 0.6166666666666667,
      "f1": 0.74
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_02/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6508692612893673,
      0.5497432618978947,
      0.46786611373862314,
      0.40380017784186684,
      0.35384847958777665,
      0.3145010822594087,
      0.28282067829268137,
      0.25698616824345355,
      0.23531297930323147,
      0.21704300594770767,
      0.20126645615425262,
      0.18753235669243132,
      0.17567584418163903,
      0.16514831277070618,
      0.1557654709175052
    ],
    "metrics": {
      "accuracy": 0.9840425531914894,
      "precision": 1.0,
      "recall": 0.6666666666666666,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_02/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6723984792966351,
      0.5940873140387994,
      0.5286846468281714,
      0.4748694164119907,
      0.4308759693110477,
      0.39432113413924114,
      0.36417639629529047,
      0.3385143388057794,
      0.31673668502501484,
      0.2981077891832299,
      0.28187538196420103,
      0.2677083654636751,
      0.2552468683398384,
      0.24416709798172884,
      0.2343342103014849
    ],
    "metrics": {
      "accuracy": 0.8936170212765957,
      "precision": 0.8703703703703703,
      "recall": 0.94,
      "f1": 0.9038461538461539
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_03/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6547630952560445,
      0.5715859482278912,
      0.5035421128947007,
      0.4494828176860608,
      0.40627913964786805,
      0.3714158453509861,
      0.3428202796801236,
      0.31878740959154883,
      0.2983799320152288,
      0.28062039751515205,
      0.2652800429528739,
      0.2517428558285359,
      0.23973158243625292,
      0.22892867842470166,
      0.21915548036718935
    ],
    "metrics": {
      "accuracy": 0.8563829787234043,
      "precision": 0.9459459459459459,
      "recall": 0.5833333333333334,
      "f1": 0.7216494845360825
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_03/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6124920091981775,
      0.5243070452421156,
      0.4524892989127765,
      0.3953241622904648,
      0.3494011944162326,
      0.3122774725231186,
      0.28183567137352855,
      0.2564837557203389,
      0.23487850990997752,
      0.21651430063471297,
      0.20065829886155526,
      0.18677675512618086,
      0.17466442108626726,
      0.16393198959499874,
      0.15445263251918154
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_03/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6527701787148631,
      0.5817018640561022,
      0.5240017019379564,
      0.47667154894164876,
      0.4378117668817664,
      0.4053992808967474,
      0.37768507440779925,
      0.3538030260305266,
      0.3330937941370426,
      0.3150144105622129,
      0.2988787385872522,
      0.2845086030868747,
      0.27170629739131447,
      0.26014424277422765,
      0.24961911458399053
    ],
    "metrics": {
      "accuracy": 0.8563829787234043,
      "precision": 0.8173913043478261,
      "recall": 0.94,
      "f1": 0.8744186046511628
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_04/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.648069287338534,
      0.5623303818576717,
      0.4938957947091036,
      0.44021786451339723,
      0.3980491184337923,
      0.36456517870863964,
      0.33728576859205844,
      0.31465862380781134,
      0.2951066247931875,
      0.2782626461085114,
      0.2633768727001457,
      0.250027696613119,
      0.23814321726048795,
      0.22729858813544088,
      0.21750222625237947
    ],
    "metrics": {
      "accuracy": 0.8085106382978723,
      "precision": 0.8529411764705882,
      "recall": 0.48333333333333334,
      "f1": 0.6170212765957447
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_04/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.639596594403568,
      0.5429542756773521,
      0.46526686128725936,
      0.4045206833389665,
      0.35688875267181247,
      0.3191902631418866,
      0.28898977355409017,
      0.26391815420343506,
      0.2427441058141552,
      0.22464343413730278,
      0.2089370383296649,
      0.1950423246212648,
      0.1827916974238707,
      0.17187316355884782,
      0.1621482213745029
    ],
    "metrics": {
      "accuracy": 0.9840425531914894,
      "precision": 1.0,
      "recall": 0.6666666666666666,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_04/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6894018044717403,
      0.6186774180933853,
      0.5596005228740536,
      0.510595097574879,
      0.4701448141819892,
      0.436056449155039,
      0.4073669473277688,
      0.3824633207314868,
      0.3607780157811103,
      0.3415726374682221,
      0.32464433084075955,
      0.30934404926854364,
      0.2956144183992237,
      0.28324155819305813,
      0.27195370780744516
    ],
    "metrics": {
      "accuracy": 0.8563829787234043,
      "precision": 0.8173913043478261,
      "recall": 0.94,
      "f1": 0.8744186046511628
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_05/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6848112217028831,
      0.5996901822373606,
      0.5297601373696421,
      0.473588530981084,
      0.4278511258538522,
      0.3913807547942808,
      0.36120513088637013,
      0.33618542407903834,
      0.31489645054507287,
      0.2966526867061499,
      0.2805916973511483,
      0.2663974794087983,
      0.25362011198559714,
      0.24221169902516168,
      0.23180450262056473
    ],
    "metrics": {
      "accuracy": 0.8085106382978723,
      "precision": 0.875,
      "recall": 0.4666666666666667,
      "f1": 0.6086956521739131
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_05/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6696768939416349,
      0.5781296054627181,
      0.5031284555969969,
      0.4419052010798234,
      0.39257207219950274,
      0.3527570704960288,
      0.31996483819330385,
      0.2926557174683247,
      0.2693419741434654,
      0.24934208129324717,
      0.23188316642529425,
      0.21653007933454124,
      0.20293534324458914,
      0.19078692254097332,
      0.17995975192739594
    ],
    "metrics": {
      "accuracy": 0.9840425531914894,
      "precision": 1.0,
      "recall": 0.6666666666666666,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_05/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.659613934738003,
      0.5965588222564133,
      0.5440657659282457,
      0.500462717195798,
      0.4641421046408196,
      0.43316574787211704,
      0.40663378141042894,
      0.3832921100969831,
      0.3626807990130849,
      0.34434870409052154,
      0.32789954695865375,
      0.3130372741814491,
      0.29954557491262174,
      0.2872827908085706,
      0.2761522934569078
    ],
    "metrics": {
      "accuracy": 0.824468085106383,
      "precision": 0.7723577235772358,
      "recall": 0.95,
      "f1": 0.852017937219731
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_06/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6250945986655776,
      0.55086959375258,
      0.49109861930263876,
      0.4441003073316899,
      0.4062992687820601,
      0.3757211733210827,
      0.3503682781084683,
      0.3286509320553259,
      0.3097898375090394,
      0.293164892067525,
      0.27843591467707446,
      0.26518070930061444,
      0.25323191226867264,
      0.24228489884769586,
      0.23237794388080682
    ],
    "metrics": {
      "accuracy": 0.776595744680851,
      "precision": 0.875,
      "recall": 0.35,
      "f1": 0.5
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_06/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6443018647134697,
      0.5566157950277845,
      0.48532392836939864,
      0.4282446091052248,
      0.38241294351562644,
      0.34514232426684943,
      0.31474741831165953,
      0.2890816353113837,
      0.26723007984961356,
      0.24829209040619107,
      0.23164345870480985,
      0.21698315901044496,
      0.20378917413548403,
      0.192073506313712,
      0.1814868930466424
    ],
    "metrics": {
      "accuracy": 0.9574468085106383,
      "precision": 0.5555555555555556,
      "recall": 0.5555555555555556,
      "f1": 0.5555555555555556
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_06/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6611047805221739,
      0.5984584797011342,
      0.5479365581092935,
      0.5052540948242933,
      0.46961089883644325,
      0.43975324877974536,
      0.4137855634664135,
      0.39087679923131885,
      0.3705900317454118,
      0.3523557508243752,
      0.3359954889730859,
      0.32114213282239956,
      0.3076447591205254,
      0.2952461392041714,
      0.2839365716575789
    ],
    "metrics": {
      "accuracy": 0.8351063829787234,
      "precision": 0.7948717948717948,
      "recall": 0.93,
      "f1": 0.8571428571428571
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_07/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6693415969019679,
      0.5814845067979165,
      0.5118567495553937,
      0.45766921855971865,
      0.4161869837318103,
      0.38285910598195527,
      0.35612681998601836,
      0.33382738085372604,
      0.31464215017845326,
      0.2979422092910172,
      0.283145330037277,
      0.2699589173182786,
      0.25787487097743955,
      0.24707623864259556,
      0.23714854704656563
    ],
    "metrics": {
      "accuracy": 0.7925531914893617,
      "precision": 0.7692307692307693,
      "recall": 0.5,
      "f1": 0.6060606060606061
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_07/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6490510428597465,
      0.5581908251681762,
      0.48483890124954665,
      0.427103975056972,
      0.3815085973890801,
      0.3447699081236337,
      0.31457918599700674,
      0.28927029633459045,
      0.26749337766727965,
      0.24862659287342465,
      0.2320240796242239,
      0.2172766727256334,
      0.20426894415322508,
      0.1925872055668497,
      0.18207135781586722
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_07/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6948755688837371,
      0.6159147236432235,
      0.5516275329665432,
      0.4990498894193213,
      0.4565450843605687,
      0.42120668089689006,
      0.391569585112001,
      0.36637129405688107,
      0.34468720209645787,
      0.3256846736255379,
      0.30893357644937786,
      0.2940499428556334,
      0.2807872692533969,
      0.2688446871513105,
      0.2580303878340098
    ],
    "metrics": {
      "accuracy": 0.8297872340425532,
      "precision": 0.788135593220339,
      "recall": 0.93,
      "f1": 0.8532110091743119
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_08/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6745793050000028,
      0.5821351311480826,
      0.5092905239983311,
      0.451151505463032,
      0.4064902485991721,
      0.37071413775731266,
      0.3419649607596656,
      0.318091549205654,
      0.29796115230852577,
      0.2806780030421883,
      0.2656136316068894,
      0.25223780967679016,
      0.24021462457183174,
      0.22946778500410808,
      0.21954570742154217
    ],
    "metrics": {
      "accuracy": 0.8297872340425532,
      "precision": 0.7592592592592593,
      "recall": 0.6833333333333333,
      "f1": 0.7192982456140351
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_08/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6953110233165787,
      0.5940554012395589,
      0.511339685096451,
      0.4458552978785224,
      0.3936676882295974,
      0.3518411574307017,
      0.31734870892692274,
      0.2887068535960335,
      0.26411446092780705,
      0.2432217117384214,
      0.22494371536149688,
      0.20908978358993757,
      0.19520395888283829,
      0.18284681876789152,
      0.17198046647415766
    ],
    "metrics": {
      "accuracy": 0.8563829787234043,
      "precision": 0.2,
      "recall": 0.6666666666666666,
      "f1": 0.3076923076923077
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_08/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7076000376138221,
      0.6183656176613691,
      0.545872201047139,
      0.486460511191518,
      0.43910402705993806,
      0.40059725641416905,
      0.3687119690005026,
      0.3420668872375942,
      0.3195795770995368,
      0.30026492177259023,
      0.2834529125155042,
      0.26878549685723874,
      0.2558874706059812,
      0.24429024466592694,
      0.23396161490340214
    ],
    "metrics": {
      "accuracy": 0.8829787234042553,
      "precision": 0.8545454545454545,
      "recall": 0.94,
      "f1": 0.8952380952380953
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_09/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.667129047307502,
      0.5735589130394052,
      0.4997986036531204,
      0.4425995163511254,
      0.3977571866786307,
      0.3624131089393812,
      0.33398288671847537,
      0.3101695323951021,
      0.28998333267680565,
      0.27283109013124063,
      0.25768208845052254,
      0.24434418942055897,
      0.23246533243549075,
      0.22182994405769765,
      0.2121942836432035
    ],
    "metrics": {
      "accuracy": 0.7978723404255319,
      "precision": 0.7291666666666666,
      "recall": 0.5833333333333334,
      "f1": 0.6481481481481481
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_09/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6654786887540528,
      0.5574192280026061,
      0.4712990151843747,
      0.40358567326040534,
      0.35035787836563637,
      0.3087946124955559,
      0.2750726976671811,
      0.24770620939674906,
      0.22483752857268724,
      0.20575971487648737,
      0.1894812358417788,
      0.17542723616489173,
      0.1633499753128742,
      0.1528231637914083,
      0.1435754067398598
    ],
    "metrics": {
      "accuracy": 0.8617021276595744,
      "precision": 0.20689655172413793,
      "recall": 0.6666666666666666,
      "f1": 0.3157894736842105
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_09/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6282932008273377,
      0.5446284794744444,
      0.4786406856940634,
      0.4271966440910707,
      0.3865600582394291,
      0.3532581646108564,
      0.32609910479939913,
      0.3041625305793717,
      0.2854187076047673,
      0.2695659286082972,
      0.2560444577248912,
      0.24432226403701257,
      0.23396165159923396,
      0.22483094396017975,
      0.21656606859149832
    ],
    "metrics": {
      "accuracy": 0.8882978723404256,
      "precision": 0.8910891089108911,
      "recall": 0.9,
      "f1": 0.8955223880597015
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_10/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6231458058130473,
      0.5242375963902693,
      0.4502455995923777,
      0.3963862169450309,
      0.35683933983863264,
      0.3260773466001886,
      0.3016382524879007,
      0.28132028914348295,
      0.26433487345158185,
      0.2498752098653559,
      0.23720410971691933,
      0.22593435078190058,
      0.21605724578568297,
      0.20703829074157906,
      0.1988556422165237
    ],
    "metrics": {
      "accuracy": 0.776595744680851,
      "precision": 0.8461538461538461,
      "recall": 0.36666666666666664,
      "f1": 0.5116279069767442
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_10/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5932937010748698,
      0.4769598885130536,
      0.3901818390330361,
      0.3263846307638614,
      0.2795636235171612,
      0.24375469634208527,
      0.21571511359715556,
      0.1931895597253482,
      0.17466269486646513,
      0.15938062591077157,
      0.14675449274647662,
      0.135742503184151,
      0.1264790674949574,
      0.11848921466180797,
      0.11150863426128499
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_10/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6740156322993249,
      0.6197584328909689,
      0.5760665396403133,
      0.5406410759474831,
      0.5118788459971843,
      0.4889308262611475,
      0.4702810545421182,
      0.45474051210335414,
      0.4415178115411983,
      0.4305099870758611,
      0.42077348458247266,
      0.41247209822328434,
      0.40505079630973945,
      0.3984922549841111,
      0.3924362602526792
    ],
    "metrics": {
      "accuracy": 0.6382978723404256,
      "precision": 0.6,
      "recall": 0.96,
      "f1": 0.7384615384615385
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_11/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6503484116992674,
      0.5671410633676748,
      0.5184439846987453,
      0.490010338234303,
      0.4705448516451383,
      0.45471727492944725,
      0.44109114426602775,
      0.4285168098883711,
      0.4173506978480945,
      0.4076195514658798,
      0.39856838922519505,
      0.3904642707369287,
      0.3831780958128416,
      0.3764044688037711,
      0.3702131469388304
    ],
    "metrics": {
      "accuracy": 0.7021276595744681,
      "precision": 1.0,
      "recall": 0.06666666666666667,
      "f1": 0.125
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_11/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.661759644140498,
      0.5677678282226251,
      0.5004335448716717,
      0.44813081570944036,
      0.4040897012937967,
      0.3656677889225505,
      0.3327610676874415,
      0.3038362060623093,
      0.2795419187416646,
      0.2584362316635515,
      0.24013831402068095,
      0.22432766930351483,
      0.21037143266500224,
      0.19812371087515213,
      0.18734699268794594
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_11/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6699024204376351,
      0.5861884200116287,
      0.5413011785070049,
      0.505930364541365,
      0.48222198656402143,
      0.46081609392890527,
      0.44306314036427275,
      0.42781792651551875,
      0.4144768288144977,
      0.4030267949463354,
      0.39244130403393956,
      0.3831121639814843,
      0.37467111539651726,
      0.36716154210633617,
      0.36019370728313843
    ],
    "metrics": {
      "accuracy": 0.7606382978723404,
      "precision": 0.7099236641221374,
      "recall": 0.93,
      "f1": 0.8051948051948052
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_12/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5872684043968684,
      0.4439215850247417,
      0.4215547300865345,
      0.41408128018738255,
      0.40056859008387186,
      0.38801369715870765,
      0.37864618430521874,
      0.37026112823694196,
      0.361772983534018,
      0.35433825010352593,
      0.34736201908818326,
      0.34061719038212473,
      0.3343840806062187,
      0.32855743241436103,
      0.3231684430114817
    ],
    "metrics": {
      "accuracy": 0.7180851063829787,
      "precision": 1.0,
      "recall": 0.11666666666666667,
      "f1": 0.208955223880597
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_12/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5515344094489966,
      0.32795617815052974,
      0.24417295847260337,
      0.21015894190165924,
      0.18819827749596876,
      0.1703840164873685,
      0.15619663206793988,
      0.14502862153705234,
      0.13623491746116345,
      0.1285397446631913,
      0.12199312166619647,
      0.11642763416234851,
      0.11158964638862774,
      0.10736439191838394,
      0.1035551329978706
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_BASE/layer_12/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6265318239990033,
      0.4693495531161406,
      0.3757696952681132,
      0.31644701236998274,
      0.27880335549238316,
      0.25413642433211414,
      0.2375181019306183,
      0.22505621054000802,
      0.21469987260998122,
      0.20662745710390096,
      0.2000306949473484,
      0.19434175601956588,
      0.18926027587246036,
      0.1845398232629755,
      0.18085514854361145
    ],
    "metrics": {
      "accuracy": 0.8935960591133005,
      "precision": 0.9202551834130781,
      "recall": 0.9086614173228347,
      "f1": 0.9144215530903328
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_00/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6117232513559823,
      0.4375542406230092,
      0.34392921769387835,
      0.28902257178959095,
      0.2532049267163237,
      0.22825476768274386,
      0.2104417642067674,
      0.19650506172483978,
      0.1853848703845386,
      0.17646166520435724,
      0.16892638847520808,
      0.16254316631941915,
      0.1569446901329006,
      0.15187666550732715,
      0.14725467708797665
    ],
    "metrics": {
      "accuracy": 0.9123152709359605,
      "precision": 0.6934306569343066,
      "recall": 0.6690140845070423,
      "f1": 0.6810035842293907
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_00/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.585936210591377,
      0.3989785841792574,
      0.29700487107451273,
      0.23855476396731062,
      0.19994166564413055,
      0.17140394247800028,
      0.15071733958007885,
      0.1352401804313105,
      0.12332846004299179,
      0.11374763751459253,
      0.10567505163581747,
      0.09897331903763425,
      0.09323977782620617,
      0.08833182119761808,
      0.08411948462932724
    ],
    "metrics": {
      "accuracy": 0.9399014778325123,
      "precision": 0.8,
      "recall": 0.5660377358490566,
      "f1": 0.6629834254143646
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_00/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6098012864094362,
      0.45930851027575886,
      0.3692081094778806,
      0.31292376389463855,
      0.27671887387529304,
      0.2519855523291057,
      0.23338324080874054,
      0.2196153825835178,
      0.20909437580947401,
      0.20078267360988417,
      0.1938506899860757,
      0.18791295256145774,
      0.18262575625382632,
      0.17799163737290455,
      0.17373178382494442
    ],
    "metrics": {
      "accuracy": 0.8926108374384236,
      "precision": 0.9096573208722741,
      "recall": 0.9196850393700787,
      "f1": 0.9146436961628818
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_01/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6012108278901953,
      0.44421261993141387,
      0.35405935006128453,
      0.2992583734011716,
      0.2613818155679016,
      0.2338581777923325,
      0.21328210782806628,
      0.19759784729692084,
      0.185484885806192,
      0.17537915082519404,
      0.1666089409482446,
      0.1589492357833894,
      0.1525099626621051,
      0.1468001086213252,
      0.14176815536874152
    ],
    "metrics": {
      "accuracy": 0.9182266009852217,
      "precision": 0.7153284671532847,
      "recall": 0.6901408450704225,
      "f1": 0.7025089605734767
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_01/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6273682059508612,
      0.42716990839741564,
      0.3109939531276101,
      0.2452803836800055,
      0.20339688520022045,
      0.17368015382758797,
      0.15201963773229446,
      0.1355987249071248,
      0.12279342642451258,
      0.11263142230190398,
      0.10424096614865384,
      0.097469756486013,
      0.09168037430401324,
      0.08680908626301467,
      0.08256342345822881
    ],
    "metrics": {
      "accuracy": 0.9320197044334976,
      "precision": 0.7534246575342466,
      "recall": 0.5188679245283019,
      "f1": 0.6145251396648045
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_01/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6357857071131551,
      0.49014052776748784,
      0.3999976160783847,
      0.3395340394940733,
      0.2971303879389142,
      0.2674230868879117,
      0.2460112029330552,
      0.2298036543038413,
      0.21676798031931108,
      0.2062250341569948,
      0.19749565864203708,
      0.19007142796245638,
      0.18356732650972138,
      0.17785026457088476,
      0.17283237962016107
    ],
    "metrics": {
      "accuracy": 0.8985221674876848,
      "precision": 0.9208860759493671,
      "recall": 0.9165354330708662,
      "f1": 0.9187056037884768
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_02/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6023874853786669,
      0.44117480830142375,
      0.35577505686606725,
      0.3068172296328558,
      0.2711044400765295,
      0.24283565092945364,
      0.2212865404805318,
      0.20391809991522178,
      0.19006582257902854,
      0.17880024322182186,
      0.16922879633480822,
      0.16113411877459105,
      0.15416600411948736,
      0.1478461675242704,
      0.14240145542119678
    ],
    "metrics": {
      "accuracy": 0.9211822660098522,
      "precision": 0.746031746031746,
      "recall": 0.6619718309859155,
      "f1": 0.7014925373134329
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_02/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5662561899737308,
      0.38015466048446717,
      0.280749061216608,
      0.22614702664088673,
      0.19132718719603942,
      0.16434485779409594,
      0.1436130917674947,
      0.12796668122184574,
      0.11595995983010844,
      0.10617010180226984,
      0.09822319712169943,
      0.09154443466349652,
      0.08603352912988028,
      0.08105257933242169,
      0.07671340502943029
    ],
    "metrics": {
      "accuracy": 0.9369458128078818,
      "precision": 0.7763157894736842,
      "recall": 0.5566037735849056,
      "f1": 0.6483516483516484
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_02/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6187264657086613,
      0.47825375574117224,
      0.3894401810340934,
      0.33047580258337744,
      0.2889587536578033,
      0.25980918399184694,
      0.23886717219431974,
      0.22278092773502223,
      0.21039268850784884,
      0.20025849459574163,
      0.19144337019596733,
      0.18357261826291968,
      0.17684057664507974,
      0.17093770870541602,
      0.16567552312589418
    ],
    "metrics": {
      "accuracy": 0.8955665024630541,
      "precision": 0.911353032659409,
      "recall": 0.9228346456692913,
      "f1": 0.917057902973396
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_03/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6210175611966204,
      0.46790984150775583,
      0.37654985922525464,
      0.3198981188340861,
      0.2789176021256275,
      0.2470956744662282,
      0.22250757724294373,
      0.20353769235663796,
      0.1886193022585972,
      0.17595642525238345,
      0.16583449672959188,
      0.15713259604994279,
      0.1495703248972708,
      0.14297211442627736,
      0.13697928560902867
    ],
    "metrics": {
      "accuracy": 0.9231527093596059,
      "precision": 0.7711864406779662,
      "recall": 0.6408450704225352,
      "f1": 0.7
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_03/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6441262485908339,
      0.4552863422853465,
      0.3406228288884308,
      0.2712129632191645,
      0.22545080693474767,
      0.1916551098516443,
      0.16616414042390945,
      0.14623300941697118,
      0.13068437735624922,
      0.11822438876549624,
      0.10813514421025802,
      0.0999311938592932,
      0.09300933446002468,
      0.08713508973986818,
      0.08198437715501336
    ],
    "metrics": {
      "accuracy": 0.9310344827586207,
      "precision": 0.7727272727272727,
      "recall": 0.4811320754716981,
      "f1": 0.5930232558139535
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_03/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6547715615367625,
      0.520446469314871,
      0.42725116602271546,
      0.3626049592554404,
      0.3168114033762438,
      0.2838428818783271,
      0.258502298238535,
      0.2387987697223547,
      0.22258469437628242,
      0.20958427531732415,
      0.19834212305803378,
      0.18899866783387773,
      0.18101004054176512,
      0.1739694036027401,
      0.1676720323324864
    ],
    "metrics": {
      "accuracy": 0.8857142857142857,
      "precision": 0.8986175115207373,
      "recall": 0.9212598425196851,
      "f1": 0.9097978227060654
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_04/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6501878037677247,
      0.5028996931879144,
      0.4064750666763644,
      0.34278174204509343,
      0.297529871840226,
      0.26344605252518216,
      0.23674687669713082,
      0.21576501454672986,
      0.19890795233672345,
      0.18473118754965448,
      0.17283686907172532,
      0.16275312229371797,
      0.1540016038059528,
      0.14653879286427246,
      0.1398980420918676
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.8303571428571429,
      "recall": 0.6549295774647887,
      "f1": 0.7322834645669292
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_04/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6194455029891799,
      0.4525558629194455,
      0.3416694193665671,
      0.2693637994105136,
      0.22096616187419257,
      0.18678373022422895,
      0.16165540044575186,
      0.14260943307440696,
      0.12748451253548884,
      0.11553045777072536,
      0.10556949993745111,
      0.09747164371601433,
      0.09060165819781639,
      0.08486706573629643,
      0.07985738177997914
    ],
    "metrics": {
      "accuracy": 0.9359605911330049,
      "precision": 0.7808219178082192,
      "recall": 0.5377358490566038,
      "f1": 0.6368715083798883
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_04/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6566023455762466,
      0.534262663835964,
      0.4485014657399661,
      0.38571208512353766,
      0.3386206198762328,
      0.30319945388718655,
      0.27568543667278134,
      0.25390618626760975,
      0.23614763784276482,
      0.22127558095303268,
      0.20878461288117967,
      0.19817833566929824,
      0.18904533295420067,
      0.18100991785691387,
      0.17376630710762953
    ],
    "metrics": {
      "accuracy": 0.8719211822660099,
      "precision": 0.8819969742813918,
      "recall": 0.9181102362204724,
      "f1": 0.8996913580246914
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_05/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6109180040636881,
      0.4828111637001883,
      0.3962900347326601,
      0.3357221974890648,
      0.29157554390027585,
      0.2577011268885182,
      0.2315838061128627,
      0.21063313275327972,
      0.19366195609695033,
      0.17947185038694716,
      0.16757004297341005,
      0.1572584088076515,
      0.14818574876996618,
      0.14036788509080284,
      0.13352717850512086
    ],
    "metrics": {
      "accuracy": 0.9428571428571428,
      "precision": 0.8333333333333334,
      "recall": 0.7394366197183099,
      "f1": 0.7835820895522388
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_05/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6041706981751397,
      0.45105499314799535,
      0.34537843292439746,
      0.27345026504465086,
      0.22372218296138202,
      0.18845082499148774,
      0.16238290128450314,
      0.14251242726628469,
      0.12674252454841567,
      0.11416922529483436,
      0.10399330356197013,
      0.0956775214863616,
      0.08866049793453427,
      0.08279275618844416,
      0.0777426183553944
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.7567567567567568,
      "recall": 0.5283018867924528,
      "f1": 0.6222222222222222
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_05/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6480867642444917,
      0.5238115767197595,
      0.43886994570906473,
      0.3779052598159399,
      0.3321755767363921,
      0.2969500654952348,
      0.2693038264800307,
      0.2475090738396235,
      0.22969665877376566,
      0.21482192083078738,
      0.202222438168988,
      0.1915338647249993,
      0.18245012152558218,
      0.1743902572304258,
      0.1672697591071644
    ],
    "metrics": {
      "accuracy": 0.8916256157635468,
      "precision": 0.9019908116385911,
      "recall": 0.9275590551181102,
      "f1": 0.9145962732919255
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_06/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6170441999990194,
      0.4847700937302819,
      0.3971117281352384,
      0.336155107377969,
      0.2911991259728112,
      0.2561371440537418,
      0.22864538052240568,
      0.2072060793060345,
      0.189540944700426,
      0.17494772811345446,
      0.1627193246521778,
      0.15236908472310803,
      0.1431629266022315,
      0.1353174331239386,
      0.12831923157554584
    ],
    "metrics": {
      "accuracy": 0.9349753694581281,
      "precision": 0.8275862068965517,
      "recall": 0.676056338028169,
      "f1": 0.7441860465116279
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_06/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5743431938487077,
      0.43214605802314104,
      0.33460109123232623,
      0.26686628393189066,
      0.21908792708058766,
      0.18457521471785707,
      0.15912617033868615,
      0.13999429341828723,
      0.12497776439645614,
      0.11302428364423503,
      0.10338051107781746,
      0.09539423207249338,
      0.08870256763581094,
      0.08286399598597159,
      0.07796262493589248
    ],
    "metrics": {
      "accuracy": 0.9349753694581281,
      "precision": 0.7631578947368421,
      "recall": 0.5471698113207547,
      "f1": 0.6373626373626373
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_06/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6083026666720488,
      0.49951554454264546,
      0.42275956360587125,
      0.36697726905180805,
      0.32449677343844047,
      0.2919917635310059,
      0.266456565830516,
      0.24554834885940657,
      0.22843798485654213,
      0.21394019726240734,
      0.20169797412576437,
      0.1910798635344096,
      0.18179692100950226,
      0.1734108291091681,
      0.16610566565039414
    ],
    "metrics": {
      "accuracy": 0.8906403940886699,
      "precision": 0.899390243902439,
      "recall": 0.9291338582677166,
      "f1": 0.9140201394268009
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_07/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7066748184510545,
      0.5519591951634415,
      0.445967938431082,
      0.3737593789840339,
      0.322387275884026,
      0.2835813225553967,
      0.25346779598753866,
      0.22940680529932567,
      0.20950338980002417,
      0.19250403873808167,
      0.1784318331123389,
      0.16629547759106283,
      0.15576253201492604,
      0.14643913274656703,
      0.13828196376149343
    ],
    "metrics": {
      "accuracy": 0.9438423645320198,
      "precision": 0.8632478632478633,
      "recall": 0.7112676056338029,
      "f1": 0.7799227799227799
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_07/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6449657107324152,
      0.4888351146534209,
      0.37956216980876023,
      0.3025355693541075,
      0.2477280056377527,
      0.2082297045108024,
      0.17901871394252514,
      0.15656027583369259,
      0.13906659093424883,
      0.12513491759009637,
      0.11381290984285836,
      0.10453168253654258,
      0.09675777549971504,
      0.09017886216042775,
      0.08451348527894456
    ],
    "metrics": {
      "accuracy": 0.9310344827586207,
      "precision": 0.75,
      "recall": 0.5094339622641509,
      "f1": 0.6067415730337079
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_07/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6229615523544375,
      0.5098929620515606,
      0.42927851384696536,
      0.37122132720379286,
      0.32783406251355224,
      0.29408820041989353,
      0.2675842291595533,
      0.24576694912527405,
      0.22782532054301444,
      0.21282901965349996,
      0.2002614958547159,
      0.1893682760792756,
      0.17954526573337015,
      0.1709510969735909,
      0.16332047559382842
    ],
    "metrics": {
      "accuracy": 0.8955665024630541,
      "precision": 0.9038167938931297,
      "recall": 0.9322834645669291,
      "f1": 0.9178294573643411
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_08/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6453497424020002,
      0.5060247211410068,
      0.4127598847543764,
      0.3492263140440648,
      0.3034273723816277,
      0.26860029071652,
      0.24050070651680477,
      0.2178217191527755,
      0.199207906412616,
      0.18357995396010432,
      0.17051243124080828,
      0.15916558114032667,
      0.14927300500407442,
      0.14054322550666629,
      0.13273581747285548
    ],
    "metrics": {
      "accuracy": 0.9280788177339901,
      "precision": 0.7633587786259542,
      "recall": 0.704225352112676,
      "f1": 0.7326007326007326
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_08/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6372964367311748,
      0.4811342956947158,
      0.37187254172943307,
      0.29654798969997925,
      0.2441389248146575,
      0.20578630980197082,
      0.1773041345240997,
      0.15577331914300735,
      0.1387527864808191,
      0.12527482673071758,
      0.11439547649380903,
      0.10513554018124979,
      0.09730764340165579,
      0.0907224493591409,
      0.0850558351446717
    ],
    "metrics": {
      "accuracy": 0.9300492610837439,
      "precision": 0.7536231884057971,
      "recall": 0.49056603773584906,
      "f1": 0.5942857142857143
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_08/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6314832043779854,
      0.5204650663437935,
      0.4416276154260556,
      0.38364269137382506,
      0.3379712995234619,
      0.30237552696978287,
      0.2739688112134748,
      0.2513877695947473,
      0.2326124849907249,
      0.217100201642084,
      0.2037707669335389,
      0.19229513086440492,
      0.18220094685078989,
      0.17337904435445728,
      0.1656597534044958
    ],
    "metrics": {
      "accuracy": 0.8995073891625616,
      "precision": 0.9068702290076336,
      "recall": 0.9354330708661417,
      "f1": 0.9209302325581395
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_09/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6620906804407072,
      0.5263302507658084,
      0.433878010808596,
      0.368704766926673,
      0.32129431804461495,
      0.28423890078497066,
      0.2541207069175065,
      0.2298913954367598,
      0.21017183492223313,
      0.1939685922250193,
      0.1798599086392289,
      0.16784880678904684,
      0.15728446320318448,
      0.14807952946242864,
      0.13980196998390135
    ],
    "metrics": {
      "accuracy": 0.929064039408867,
      "precision": 0.8240740740740741,
      "recall": 0.6267605633802817,
      "f1": 0.712
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_09/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.560168796992368,
      0.42827496569902945,
      0.3372489743285562,
      0.273334724420986,
      0.22730563291222106,
      0.1933003851168704,
      0.16770708920057462,
      0.1482815857326555,
      0.1328985858904688,
      0.12061094172360824,
      0.11038702709027605,
      0.10182632472458969,
      0.09463692466803204,
      0.08833828699927251,
      0.08291537063273696
    ],
    "metrics": {
      "accuracy": 0.9359605911330049,
      "precision": 0.8059701492537313,
      "recall": 0.5094339622641509,
      "f1": 0.6242774566473989
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_09/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6855522242609484,
      0.5604846431938235,
      0.47248090801146553,
      0.4088829189291291,
      0.3608417243343311,
      0.3239630905875209,
      0.2946244245585973,
      0.2709594813905594,
      0.2512162260896942,
      0.23475296101081405,
      0.22048199128080934,
      0.20811545072004736,
      0.1973416329255725,
      0.1878421712780263,
      0.17933989364519673
    ],
    "metrics": {
      "accuracy": 0.8955665024630541,
      "precision": 0.8989441930618401,
      "recall": 0.9385826771653544,
      "f1": 0.9183359013867488
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_10/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6381461357806197,
      0.5036201830550905,
      0.4140414746349208,
      0.3513763169502618,
      0.3053935643460942,
      0.26997568032748154,
      0.24220429502035443,
      0.21946105531047916,
      0.2007177408051953,
      0.18508183311392395,
      0.1717878591816181,
      0.16031061545055658,
      0.15051995882779937,
      0.14189485830778562,
      0.13428081722718527
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.8245614035087719,
      "recall": 0.6619718309859155,
      "f1": 0.734375
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_10/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6820674788918851,
      0.5224474517427323,
      0.4092043854853453,
      0.3292697368731459,
      0.27258358003360084,
      0.23125128097151124,
      0.19999451126253176,
      0.17591762056476193,
      0.15704282541189168,
      0.14192980347082557,
      0.12980058676153008,
      0.11967521065490068,
      0.11107623827259296,
      0.10366565211162673,
      0.09718866790760917
    ],
    "metrics": {
      "accuracy": 0.9270935960591133,
      "precision": 0.7352941176470589,
      "recall": 0.4716981132075472,
      "f1": 0.5747126436781609
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_10/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6290111662278215,
      0.5249904886837481,
      0.452291475785406,
      0.3981505981277561,
      0.35623041997325716,
      0.32296375777582714,
      0.2958441174839342,
      0.27319712189756273,
      0.25413784729807,
      0.2384521513434328,
      0.2247177100495288,
      0.21298616977609755,
      0.2025408721614082,
      0.1932525912728006,
      0.1849890736083905
    ],
    "metrics": {
      "accuracy": 0.8945812807881773,
      "precision": 0.8987915407854985,
      "recall": 0.937007874015748,
      "f1": 0.9175019275250579
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_11/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6060848758821672,
      0.48556914522707295,
      0.40530609447209787,
      0.34790133997343914,
      0.3048905249530259,
      0.27085142774595117,
      0.24374083178195266,
      0.2217239982533653,
      0.20316504771689628,
      0.1876464448972422,
      0.1742670804674936,
      0.1627375236343479,
      0.1526556001805863,
      0.143789430222683,
      0.13608078845980426
    ],
    "metrics": {
      "accuracy": 0.9399014778325123,
      "precision": 0.8715596330275229,
      "recall": 0.6690140845070423,
      "f1": 0.7569721115537849
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_11/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6798898522873664,
      0.5224756781414275,
      0.41213625073432925,
      0.3346883039725454,
      0.27918774227191206,
      0.2385019933005119,
      0.20793054242543565,
      0.18385800824105905,
      0.16481487820353205,
      0.14949378568544944,
      0.13693560434510504,
      0.12622475867208682,
      0.11718836793691498,
      0.10940985533504274,
      0.10271354833633285
    ],
    "metrics": {
      "accuracy": 0.9320197044334976,
      "precision": 0.7936507936507936,
      "recall": 0.4716981132075472,
      "f1": 0.591715976331361
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_11/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6570705107044315,
      0.5485182233134135,
      0.47080012180138164,
      0.4128298483727051,
      0.3686791402481269,
      0.3341591000556946,
      0.30621775687566427,
      0.28343286416041885,
      0.2642027128271119,
      0.2481053663092637,
      0.2342127734934524,
      0.2221094628945612,
      0.21157950200862832,
      0.2021712831595598,
      0.1937985534235381
    ],
    "metrics": {
      "accuracy": 0.9024630541871921,
      "precision": 0.9036144578313253,
      "recall": 0.9448818897637795,
      "f1": 0.9237875288683602
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_12/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.610480484770936,
      0.49779757114328504,
      0.41863837975214063,
      0.3608702484755635,
      0.31666333487159326,
      0.2815162486481865,
      0.2533678123495255,
      0.22978676833274292,
      0.210590080293592,
      0.19452505598768302,
      0.18073496695535665,
      0.1688466793694985,
      0.15846724676953788,
      0.14952327368414634,
      0.1415244661127101
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.8557692307692307,
      "recall": 0.6267605633802817,
      "f1": 0.7235772357723578
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_12/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6736218729177671,
      0.521514545319153,
      0.41197773941335913,
      0.3341025794477014,
      0.2774673072585109,
      0.23576841237142146,
      0.2039980518685814,
      0.180163187663641,
      0.16150078655445013,
      0.14640160766830074,
      0.133876728681316,
      0.12332119493438266,
      0.11448460856963392,
      0.10686469265463609,
      0.10033632525942002
    ],
    "metrics": {
      "accuracy": 0.9359605911330049,
      "precision": 0.7887323943661971,
      "recall": 0.5283018867924528,
      "f1": 0.632768361581921
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_12/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 13,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6588302456441018,
      0.5451789288969912,
      0.46304903327593183,
      0.40391134081454816,
      0.3595140405308837,
      0.32454810604824585,
      0.2965646061375531,
      0.27416598600363795,
      0.2558266462051307,
      0.24014014723063176,
      0.226733413049719,
      0.21513635821619853,
      0.2051998402025561,
      0.19624491408260905,
      0.18805466732655204
    ],
    "metrics": {
      "accuracy": 0.8896551724137931,
      "precision": 0.888558692421991,
      "recall": 0.9417322834645669,
      "f1": 0.9143730886850153
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_13/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 13,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.620616926380802,
      0.49879814799142347,
      0.4142554662399345,
      0.3547395696105059,
      0.3112081266836446,
      0.27749172605966266,
      0.2505670637552758,
      0.22851726491200297,
      0.20983223139083948,
      0.1941815054730365,
      0.18081161506123158,
      0.16937964083910648,
      0.15927700218731677,
      0.15038105652272865,
      0.14241483384882644
    ],
    "metrics": {
      "accuracy": 0.9399014778325123,
      "precision": 0.8461538461538461,
      "recall": 0.6971830985915493,
      "f1": 0.7644787644787645
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_13/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 13,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.644196139709441,
      0.5003525881886152,
      0.3981779887240349,
      0.3247834242942261,
      0.27152586003089546,
      0.23204466080566521,
      0.20181095005732824,
      0.17853919635023766,
      0.1598588979227721,
      0.14465584967109965,
      0.13221475983095302,
      0.1220658060999128,
      0.11342315651951074,
      0.10594502152498408,
      0.09946945067340317
    ],
    "metrics": {
      "accuracy": 0.9339901477832512,
      "precision": 0.8095238095238095,
      "recall": 0.4811320754716981,
      "f1": 0.6035502958579881
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_13/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 14,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6690997413320885,
      0.5493835773329325,
      0.4633197395094874,
      0.4014667063208498,
      0.35565787342446664,
      0.32057532770481795,
      0.29237735294569234,
      0.2694882831249871,
      0.25072171438764007,
      0.2347614788530276,
      0.2209389176230021,
      0.2087857120255024,
      0.19811426595967893,
      0.18874768527260777,
      0.18043878826408175
    ],
    "metrics": {
      "accuracy": 0.8985221674876848,
      "precision": 0.8993993993993994,
      "recall": 0.9433070866141732,
      "f1": 0.9208301306687163
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_14/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 14,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6757155187902688,
      0.5329260711359516,
      0.43468350786251375,
      0.3648385640491739,
      0.3146906496415178,
      0.2769390699275643,
      0.2477616329272368,
      0.22457061302628875,
      0.20567629142481203,
      0.1898158136579799,
      0.1764077962930843,
      0.16456108836255906,
      0.15456857020835138,
      0.1457171906435919,
      0.13791302513960657
    ],
    "metrics": {
      "accuracy": 0.9300492610837439,
      "precision": 0.8198198198198198,
      "recall": 0.6408450704225352,
      "f1": 0.7193675889328063
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_14/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 14,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6335931957263365,
      0.4835438544565291,
      0.37842440522608667,
      0.3036589536970672,
      0.2502147318088447,
      0.21141290250247205,
      0.18283059647373875,
      0.16099227593380988,
      0.14369896004322164,
      0.12980754821254276,
      0.11853808395750305,
      0.1091973568635304,
      0.10124562033078016,
      0.09438082506039136,
      0.08848966668021976
    ],
    "metrics": {
      "accuracy": 0.9300492610837439,
      "precision": 0.7536231884057971,
      "recall": 0.49056603773584906,
      "f1": 0.5942857142857143
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_14/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 15,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6738324667938528,
      0.542389541154423,
      0.4502948104839906,
      0.38459202622442695,
      0.33675950818444883,
      0.3000644475139079,
      0.2722078969438981,
      0.25005196694522025,
      0.23206754014762815,
      0.21715928870885326,
      0.2044672726511625,
      0.19350542855394845,
      0.18385665622279254,
      0.175282279135778,
      0.1676326867038193
    ],
    "metrics": {
      "accuracy": 0.8886699507389163,
      "precision": 0.9015384615384615,
      "recall": 0.9228346456692913,
      "f1": 0.9120622568093385
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_15/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 15,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6357292725769106,
      0.49788143548939034,
      0.40429269232248005,
      0.33887624359196905,
      0.29164339274250567,
      0.25605000369766745,
      0.2287049628443335,
      0.20684852101466003,
      0.1892908343813096,
      0.17439248755863168,
      0.16154335245201132,
      0.15072438501420113,
      0.14114035004724096,
      0.13281347461024148,
      0.12554996873037966
    ],
    "metrics": {
      "accuracy": 0.9389162561576355,
      "precision": 0.8278688524590164,
      "recall": 0.7112676056338029,
      "f1": 0.7651515151515151
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_15/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 15,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6125298120308451,
      0.46288261312857226,
      0.35832049678237154,
      0.2845917220095848,
      0.23221483445233584,
      0.19433966479638276,
      0.16676189767356725,
      0.1459680706675363,
      0.12990475273858806,
      0.11713168576070807,
      0.10685517006551129,
      0.0984851128176639,
      0.09142308011857427,
      0.08538261061725194,
      0.08019377104628449
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.7435897435897436,
      "recall": 0.5471698113207547,
      "f1": 0.6304347826086957
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_15/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 16,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.632509180152185,
      0.4937976406056465,
      0.4011747041402431,
      0.3381044578189005,
      0.2939445279806935,
      0.2613702032374543,
      0.23691602060339126,
      0.21789501092275423,
      0.20258701905979673,
      0.1893521740000664,
      0.17825184979597286,
      0.16868429875770105,
      0.16022513091894397,
      0.15292946428803525,
      0.14625148152793213
    ],
    "metrics": {
      "accuracy": 0.9073891625615763,
      "precision": 0.921996879875195,
      "recall": 0.9307086614173228,
      "f1": 0.9263322884012539
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_16/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 16,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6288252497313755,
      0.47966489362584586,
      0.38284972235766807,
      0.3177259512059907,
      0.27232414421282314,
      0.23928529845545496,
      0.21381390429930014,
      0.1937783494055106,
      0.17740318656297932,
      0.1641011523738132,
      0.15279275893422045,
      0.1427285405985206,
      0.13401485116032683,
      0.12621064482881092,
      0.11940264696064418
    ],
    "metrics": {
      "accuracy": 0.9300492610837439,
      "precision": 0.808695652173913,
      "recall": 0.6549295774647887,
      "f1": 0.7237354085603113
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_16/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 16,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6183614317730193,
      0.4502806818716414,
      0.3365105220155373,
      0.260557083459442,
      0.20915394519504749,
      0.17387846858547665,
      0.14851633045729506,
      0.1294821727267593,
      0.11495138232975455,
      0.10333003749312457,
      0.09394008212224929,
      0.08637577890937018,
      0.07994121522371789,
      0.07458964484302621,
      0.0700612851787472
    ],
    "metrics": {
      "accuracy": 0.9389162561576355,
      "precision": 0.7972972972972973,
      "recall": 0.5566037735849056,
      "f1": 0.6555555555555556
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_16/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 17,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6044412901527003,
      0.46894671667645843,
      0.3804648895012705,
      0.32222975109422636,
      0.2816033882612667,
      0.25243710128389235,
      0.23043403708043192,
      0.21313628182021535,
      0.1989835378535897,
      0.18693356163118685,
      0.17663745104523576,
      0.16762746795392763,
      0.15955736254060698,
      0.15238456877975254,
      0.14579089066823764
    ],
    "metrics": {
      "accuracy": 0.8985221674876848,
      "precision": 0.9092307692307692,
      "recall": 0.9307086614173228,
      "f1": 0.9198443579766536
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_17/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 17,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.642283431810025,
      0.4847600753287529,
      0.38238050513320354,
      0.31469395831020913,
      0.26764765495738824,
      0.23344165279099155,
      0.20783387799837583,
      0.18751489073450875,
      0.1709291996222784,
      0.15749031020498672,
      0.14611874161664798,
      0.13643854468895789,
      0.12798712859523592,
      0.12052300209979272,
      0.11386880064770125
    ],
    "metrics": {
      "accuracy": 0.941871921182266,
      "precision": 0.8738738738738738,
      "recall": 0.6830985915492958,
      "f1": 0.766798418972332
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_17/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 17,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7070064532129388,
      0.5147255200923645,
      0.38434722800003857,
      0.2980287323037673,
      0.23893892566087835,
      0.1976676758801838,
      0.1675594170090234,
      0.14582699543056066,
      0.12952046296520578,
      0.11655135056483779,
      0.10615198991965719,
      0.09753300180230444,
      0.09025317868037237,
      0.08417265098593572,
      0.07886647876362392
    ],
    "metrics": {
      "accuracy": 0.929064039408867,
      "precision": 0.75,
      "recall": 0.4811320754716981,
      "f1": 0.5862068965517241
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_17/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 18,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5974222664357552,
      0.4677523941379505,
      0.38344452468642237,
      0.32635951582084405,
      0.28588487619838554,
      0.2568398584371789,
      0.2348864175936522,
      0.21727753890848556,
      0.20257926943229507,
      0.1903998961574153,
      0.1799544997987985,
      0.1708671386717429,
      0.16286155024641438,
      0.15569450288928446,
      0.14952758030135216
    ],
    "metrics": {
      "accuracy": 0.903448275862069,
      "precision": 0.9111791730474732,
      "recall": 0.937007874015748,
      "f1": 0.9239130434782609
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_18/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 18,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6394346343513341,
      0.4808899796900657,
      0.37827411670433847,
      0.31037987475580125,
      0.264050703770236,
      0.23042124727756363,
      0.20525283408131956,
      0.18576288019355974,
      0.17019337267096354,
      0.15722799187221687,
      0.14624654158248135,
      0.13690055235601198,
      0.12841841103380078,
      0.12097593543437049,
      0.11442351771358637
    ],
    "metrics": {
      "accuracy": 0.9399014778325123,
      "precision": 0.824,
      "recall": 0.7253521126760564,
      "f1": 0.7715355805243446
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_18/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 18,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6651089873340321,
      0.4725322513864311,
      0.3461660307530221,
      0.2645051412139903,
      0.2107168380243296,
      0.17343020615815455,
      0.14728765434835756,
      0.12809656877844616,
      0.11372018326022289,
      0.1025213466704387,
      0.09344808408510652,
      0.08590335284161105,
      0.07964775385206095,
      0.07437438501504319,
      0.06991730636383027
    ],
    "metrics": {
      "accuracy": 0.9428571428571428,
      "precision": 0.8157894736842105,
      "recall": 0.5849056603773585,
      "f1": 0.6813186813186813
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_18/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 19,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5907706643735933,
      0.4574548510468237,
      0.3703538042521543,
      0.3127581727636818,
      0.27296052865704673,
      0.24449882298460296,
      0.22296964357764437,
      0.2060865423685956,
      0.19263828254802737,
      0.1815459955679743,
      0.1723878078018199,
      0.16475317082741914,
      0.15796420597303606,
      0.15157348971782958,
      0.14530406785803818
    ],
    "metrics": {
      "accuracy": 0.8935960591133005,
      "precision": 0.9097978227060654,
      "recall": 0.9212598425196851,
      "f1": 0.9154929577464789
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_19/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 19,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6275681093293874,
      0.46658141859020225,
      0.3688889576457544,
      0.30566167240327746,
      0.26135222611334846,
      0.22906983026672267,
      0.2053818042918916,
      0.18696903201681755,
      0.17252153797162867,
      0.16050067490322767,
      0.15024410203057972,
      0.14131836538664852,
      0.13364473854570838,
      0.12690656181435175,
      0.12088957916006157
    ],
    "metrics": {
      "accuracy": 0.9339901477832512,
      "precision": 0.8205128205128205,
      "recall": 0.676056338028169,
      "f1": 0.7413127413127413
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_19/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 19,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6059076083994308,
      0.4249002932841758,
      0.31157214941245365,
      0.23959084445419734,
      0.19106714408483533,
      0.1576989630252701,
      0.13406647112726175,
      0.11671700600606913,
      0.10388898857742795,
      0.09389924330229243,
      0.08592119420004023,
      0.0792890397599612,
      0.073855315755609,
      0.06926976958717997,
      0.06529001418366986
    ],
    "metrics": {
      "accuracy": 0.9389162561576355,
      "precision": 0.75,
      "recall": 0.6226415094339622,
      "f1": 0.6804123711340206
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_19/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 20,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6325210055485987,
      0.49015835690366266,
      0.39698238123486906,
      0.33419910732068514,
      0.29076358282169806,
      0.26091515606790366,
      0.2395538334618645,
      0.22295867731366462,
      0.20944481956001135,
      0.19850953331944685,
      0.18942464301955997,
      0.181130670733399,
      0.17364708684653127,
      0.16713098122472578,
      0.16139152833464404
    ],
    "metrics": {
      "accuracy": 0.8935960591133005,
      "precision": 0.9035222052067381,
      "recall": 0.9291338582677166,
      "f1": 0.9161490683229814
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_20/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 20,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5727560585720718,
      0.42163009235733434,
      0.338286203921997,
      0.2846727601213799,
      0.24677944085109266,
      0.21956472909516575,
      0.19860955483365256,
      0.18223113994684245,
      0.16940408392791273,
      0.1582461646058883,
      0.14917357369142886,
      0.14153480715533703,
      0.13435479251053856,
      0.12814454040864168,
      0.12258221728319607
    ],
    "metrics": {
      "accuracy": 0.9310344827586207,
      "precision": 0.7857142857142857,
      "recall": 0.6971830985915493,
      "f1": 0.7388059701492538
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_20/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 20,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5781811500520257,
      0.38584984602855515,
      0.2800448987705225,
      0.21712409686348774,
      0.17373111130788385,
      0.14328075740641175,
      0.12174515995375007,
      0.10693756646149047,
      0.09569594727576275,
      0.08697204272832897,
      0.07985836797473833,
      0.07412392005035422,
      0.06937317044327133,
      0.06536310310798009,
      0.06194806616350885
    ],
    "metrics": {
      "accuracy": 0.9379310344827586,
      "precision": 0.7529411764705882,
      "recall": 0.6037735849056604,
      "f1": 0.6701570680628273
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_20/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 21,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5989013517167099,
      0.47531074574449383,
      0.3915818588885574,
      0.3368419511331416,
      0.2994114319290811,
      0.27325941599967407,
      0.25332939973168095,
      0.2384025336715323,
      0.22661917878320012,
      0.21666018006874255,
      0.20827161638360275,
      0.20136589059539117,
      0.1949886303198965,
      0.18932696238283966,
      0.18426696861219538
    ],
    "metrics": {
      "accuracy": 0.8876847290640394,
      "precision": 0.9128367670364501,
      "recall": 0.9070866141732283,
      "f1": 0.909952606635071
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_21/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 21,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.61127535649614,
      0.46267993486488956,
      0.3781972597345421,
      0.3174739714474559,
      0.27474824298286704,
      0.24343602046411783,
      0.2207665089920287,
      0.20303145252436483,
      0.1888662140620382,
      0.17704061096394821,
      0.1675063896212221,
      0.15926864825787637,
      0.15211746014881664,
      0.14577082355927232,
      0.14026438582306752
    ],
    "metrics": {
      "accuracy": 0.9211822660098522,
      "precision": 0.7348484848484849,
      "recall": 0.6830985915492958,
      "f1": 0.708029197080292
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_21/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 21,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5326095750127142,
      0.3602853709310706,
      0.27097203766209926,
      0.21401127765053196,
      0.17463102730357416,
      0.14613996583999359,
      0.12566240807566947,
      0.11072078354223283,
      0.0995176730311148,
      0.09053103725872212,
      0.08345619506948213,
      0.07767761855326862,
      0.07283371881971398,
      0.06883836296126453,
      0.0653643087151143
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.7638888888888888,
      "recall": 0.5188679245283019,
      "f1": 0.6179775280898876
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_21/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 22,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6671067794934534,
      0.5603284601029267,
      0.48694734814424595,
      0.43675125685425015,
      0.4011960788777,
      0.3749618319593308,
      0.3553473777057722,
      0.3393458822262254,
      0.3260630804415885,
      0.31460646556850286,
      0.3048698228647174,
      0.2960472234728594,
      0.2881203934591563,
      0.2813714630716065,
      0.27501000994790625
    ],
    "metrics": {
      "accuracy": 0.8571428571428571,
      "precision": 0.8876582278481012,
      "recall": 0.8834645669291339,
      "f1": 0.8855564325177585
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_22/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 22,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6097373345552058,
      0.434536711628087,
      0.39677490543295474,
      0.37476110454246275,
      0.34971466227911846,
      0.325569645164746,
      0.30782705561936397,
      0.29459965755734746,
      0.28214017341837,
      0.2713336022606847,
      0.26175204489865134,
      0.25288952516386715,
      0.24474852512747958,
      0.23852259130359027,
      0.23082438257427426
    ],
    "metrics": {
      "accuracy": 0.8985221674876848,
      "precision": 0.8,
      "recall": 0.36619718309859156,
      "f1": 0.5024154589371981
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_22/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 22,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5627857510568033,
      0.37651729162710196,
      0.32479186038231256,
      0.30096468468121873,
      0.2776079166463868,
      0.2566606381469486,
      0.23868149277080788,
      0.22346774458554974,
      0.20961515561695573,
      0.1967264582245634,
      0.18553939336224606,
      0.17436267275394166,
      0.16439491502135745,
      0.15560834264986403,
      0.1479462206446233
    ],
    "metrics": {
      "accuracy": 0.9083743842364532,
      "precision": 0.8095238095238095,
      "recall": 0.16037735849056603,
      "f1": 0.2677165354330709
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_22/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 23,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6724062207002719,
      0.6391968689466777,
      0.6222222767708374,
      0.6036116692828339,
      0.5875295821649547,
      0.5730538480169555,
      0.5590231715146855,
      0.5466258376258892,
      0.5347240543761742,
      0.5241859348526952,
      0.5140402432293774,
      0.5061732519696625,
      0.49810067638135685,
      0.4900422214471072,
      0.4830611391245824
    ],
    "metrics": {
      "accuracy": 0.7379310344827587,
      "precision": 0.7631954350927247,
      "recall": 0.84251968503937,
      "f1": 0.8008982035928144
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_23/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 23,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.630661282578994,
      0.5176001526972593,
      0.45731707953350037,
      0.4315546050956705,
      0.42371589833679624,
      0.4204297212187273,
      0.4186119519442402,
      0.4165692877076009,
      0.41465762937828443,
      0.4128575307840786,
      0.4111085815608006,
      0.4094554554392426,
      0.4077761713982949,
      0.4061282077984797,
      0.4045206095868531
    ],
    "metrics": {
      "accuracy": 0.8600985221674877,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_23/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 23,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5894643618624626,
      0.45495275714721045,
      0.37446599417776283,
      0.3321658083441515,
      0.3117311547667696,
      0.301615022770916,
      0.2972618157843804,
      0.2944515768675923,
      0.29250688562763033,
      0.2907436001994273,
      0.2890395139888383,
      0.287326502618367,
      0.2857286144656818,
      0.2842183850808817,
      0.282561995382124
    ],
    "metrics": {
      "accuracy": 0.8955665024630541,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_23/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 24,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6589827011826956,
      0.6323007211460632,
      0.610290626904971,
      0.5914643322001534,
      0.572561740115739,
      0.5559526921969702,
      0.5421512751037725,
      0.5277467576420538,
      0.5169501918174554,
      0.5063133018498935,
      0.5043462875807384,
      0.491027878592219,
      0.48351808680721925,
      0.4771024941902742,
      0.46913901575714595
    ],
    "metrics": {
      "accuracy": 0.7241379310344828,
      "precision": 0.7338603425559947,
      "recall": 0.8771653543307086,
      "f1": 0.7991391678622669
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_24/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 24,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4640231843470206,
      0.4492303783213333,
      0.4431403275837198,
      0.42416435297671445,
      0.4325321754094967,
      0.4225393365459759,
      0.4181959198782649,
      0.41684154749246843,
      0.41355588396500353,
      0.41291790607893564,
      0.40962164841200177,
      0.4100116250092303,
      0.4056277013881715,
      0.40454097471078676,
      0.4022055480949106
    ],
    "metrics": {
      "accuracy": 0.8600985221674877,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_24/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 24,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.519532026825189,
      0.3116913436770109,
      0.33932198730201935,
      0.3191006985645215,
      0.29685612538019374,
      0.2949212914358546,
      0.29281419585781415,
      0.2913953747115307,
      0.2902728691655843,
      0.2873893451492542,
      0.28589750898181565,
      0.28454289117678383,
      0.28256420656584635,
      0.28064789952003394,
      0.2789480851627783
    ],
    "metrics": {
      "accuracy": 0.8955665024630541,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAV2VEC2_LARGE/layer_24/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.628266315935438,
      0.5576962659363657,
      0.4994795010692772,
      0.4522215472923329,
      0.4141367252614273,
      0.3831033159746053,
      0.35775273067462604,
      0.336946599943684,
      0.31951129289444735,
      0.30491127984878696,
      0.29230399976633564,
      0.28153103539881535,
      0.27204546197008145,
      0.2636227832560383,
      0.25613235341155766
    ],
    "metrics": {
      "accuracy": 0.8529657477025898,
      "precision": 0.8689384010484927,
      "recall": 0.8971583220568335,
      "f1": 0.8828229027962716
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_00/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6462405099399557,
      0.5531207456420308,
      0.47870966413624655,
      0.4214485770585927,
      0.3768933220991809,
      0.34354406525048015,
      0.3174876979178062,
      0.29674867523261267,
      0.2800681279726245,
      0.26615912642069883,
      0.25445297377548,
      0.24450632519570925,
      0.23585312543026968,
      0.22810109515700783,
      0.22126160358593916
    ],
    "metrics": {
      "accuracy": 0.9147869674185464,
      "precision": 0.7951807228915663,
      "recall": 0.66,
      "f1": 0.7213114754098361
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_00/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.644269870147673,
      0.5533216392790065,
      0.4791807594805964,
      0.4202176904207122,
      0.3745086007687034,
      0.33827926120338303,
      0.30933298374846563,
      0.28557489989082585,
      0.2659210330436702,
      0.24921747066241404,
      0.23483241543503813,
      0.22226953687355702,
      0.21126279934618297,
      0.20146558627816252,
      0.19268021531839613
    ],
    "metrics": {
      "accuracy": 0.948203842940685,
      "precision": 0.7333333333333333,
      "recall": 0.39759036144578314,
      "f1": 0.515625
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_00/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6514942324191607,
      0.5859959252682059,
      0.5309667476659935,
      0.48534620423961294,
      0.44690248805466637,
      0.4144410369006532,
      0.3869773025669101,
      0.3633490473842434,
      0.343569213347439,
      0.3262649600015223,
      0.31141965125901777,
      0.2985385947027626,
      0.28725293024701837,
      0.27728282451161756,
      0.26838087508382336
    ],
    "metrics": {
      "accuracy": 0.8671679197994987,
      "precision": 0.8776041666666666,
      "recall": 0.912043301759134,
      "f1": 0.8944923689449237
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_01/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6676338677617526,
      0.5842276386329698,
      0.516498994436256,
      0.4632591453208822,
      0.421095408793755,
      0.3880058328477749,
      0.36095833097447994,
      0.33861851435700885,
      0.31968019145324444,
      0.30343568009223326,
      0.28935238169226823,
      0.2767149255928754,
      0.2656775062445803,
      0.25578777713871886,
      0.2469879981847848
    ],
    "metrics": {
      "accuracy": 0.910609857978279,
      "precision": 0.8345323741007195,
      "recall": 0.58,
      "f1": 0.6843657817109144
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_01/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.670903268834941,
      0.580119865111754,
      0.5049931805341692,
      0.44521291343845637,
      0.3969994489889971,
      0.35901354072406105,
      0.32805506859568945,
      0.3026225194982497,
      0.28137456993947085,
      0.2628916839541325,
      0.24677637276243086,
      0.23265723926716236,
      0.21990218024595398,
      0.2084574851421271,
      0.1980864993824757
    ],
    "metrics": {
      "accuracy": 0.9473684210526315,
      "precision": 0.9545454545454546,
      "recall": 0.25301204819277107,
      "f1": 0.4
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_01/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.66061235964716,
      0.6024789167179058,
      0.5534538400918454,
      0.512228790872198,
      0.47665216545447736,
      0.44535678295083897,
      0.41788792793143187,
      0.39375230139432116,
      0.3726761231226583,
      0.3540355151763041,
      0.33741958936891003,
      0.3228694371041511,
      0.3096012367331952,
      0.29788560672804926,
      0.28719489227532335
    ],
    "metrics": {
      "accuracy": 0.8654970760233918,
      "precision": 0.866751269035533,
      "recall": 0.9242219215155616,
      "f1": 0.8945645055664702
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_02/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.663578779833772,
      0.5785947280134646,
      0.5124497719094437,
      0.4604903556968372,
      0.4220163173323958,
      0.3918408155107084,
      0.36773782559125606,
      0.3474695897750705,
      0.33008047500544313,
      0.3144906872723127,
      0.3006391611742913,
      0.28798546505669503,
      0.27671618344805843,
      0.2662880647606899,
      0.25685899226161524
    ],
    "metrics": {
      "accuracy": 0.8964076858813701,
      "precision": 0.8958333333333334,
      "recall": 0.43,
      "f1": 0.581081081081081
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_02/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6465846388855333,
      0.5520191597343661,
      0.4752546192585737,
      0.415843459130804,
      0.3698209350537545,
      0.33456505077674603,
      0.3065677495824211,
      0.28392909680690825,
      0.2648275102641959,
      0.2485279087170453,
      0.2340730222535795,
      0.22120379020528094,
      0.20964377501497491,
      0.19902167357097061,
      0.1894046307771454
    ],
    "metrics": {
      "accuracy": 0.9431913116123642,
      "precision": 0.8571428571428571,
      "recall": 0.21686746987951808,
      "f1": 0.34615384615384615
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_02/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6717098919089382,
      0.6115342458991534,
      0.5601604702026863,
      0.5162797249730374,
      0.4786693023672818,
      0.44619474183420255,
      0.4179780963074102,
      0.3933246515781097,
      0.3716138582253677,
      0.3527016894119542,
      0.33571688152007906,
      0.32085332868478195,
      0.30740545388861534,
      0.29542104160882593,
      0.28453097790939186
    ],
    "metrics": {
      "accuracy": 0.858813700918964,
      "precision": 0.8580402010050251,
      "recall": 0.9242219215155616,
      "f1": 0.8899022801302932
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_03/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.650632984871486,
      0.575056533085588,
      0.5118544168053871,
      0.4599882385494798,
      0.4180167262498023,
      0.3838427055105964,
      0.3556608674169957,
      0.3319984218186613,
      0.3118584608961495,
      0.29443985472749457,
      0.2791338314069631,
      0.2655987904323795,
      0.25356891135525095,
      0.24279868690062545,
      0.23305521380727554
    ],
    "metrics": {
      "accuracy": 0.9164578111946533,
      "precision": 0.890625,
      "recall": 0.57,
      "f1": 0.6951219512195121
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_03/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6480656769685395,
      0.5661985185890261,
      0.497549620594068,
      0.4399720541746435,
      0.39262897291703486,
      0.3536427475706282,
      0.3213410338400992,
      0.2941049758646713,
      0.27103660974410326,
      0.2510596634185645,
      0.23370944672032568,
      0.21856255086156076,
      0.205019297467282,
      0.19301829316016503,
      0.18216112919020191
    ],
    "metrics": {
      "accuracy": 0.9657477025898078,
      "precision": 0.875,
      "recall": 0.5903614457831325,
      "f1": 0.7050359712230215
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_03/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6779397751123991,
      0.6208923755655912,
      0.5706961140232926,
      0.5267466509880256,
      0.48864760256328266,
      0.4553715474538052,
      0.42648980044870777,
      0.4010178032026994,
      0.37866871528074725,
      0.3589260264591974,
      0.34142931619043404,
      0.3256048454033884,
      0.31157869055453624,
      0.29890129030302254,
      0.2874459902178115
    ],
    "metrics": {
      "accuracy": 0.8646616541353384,
      "precision": 0.8610763454317898,
      "recall": 0.9309878213802436,
      "f1": 0.8946684005201561
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_04/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6713049404922573,
      0.604754563754167,
      0.547301040114827,
      0.4981058369940792,
      0.4564410195753024,
      0.421024675124628,
      0.3910707406112718,
      0.3649541554596032,
      0.3425376583021296,
      0.3226019539918624,
      0.305028805837666,
      0.28937513150017835,
      0.27530789208204964,
      0.26255025700223455,
      0.2509749970551061
    ],
    "metrics": {
      "accuracy": 0.9256474519632414,
      "precision": 0.9051094890510949,
      "recall": 0.62,
      "f1": 0.7359050445103857
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_04/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6894719398486236,
      0.6141617341739375,
      0.5478107760124324,
      0.4902857641044838,
      0.4412791295014144,
      0.3994347215584423,
      0.36366337066542914,
      0.33306810169584916,
      0.3065752593332023,
      0.2834977802857318,
      0.26332630727148737,
      0.24552814926057093,
      0.22969184695153735,
      0.2156950349162064,
      0.20313698026623953
    ],
    "metrics": {
      "accuracy": 0.9674185463659147,
      "precision": 0.8548387096774194,
      "recall": 0.6385542168674698,
      "f1": 0.7310344827586207
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_04/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6640401505641921,
      0.6093424231624416,
      0.5623407359714097,
      0.5209921789764188,
      0.48533195532902235,
      0.4539307512370084,
      0.426338453051554,
      0.4019913201509887,
      0.38045916407423125,
      0.36114677905468234,
      0.34387599903894867,
      0.3282861864663721,
      0.3141969517646198,
      0.3013790869265001,
      0.2896847781895722
    ],
    "metrics": {
      "accuracy": 0.873015873015873,
      "precision": 0.8655043586550436,
      "recall": 0.9404600811907984,
      "f1": 0.9014267185473411
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_05/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6620818310870755,
      0.590898448975774,
      0.5309509976524447,
      0.480789911130379,
      0.4393537861895822,
      0.4045540652573861,
      0.3750516392367876,
      0.349746909359105,
      0.3276059913942718,
      0.30821997367570403,
      0.29079235194943887,
      0.27528652212083055,
      0.2612698540104047,
      0.24860651418462265,
      0.2371009366499599
    ],
    "metrics": {
      "accuracy": 0.923141186299081,
      "precision": 0.9354838709677419,
      "recall": 0.58,
      "f1": 0.7160493827160493
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_05/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6405044196365192,
      0.5658755713829915,
      0.5021487616309607,
      0.44940339902351645,
      0.4055970085496023,
      0.36952306125924006,
      0.3392397495237826,
      0.3134321501216937,
      0.2911609973030529,
      0.27158573873493563,
      0.2542968775616462,
      0.23873825089701559,
      0.22482444877747498,
      0.21224214306207206,
      0.20078375966468043
    ],
    "metrics": {
      "accuracy": 0.9557226399331662,
      "precision": 0.9166666666666666,
      "recall": 0.39759036144578314,
      "f1": 0.5546218487394958
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_05/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.65143263069294,
      0.5994034346192031,
      0.553683793257357,
      0.5145031188862444,
      0.47960442089051936,
      0.44924186307541086,
      0.4221673682937777,
      0.39819183781897616,
      0.376791725823416,
      0.3576297154438606,
      0.34042333330899555,
      0.3248616275848846,
      0.31072300303239664,
      0.29781153997788085,
      0.28602735502298116
    ],
    "metrics": {
      "accuracy": 0.8972431077694235,
      "precision": 0.8948717948717949,
      "recall": 0.9445196211096076,
      "f1": 0.9190256747860435
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_06/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6707079301102341,
      0.5995721254055996,
      0.5389775410231871,
      0.48887427405613226,
      0.44726537419094037,
      0.41275843310362825,
      0.38348005599657425,
      0.3583890310699344,
      0.33639065646009014,
      0.31691818755983736,
      0.29958816252404447,
      0.28402057615922616,
      0.269946010065306,
      0.2570723030483285,
      0.24536831336493314
    ],
    "metrics": {
      "accuracy": 0.9214703425229741,
      "precision": 0.9416666666666667,
      "recall": 0.565,
      "f1": 0.70625
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_06/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6625448292398574,
      0.5825294136232376,
      0.51600058103998,
      0.4599621973854506,
      0.4146993026567635,
      0.3773123576656456,
      0.3464236992612619,
      0.32045646578716835,
      0.2982754621614018,
      0.2788595401308334,
      0.2617013982223268,
      0.2464059563512925,
      0.2327712749337027,
      0.22010920539953677,
      0.20876440554147077
    ],
    "metrics": {
      "accuracy": 0.9557226399331662,
      "precision": 0.9411764705882353,
      "recall": 0.3855421686746988,
      "f1": 0.5470085470085471
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_06/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6705705387972636,
      0.6187310328595873,
      0.5724824712762386,
      0.5318481578925828,
      0.4957627301911931,
      0.4640244515813764,
      0.4356807478676666,
      0.41073645740321346,
      0.38840991912818534,
      0.36835001201431794,
      0.35042595250920017,
      0.3342011215424785,
      0.3193720864638047,
      0.30599404041393485,
      0.2936983812263041
    ],
    "metrics": {
      "accuracy": 0.8955722639933166,
      "precision": 0.8886075949367088,
      "recall": 0.9499323410013532,
      "f1": 0.9182472204054938
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_07/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6668358530722849,
      0.6005787396584702,
      0.5437182907901761,
      0.495696524060471,
      0.4550033218224977,
      0.42036675358306536,
      0.39043835473889427,
      0.364606706090825,
      0.34176412767009773,
      0.3215440034715943,
      0.3035774050488805,
      0.28745536109730746,
      0.2728117965485557,
      0.25957829402647403,
      0.24756502921771095
    ],
    "metrics": {
      "accuracy": 0.924812030075188,
      "precision": 0.9583333333333334,
      "recall": 0.575,
      "f1": 0.71875
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_07/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6579951429387118,
      0.5842803137323119,
      0.5218090284913403,
      0.4693030488818575,
      0.42577521124071926,
      0.38941359389620334,
      0.3586837549085272,
      0.33236120436951533,
      0.30949078612645736,
      0.2894902000799545,
      0.27155833559140524,
      0.2556182631038971,
      0.24114554742821667,
      0.2280253774233482,
      0.21620935882996004
    ],
    "metrics": {
      "accuracy": 0.9573934837092731,
      "precision": 0.9210526315789473,
      "recall": 0.42168674698795183,
      "f1": 0.5785123966942148
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_07/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6901049698505343,
      0.6393140158567704,
      0.5937387307284424,
      0.5533639318240534,
      0.5178690058596167,
      0.4860482986213314,
      0.457921750327603,
      0.43275000773660605,
      0.41034038132200196,
      0.3900793640259972,
      0.3718741505143353,
      0.355239126456362,
      0.3401114440595933,
      0.32626566767091003,
      0.31347559691143867
    ],
    "metrics": {
      "accuracy": 0.8880534670008354,
      "precision": 0.8776529338327091,
      "recall": 0.9512855209742895,
      "f1": 0.912987012987013
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_08/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6528191357926224,
      0.5866318764658511,
      0.5315619859168734,
      0.4861517153452651,
      0.4479400223298069,
      0.41587702559428885,
      0.38823583159822356,
      0.36401010239729203,
      0.3425644376396899,
      0.32352579344311516,
      0.30626342826809305,
      0.2908923584588743,
      0.2768231153588419,
      0.2641417152212553,
      0.2524819550709394
    ],
    "metrics": {
      "accuracy": 0.908939014202172,
      "precision": 0.941747572815534,
      "recall": 0.485,
      "f1": 0.6402640264026402
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_08/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6378614702978688,
      0.5652786635002369,
      0.5044089103232989,
      0.45475913047422906,
      0.41405092588753,
      0.38035195247947184,
      0.3518662646784647,
      0.32724988153076384,
      0.3058878245275496,
      0.2868368693316454,
      0.2697839567331764,
      0.2544602684348713,
      0.24049488833747995,
      0.22789283810308208,
      0.21628282855196698
    ],
    "metrics": {
      "accuracy": 0.9624060150375939,
      "precision": 0.8958333333333334,
      "recall": 0.5180722891566265,
      "f1": 0.6564885496183206
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_08/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6769639364403772,
      0.6271498265271765,
      0.5832300717201693,
      0.5445745661875632,
      0.5107437754532921,
      0.4804924670006335,
      0.45403668894331967,
      0.4302987997057995,
      0.4093682361745286,
      0.3903265211189164,
      0.37308443196688107,
      0.35757280291714255,
      0.3432665646727893,
      0.3301540466293354,
      0.3181483377035439
    ],
    "metrics": {
      "accuracy": 0.8721804511278195,
      "precision": 0.8538647342995169,
      "recall": 0.9566982408660352,
      "f1": 0.9023611997447352
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_09/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6566986616900363,
      0.594444894459791,
      0.5409486892178575,
      0.4963284318925688,
      0.4587313258534291,
      0.4269051850009172,
      0.3992481714609059,
      0.37512842087241693,
      0.3538710572888679,
      0.3348277750338096,
      0.31803027213973295,
      0.3026176924327191,
      0.28880529420229445,
      0.2761136861719068,
      0.26454039017860714
    ],
    "metrics": {
      "accuracy": 0.873015873015873,
      "precision": 0.6791044776119403,
      "recall": 0.455,
      "f1": 0.5449101796407185
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_09/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.654087240718679,
      0.5799629828627115,
      0.5188608767607314,
      0.4680098352777814,
      0.4264290114811966,
      0.39223067098583597,
      0.3634586707948134,
      0.3387543052844317,
      0.3172475489826138,
      0.2982163028386851,
      0.2812819804485552,
      0.26585762802211715,
      0.2518246534962196,
      0.2391604080457864,
      0.2274970155964387
    ],
    "metrics": {
      "accuracy": 0.9314954051796157,
      "precision": 0.5064935064935064,
      "recall": 0.46987951807228917,
      "f1": 0.4875
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_09/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6762693438972449,
      0.616785233131737,
      0.5655247496729777,
      0.520735560460755,
      0.4817976362403782,
      0.44829036599954103,
      0.4189128852004192,
      0.39334225568545444,
      0.37096430882205805,
      0.3508948465672935,
      0.33316980514968847,
      0.3173462621949118,
      0.30302140701542324,
      0.2901490551769683,
      0.27829965831252884
    ],
    "metrics": {
      "accuracy": 0.8755221386800334,
      "precision": 0.8678304239401496,
      "recall": 0.9418132611637348,
      "f1": 0.9033095392602206
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_10/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6520975327204348,
      0.5852879768063582,
      0.5296941728678143,
      0.48321113881023453,
      0.44415767711853826,
      0.41123279549008096,
      0.3827347712069625,
      0.3579669442787069,
      0.3357649053934411,
      0.3162393982015406,
      0.29873246981344337,
      0.28287160969729647,
      0.26863232658529,
      0.2556439622764598,
      0.2438527562093895
    ],
    "metrics": {
      "accuracy": 0.9072681704260651,
      "precision": 0.8617886178861789,
      "recall": 0.53,
      "f1": 0.6563467492260062
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_10/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6498130523660519,
      0.5711434943220813,
      0.5059718002967551,
      0.4532633620482184,
      0.4102171858653054,
      0.37515754886190866,
      0.3458513890891507,
      0.3207795263205652,
      0.29917326559531177,
      0.2799318863090962,
      0.262785750884852,
      0.24731223350367293,
      0.23344142504823887,
      0.22066797033675017,
      0.20923087477917962
    ],
    "metrics": {
      "accuracy": 0.9323308270676691,
      "precision": 0.5108695652173914,
      "recall": 0.5662650602409639,
      "f1": 0.5371428571428571
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_10/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6588181608158366,
      0.599691163066525,
      0.5477588818225,
      0.50265327568879,
      0.46366335177140844,
      0.4297513771047103,
      0.4002199058426439,
      0.3743436983278695,
      0.35163728645912634,
      0.33144168199395346,
      0.313474446969571,
      0.2973593649056769,
      0.28295968674731115,
      0.269889104774027,
      0.2579323355351839
    ],
    "metrics": {
      "accuracy": 0.885547201336675,
      "precision": 0.8810126582278481,
      "recall": 0.9418132611637348,
      "f1": 0.9103989535644212
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_11/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6522880724942213,
      0.5895816386163752,
      0.5357482227785834,
      0.4902383986059477,
      0.4515316380166459,
      0.41832602473577934,
      0.38982526301702664,
      0.36487550101495436,
      0.34273512200678236,
      0.3228633261575798,
      0.30512539535668975,
      0.28910602345532116,
      0.274378886569071,
      0.26103324146707885,
      0.24880888092273887
    ],
    "metrics": {
      "accuracy": 0.8771929824561403,
      "precision": 0.6879432624113475,
      "recall": 0.485,
      "f1": 0.5689149560117303
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_11/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6470394531217382,
      0.5772273523118404,
      0.517996263998645,
      0.4679093841397532,
      0.4263998985056587,
      0.3913241451549236,
      0.36142054424086706,
      0.3356073786305352,
      0.31284097341686395,
      0.29280794627665807,
      0.2745995462141286,
      0.25847179713555335,
      0.24364508167097207,
      0.23027542477433408,
      0.21804655892009456
    ],
    "metrics": {
      "accuracy": 0.9314954051796157,
      "precision": 0.5050505050505051,
      "recall": 0.6024096385542169,
      "f1": 0.5494505494505495
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_11/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6656108119422928,
      0.5940888311838215,
      0.5369478760395259,
      0.48971441305415586,
      0.44928979388231116,
      0.41448530628295516,
      0.38451979469110026,
      0.358724609313975,
      0.33631423398965143,
      0.3164902924655832,
      0.29892541962342334,
      0.2834729732820758,
      0.26957716856111086,
      0.2570307691925408,
      0.24575910895001765
    ],
    "metrics": {
      "accuracy": 0.8755221386800334,
      "precision": 0.8624078624078624,
      "recall": 0.9499323410013532,
      "f1": 0.9040566645202833
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_12/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6487798098425656,
      0.5268824146781143,
      0.44343625318613045,
      0.38742651579625337,
      0.34888491753038653,
      0.31920381007757315,
      0.2947817855784296,
      0.27356066184031186,
      0.25481496721648156,
      0.2384495905652446,
      0.2237549588556279,
      0.21081178795983888,
      0.1990250304596144,
      0.18845179092158848,
      0.17889031784972925
    ],
    "metrics": {
      "accuracy": 0.9022556390977443,
      "precision": 0.9191919191919192,
      "recall": 0.455,
      "f1": 0.6086956521739131
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_12/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 769,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5932624883968556,
      0.4720238431732562,
      0.38764314943747524,
      0.3316217870029843,
      0.29284671916492455,
      0.26425085857798813,
      0.24142355989651215,
      0.22197821704586715,
      0.20443918624277171,
      0.1891060772148006,
      0.1755806854585322,
      0.16352015011010465,
      0.15276386180460738,
      0.14336891080071887,
      0.1347827758939787
    ],
    "metrics": {
      "accuracy": 0.9590643274853801,
      "precision": 0.8541666666666666,
      "recall": 0.4939759036144578,
      "f1": 0.6259541984732825
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_BASE/layer_12/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1570740579061745,
      0.5026552876406213,
      0.311292139153776,
      0.2561036460376196,
      0.2287907149483036,
      0.2116186260412275,
      0.20154638275597678,
      0.1916373978986006,
      0.18456341939287502,
      0.17954819246113643,
      0.17583086941042397,
      0.17242591813259556,
      0.16992640162536168,
      0.16735672791685005,
      0.16390466047722949
    ],
    "metrics": {
      "accuracy": 0.8882063882063882,
      "precision": 0.8861788617886179,
      "recall": 0.9256900212314225,
      "f1": 0.9055036344755971
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_00/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3725750171972239,
      0.2302165217992552,
      0.20130072252984063,
      0.1845916416796055,
      0.16590516242968265,
      0.152081270605822,
      0.1465411856689155,
      0.14055590849820299,
      0.13486690041051028,
      0.13126005191653925,
      0.1265058763428949,
      0.12400000102038987,
      0.12064498743292025,
      0.11805911219790435,
      0.11582915818889773
    ],
    "metrics": {
      "accuracy": 0.9164619164619164,
      "precision": 0.7142857142857143,
      "recall": 0.7142857142857143,
      "f1": 0.7142857142857143
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_00/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8399747696903733,
      0.439294889654711,
      0.3557434658225755,
      0.16926131146488832,
      0.1575325214078509,
      0.11981736204515478,
      0.11073831523128654,
      0.09874394676771901,
      0.09319207740430457,
      0.08833528280567349,
      0.08425765762213895,
      0.08092863320767342,
      0.07816410674493625,
      0.0754187223553625,
      0.07330494779160837
    ],
    "metrics": {
      "accuracy": 0.9533169533169533,
      "precision": 0.5882352941176471,
      "recall": 0.45454545454545453,
      "f1": 0.5128205128205128
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_00/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4078984156661824,
      0.22173801030319895,
      0.1882795777162697,
      0.1732546040310809,
      0.16152458191487493,
      0.15296979569693975,
      0.1453918846796485,
      0.13981068584230993,
      0.134432667921776,
      0.13112941853765123,
      0.12709291908232007,
      0.12453981487112491,
      0.12152820513966368,
      0.11902464682161563,
      0.11622513790591767
    ],
    "metrics": {
      "accuracy": 0.8808353808353808,
      "precision": 0.874,
      "recall": 0.9278131634819533,
      "f1": 0.9001029866117405
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_01/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3956802011008084,
      0.2141590597865167,
      0.16248182517939372,
      0.13627991437049566,
      0.12257378895996114,
      0.11499611631650077,
      0.1089947617610491,
      0.1032496293670585,
      0.0993421579722072,
      0.09597162339035976,
      0.09351817706008443,
      0.09070890220688108,
      0.08747465118619382,
      0.08561651365958112,
      0.08385519396158765
    ],
    "metrics": {
      "accuracy": 0.9312039312039312,
      "precision": 0.7787610619469026,
      "recall": 0.7394957983193278,
      "f1": 0.7586206896551724
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_01/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.38384749379732097,
      0.15863694508902987,
      0.09634734519332476,
      0.07730765293631728,
      0.06367160882083829,
      0.05799528073652696,
      0.05222764308583434,
      0.04895038237231304,
      0.046256543632668935,
      0.043609655103965306,
      0.041979326308993994,
      0.039997088713477354,
      0.038656451756914165,
      0.037303112364884386,
      0.03610819043175155
    ],
    "metrics": {
      "accuracy": 0.9606879606879607,
      "precision": 0.6428571428571429,
      "recall": 0.6136363636363636,
      "f1": 0.627906976744186
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_01/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7448880333100516,
      0.29510277334764423,
      0.2166177545402859,
      0.18294676109932825,
      0.16537566164901535,
      0.15196070127105765,
      0.14064639630398723,
      0.13411362763110843,
      0.12686446560086562,
      0.12267229262431267,
      0.11890057764628074,
      0.11460548791441473,
      0.11187073832452542,
      0.10934864803070649,
      0.10605487081804726
    ],
    "metrics": {
      "accuracy": 0.8759213759213759,
      "precision": 0.8714859437751004,
      "recall": 0.921443736730361,
      "f1": 0.8957688338493293
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_02/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7150062435382122,
      0.32301656171626614,
      0.2112127470979917,
      0.1542009135457521,
      0.13200703622489038,
      0.1147345195872973,
      0.10701992323481252,
      0.09970301361624868,
      0.0953933853933696,
      0.0908165709091411,
      0.08716540713266958,
      0.08399922350472906,
      0.0806012664914717,
      0.07786378425419119,
      0.07561789703009528
    ],
    "metrics": {
      "accuracy": 0.9164619164619164,
      "precision": 0.7475728155339806,
      "recall": 0.6470588235294118,
      "f1": 0.6936936936936937
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_02/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.65406210315771,
      0.2782875898347798,
      0.11839616336101332,
      0.08903374634591601,
      0.06660790298995492,
      0.05822104066325575,
      0.052924541239363555,
      0.04838794707710906,
      0.04632091472790341,
      0.04386868192797764,
      0.041672787238283625,
      0.04011170296677305,
      0.03828787120425763,
      0.03740037644117737,
      0.03585796973177588
    ],
    "metrics": {
      "accuracy": 0.957002457002457,
      "precision": 0.6,
      "recall": 0.6136363636363636,
      "f1": 0.6067415730337079
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_02/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5541088034587254,
      0.21586668982780471,
      0.16585223216064113,
      0.14079233618982495,
      0.12596856000284792,
      0.11653701398839984,
      0.11010965577792249,
      0.10479468839874106,
      0.10192010091801273,
      0.09727246060442671,
      0.09462258097881703,
      0.09098618480430547,
      0.08850172725476887,
      0.08569134026460722,
      0.08314269119347342
    ],
    "metrics": {
      "accuracy": 0.8832923832923832,
      "precision": 0.8790322580645161,
      "recall": 0.9256900212314225,
      "f1": 0.9017580144777663
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_03/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5404840114498737,
      0.2429614755305442,
      0.16814380950275876,
      0.12945001812993975,
      0.1075448514397861,
      0.09573350800391986,
      0.08641132753654611,
      0.07988947696033931,
      0.07515135774790117,
      0.07114369605665093,
      0.06712790162038386,
      0.06377525388413428,
      0.061197127252939194,
      0.05869178839054324,
      0.056575629084187715
    ],
    "metrics": {
      "accuracy": 0.9250614250614251,
      "precision": 0.7788461538461539,
      "recall": 0.680672268907563,
      "f1": 0.726457399103139
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_03/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.32464622598575693,
      0.09596097386749006,
      0.05235516069619147,
      0.04239780968500069,
      0.03703038909869411,
      0.03368348722864037,
      0.030263011750325034,
      0.02797815250957432,
      0.026204055549951644,
      0.024407838757266577,
      0.023488613929667664,
      0.02190554328466207,
      0.020916596181647977,
      0.01967152635943945,
      0.01899617771614763
    ],
    "metrics": {
      "accuracy": 0.9545454545454546,
      "precision": 0.5714285714285714,
      "recall": 0.6363636363636364,
      "f1": 0.6021505376344086
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_03/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5467629374017359,
      0.2313198176012513,
      0.17158440922961807,
      0.14928580818119644,
      0.13129838464927582,
      0.12031084888543778,
      0.11223792818044659,
      0.10669354460838548,
      0.1013086568060759,
      0.09685962365895974,
      0.09254194638652942,
      0.08899918016948369,
      0.08574041640302082,
      0.08331903042142065,
      0.08042819742057417
    ],
    "metrics": {
      "accuracy": 0.8857493857493858,
      "precision": 0.8735177865612648,
      "recall": 0.9384288747346072,
      "f1": 0.9048106448311156
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_04/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.32096346464275566,
      0.1513239014044571,
      0.10706934025508603,
      0.08649973163633945,
      0.07399239543639276,
      0.06562509128395208,
      0.059626918574914624,
      0.0548488648138979,
      0.051262380963091214,
      0.04822848802734977,
      0.045345885454876125,
      0.04280467019951591,
      0.04074255731582251,
      0.03894127861027375,
      0.03701831854894094
    ],
    "metrics": {
      "accuracy": 0.9299754299754299,
      "precision": 0.7767857142857143,
      "recall": 0.7310924369747899,
      "f1": 0.7532467532467533
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_04/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4817122914346554,
      0.1388384896917093,
      0.05962214964652221,
      0.05130291823323164,
      0.04111204946471097,
      0.0365702617224972,
      0.03476045993513954,
      0.03279366122277511,
      0.030374475873278572,
      0.028680497854937873,
      0.027153962255419196,
      0.025741355056860978,
      0.024411388417365704,
      0.023329574800875223,
      0.022102893783486902
    ],
    "metrics": {
      "accuracy": 0.957002457002457,
      "precision": 0.5882352941176471,
      "recall": 0.6818181818181818,
      "f1": 0.631578947368421
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_04/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6666490391258851,
      0.23007745637069985,
      0.17834005133232847,
      0.14793389675100904,
      0.1321620968133089,
      0.1186787673693487,
      0.10891613310521787,
      0.10205083772633657,
      0.09633499846053585,
      0.09097349310129547,
      0.08676618776977502,
      0.08510869267515364,
      0.0798482362515543,
      0.07710967379500884,
      0.07372673736173795
    ],
    "metrics": {
      "accuracy": 0.8882063882063882,
      "precision": 0.8696498054474708,
      "recall": 0.9490445859872612,
      "f1": 0.9076142131979695
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_05/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.48025902021608163,
      0.17560298933687998,
      0.10993144639119111,
      0.0827675339769152,
      0.06988701719506953,
      0.06147789300391168,
      0.05535150603031465,
      0.05035114692284571,
      0.04676184148702861,
      0.0439058513511018,
      0.04076395369913615,
      0.03875497576035407,
      0.03652405418067105,
      0.0344272479430195,
      0.03286589830279871
    ],
    "metrics": {
      "accuracy": 0.9250614250614251,
      "precision": 0.7735849056603774,
      "recall": 0.6890756302521008,
      "f1": 0.7288888888888889
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_05/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.33514990309548776,
      0.07909500923027049,
      0.04402635262177155,
      0.0369220099882524,
      0.03231816836273023,
      0.02869236832619356,
      0.02529619592555943,
      0.022785068708775783,
      0.020954590107723887,
      0.01936922810942244,
      0.017922186645862998,
      0.01678225070562538,
      0.015792289084174935,
      0.01478388692106652,
      0.014114973277673267
    ],
    "metrics": {
      "accuracy": 0.9668304668304668,
      "precision": 0.660377358490566,
      "recall": 0.7954545454545454,
      "f1": 0.7216494845360825
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_05/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7387279505746598,
      0.2540049557839786,
      0.17272130312276543,
      0.12892160338275654,
      0.11247139017690312,
      0.0985850037779601,
      0.08937501564821258,
      0.08298224701342477,
      0.07833681335922411,
      0.0731753200443104,
      0.06935178316517375,
      0.06574794082182078,
      0.0630943190856625,
      0.060566590489209954,
      0.05773419009660425
    ],
    "metrics": {
      "accuracy": 0.9017199017199017,
      "precision": 0.8871287128712871,
      "recall": 0.9511677282377919,
      "f1": 0.9180327868852459
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_06/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6764400078646315,
      0.22274568261603594,
      0.1217771180130698,
      0.0936742779025119,
      0.0721080883129223,
      0.0615293300671718,
      0.05325863679599931,
      0.04843491715728147,
      0.04462846853306816,
      0.041666697394463846,
      0.03890332704297578,
      0.0368660847744654,
      0.03437085519868951,
      0.03278149493545123,
      0.031220835695358988
    ],
    "metrics": {
      "accuracy": 0.9361179361179361,
      "precision": 0.7913043478260869,
      "recall": 0.7647058823529411,
      "f1": 0.7777777777777778
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_06/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.163043845685948,
      0.27966834511989264,
      0.11038826431223775,
      0.05208467259553574,
      0.04835957618760275,
      0.04424576663648353,
      0.03933685310586673,
      0.035980109284791326,
      0.0334903384519956,
      0.03130077395472221,
      0.02956520454002605,
      0.02782113733250112,
      0.02632867595434612,
      0.025112541230233223,
      0.023690931536125056
    ],
    "metrics": {
      "accuracy": 0.9680589680589681,
      "precision": 0.6875,
      "recall": 0.75,
      "f1": 0.717391304347826
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_06/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7120083643460645,
      0.23409648408435454,
      0.15796854699077809,
      0.1223036938601428,
      0.10168604673464345,
      0.08941716244156947,
      0.08180396607867232,
      0.07537845226826968,
      0.06929132876368028,
      0.0646221012064189,
      0.061735805552203635,
      0.05825807805367093,
      0.0548310211239016,
      0.05245917150610918,
      0.04921820496165489
    ],
    "metrics": {
      "accuracy": 0.8992628992628993,
      "precision": 0.8791423001949318,
      "recall": 0.9575371549893843,
      "f1": 0.9166666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_07/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3584168824730042,
      0.1348609133025287,
      0.07935114062502838,
      0.05784646643378062,
      0.04631190989273284,
      0.03856588939650769,
      0.033815615968852464,
      0.029454585637692834,
      0.027218128500875963,
      0.024122486458981976,
      0.0221792427630225,
      0.020086094889095206,
      0.018430201716592914,
      0.016919311926220402,
      0.015619836456782825
    ],
    "metrics": {
      "accuracy": 0.9459459459459459,
      "precision": 0.8571428571428571,
      "recall": 0.7563025210084033,
      "f1": 0.8035714285714286
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_07/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6965630875888692,
      0.1519835327606757,
      0.06636164745419136,
      0.044033515473271924,
      0.04086299738108119,
      0.03615262702454737,
      0.031886887395159,
      0.028745827100710313,
      0.026475840612763903,
      0.02446834890132731,
      0.02252141855516754,
      0.02101287598282591,
      0.01949694397453236,
      0.018257927633628733,
      0.017106682682204447
    ],
    "metrics": {
      "accuracy": 0.9680589680589681,
      "precision": 0.7045454545454546,
      "recall": 0.7045454545454546,
      "f1": 0.7045454545454546
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_07/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0439809956675568,
      0.30459575584896137,
      0.17251923687627918,
      0.12293471267013123,
      0.09995529455481869,
      0.08673638877909658,
      0.07592607541159792,
      0.07084952344964868,
      0.0650483959832707,
      0.06118846374100881,
      0.05656069227085717,
      0.053630604113495614,
      0.05056397396885011,
      0.04830415503493374,
      0.04538510342713607
    ],
    "metrics": {
      "accuracy": 0.8882063882063882,
      "precision": 0.8725490196078431,
      "recall": 0.9447983014861996,
      "f1": 0.9072375127420998
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_08/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0771215485559928,
      0.3498283096497872,
      0.17826584915531615,
      0.10705577937055734,
      0.07958625531199849,
      0.06006290572317871,
      0.05119625852834062,
      0.045005687617463166,
      0.04042331297220085,
      0.03730255171327099,
      0.03459496952139742,
      0.03223900623983644,
      0.03028541605043958,
      0.028516228556116355,
      0.02673519557378037
    ],
    "metrics": {
      "accuracy": 0.9484029484029484,
      "precision": 0.8666666666666667,
      "recall": 0.7647058823529411,
      "f1": 0.8125
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_08/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3078342550949031,
      0.0729733103478936,
      0.03877770097088755,
      0.03434564034966078,
      0.028439284819187182,
      0.024353046858555594,
      0.021997978437387843,
      0.019399291137678316,
      0.017086297875957234,
      0.0151544020857246,
      0.013810584992841558,
      0.01241227860760565,
      0.011223278550973704,
      0.010309377046509938,
      0.009479869253310005
    ],
    "metrics": {
      "accuracy": 0.9606879606879607,
      "precision": 0.625,
      "recall": 0.6818181818181818,
      "f1": 0.6521739130434783
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_08/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7944186621600086,
      0.26300029938675945,
      0.16350905499170623,
      0.11121961120094005,
      0.08983215625791188,
      0.07464889204066014,
      0.06594913448083768,
      0.05892784026617435,
      0.053866692526058,
      0.04981024223581921,
      0.046146007014197986,
      0.04295669814178666,
      0.04031615742384867,
      0.038108300807174686,
      0.03577572332785132
    ],
    "metrics": {
      "accuracy": 0.902948402948403,
      "precision": 0.8904382470119522,
      "recall": 0.9490445859872612,
      "f1": 0.9188078108941419
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_09/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.32627206319119806,
      0.1044849629864532,
      0.054926924547828875,
      0.040617517414043874,
      0.03204292457000564,
      0.02757718050069324,
      0.023646620440126734,
      0.021077306331965463,
      0.018642573222546442,
      0.016857277954603896,
      0.015062850785517718,
      0.013567182789941873,
      0.012385796733432427,
      0.011037378386578338,
      0.010107094769544316
    ],
    "metrics": {
      "accuracy": 0.9557739557739557,
      "precision": 0.8672566371681416,
      "recall": 0.8235294117647058,
      "f1": 0.8448275862068966
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_09/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3513861038167067,
      0.07754516276502191,
      0.042849787274732015,
      0.032849336071539934,
      0.0271947301604889,
      0.022922904763819252,
      0.018480823934383318,
      0.015569697208946645,
      0.013506468173920897,
      0.011621739302433614,
      0.010218429299203134,
      0.009148953254953731,
      0.008402967359107918,
      0.007476605212307272,
      0.006640180102553307
    ],
    "metrics": {
      "accuracy": 0.9668304668304668,
      "precision": 0.6808510638297872,
      "recall": 0.7272727272727273,
      "f1": 0.7032967032967034
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_09/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.648866047543188,
      0.19723585994475337,
      0.11372349618718236,
      0.08446810410899312,
      0.07039183301334007,
      0.06166470747562077,
      0.05498384848468915,
      0.048664506718032255,
      0.04441272460662567,
      0.042477600967525266,
      0.03728726266067421,
      0.03519810002410051,
      0.0324136940353056,
      0.03014561207062424,
      0.02805623654382918
    ],
    "metrics": {
      "accuracy": 0.9017199017199017,
      "precision": 0.8856015779092702,
      "recall": 0.9532908704883227,
      "f1": 0.918200408997955
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_10/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9981376327291526,
      0.2703042661935425,
      0.11528184885881718,
      0.07922312806871723,
      0.054540943610653536,
      0.04594295610321079,
      0.0373991861697383,
      0.03236009266406477,
      0.029517033320696277,
      0.026628582026309088,
      0.02406225404889002,
      0.022329348104632423,
      0.020535511231909772,
      0.01921182911036576,
      0.018024054641824966
    ],
    "metrics": {
      "accuracy": 0.9434889434889435,
      "precision": 0.8288288288288288,
      "recall": 0.773109243697479,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_10/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.39033366955355026,
      0.07550552300549485,
      0.044452644876450294,
      0.03248763977189696,
      0.027005721403297555,
      0.023439143318555785,
      0.020071598059957205,
      0.017481523760640955,
      0.015066002820265803,
      0.013427250365412141,
      0.01153945413535324,
      0.01027446713450093,
      0.009129688868791357,
      0.008227822401210231,
      0.007395986668966912
    ],
    "metrics": {
      "accuracy": 0.9656019656019657,
      "precision": 0.66,
      "recall": 0.75,
      "f1": 0.7021276595744681
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_10/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4355200569656681,
      0.1561663977816038,
      0.10548638277225666,
      0.07988638034201762,
      0.06509520049091737,
      0.056877936916682616,
      0.049160523172300144,
      0.04329517142607676,
      0.03886298419932606,
      0.03562497537569892,
      0.03281271430619779,
      0.02979255633120032,
      0.028187081705928336,
      0.02572097975090492,
      0.024307560695346963
    ],
    "metrics": {
      "accuracy": 0.914004914004914,
      "precision": 0.9001996007984032,
      "recall": 0.9575371549893843,
      "f1": 0.9279835390946503
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_11/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.2111734102942597,
      0.32358096398407077,
      0.11595377057115465,
      0.08027782421960812,
      0.055760530055224196,
      0.04264609543939708,
      0.03679212130282767,
      0.03270099902997943,
      0.029607207725755615,
      0.027614194945562675,
      0.02509920675675668,
      0.02361557226975881,
      0.02206780195364349,
      0.020495877708627486,
      0.019352133134382526
    ],
    "metrics": {
      "accuracy": 0.9545454545454546,
      "precision": 0.8867924528301887,
      "recall": 0.7899159663865546,
      "f1": 0.8355555555555556
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_11/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.44243762803848996,
      0.07731489615971002,
      0.04509136341095231,
      0.03230009452129531,
      0.02708672913755111,
      0.023253503719046244,
      0.01896824710703664,
      0.017435562372545288,
      0.014968857365433323,
      0.0124667495974232,
      0.010798902881369626,
      0.009973146568705642,
      0.008869042922113393,
      0.007982014341917018,
      0.007330216602260848
    ],
    "metrics": {
      "accuracy": 0.9643734643734644,
      "precision": 0.6923076923076923,
      "recall": 0.6136363636363636,
      "f1": 0.6506024096385542
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_11/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8616145235119443,
      0.23233016873037363,
      0.14447979795625226,
      0.10393934429847182,
      0.08455120174734441,
      0.07411937338307423,
      0.0645175874253586,
      0.05678246126856239,
      0.05162395531000936,
      0.04682662771872865,
      0.04354962342884773,
      0.039748529916557494,
      0.037237627666424265,
      0.0340799129934925,
      0.03223655589988672
    ],
    "metrics": {
      "accuracy": 0.9041769041769042,
      "precision": 0.90020366598778,
      "recall": 0.9384288747346072,
      "f1": 0.918918918918919
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_12/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.3097332917924724,
      0.4145787759716316,
      0.18136894563785055,
      0.11462735641191411,
      0.07336724222666444,
      0.053095132124707116,
      0.045284670866861096,
      0.03893970617495117,
      0.03435328155639041,
      0.03051740786992776,
      0.027817344831502604,
      0.02532445561799795,
      0.023515779663354296,
      0.021912252256245542,
      0.020479799688895673
    ],
    "metrics": {
      "accuracy": 0.9422604422604423,
      "precision": 0.8214285714285714,
      "recall": 0.773109243697479,
      "f1": 0.7965367965367965
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_12/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.31493876173526836,
      0.062071196134872136,
      0.038299095980902365,
      0.028614626694475728,
      0.022306053457594035,
      0.01790197675225434,
      0.016052001730393728,
      0.013483544306218351,
      0.011079332428229727,
      0.009576616994884051,
      0.007885675499006728,
      0.0070485439628691655,
      0.005789359467206541,
      0.005205438917270375,
      0.004671927544863199
    ],
    "metrics": {
      "accuracy": 0.9643734643734644,
      "precision": 0.6666666666666666,
      "recall": 0.6818181818181818,
      "f1": 0.6741573033707865
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_12/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 13,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0381938346969017,
      0.2572799520356031,
      0.15754514479048096,
      0.1161202667064918,
      0.09046623638800315,
      0.07702933706662514,
      0.06980261995416179,
      0.06205619063554828,
      0.055128494922886316,
      0.04979708102317397,
      0.04667354801045784,
      0.04287902272346809,
      0.03948340749145856,
      0.036746397074449266,
      0.03440056389557219
    ],
    "metrics": {
      "accuracy": 0.9066339066339066,
      "precision": 0.8957915831663327,
      "recall": 0.9490445859872612,
      "f1": 0.9216494845360824
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_13/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 13,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1658750057806253,
      0.2371325706958836,
      0.12086054799178732,
      0.07112881051157298,
      0.050740160264884336,
      0.040229689721663874,
      0.034089186436535066,
      0.030369453201308915,
      0.027022529356822336,
      0.02464148112189573,
      0.02242587234061125,
      0.020226424673346916,
      0.018687131435315675,
      0.017352502884985504,
      0.015995917018526342
    ],
    "metrics": {
      "accuracy": 0.9471744471744472,
      "precision": 0.8725490196078431,
      "recall": 0.7478991596638656,
      "f1": 0.8054298642533937
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_13/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 13,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3471115046215617,
      0.06364550990559244,
      0.04159137983090714,
      0.03277550067385461,
      0.026357350846813035,
      0.021288960980906893,
      0.01800453414723029,
      0.016081376643986154,
      0.012655922956408746,
      0.011176215164000313,
      0.009729489366799276,
      0.007860386454676455,
      0.006841406577533462,
      0.005977420173739237,
      0.005448086074673691
    ],
    "metrics": {
      "accuracy": 0.9717444717444718,
      "precision": 0.7692307692307693,
      "recall": 0.6818181818181818,
      "f1": 0.7228915662650602
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_13/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 14,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0623382752933628,
      0.3188966202859569,
      0.20448275534484414,
      0.13745720202467854,
      0.10940722474961082,
      0.09206504860260824,
      0.08074722286499884,
      0.07238109335567727,
      0.06521875568857015,
      0.05866397121972541,
      0.05415676349843668,
      0.049854503684671335,
      0.04708824197296689,
      0.04406927110448809,
      0.040848938532381106
    ],
    "metrics": {
      "accuracy": 0.9004914004914005,
      "precision": 0.89,
      "recall": 0.9447983014861996,
      "f1": 0.9165808444902163
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_14/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 14,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0329634764709987,
      0.261853283470018,
      0.15574300389634174,
      0.09505606522118007,
      0.06288012129427785,
      0.050794882673913584,
      0.04006893575329302,
      0.03519932822170005,
      0.030831697391594755,
      0.02656310285565398,
      0.023806284840538827,
      0.021274536886205935,
      0.01956200177918325,
      0.017963045736642085,
      0.016248151941167473
    ],
    "metrics": {
      "accuracy": 0.9373464373464373,
      "precision": 0.84,
      "recall": 0.7058823529411765,
      "f1": 0.7671232876712328
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_14/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 14,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9825655480746588,
      0.21296058035420812,
      0.11301985206074835,
      0.049895850601096296,
      0.04202628664371341,
      0.034996468160396026,
      0.02936522584330212,
      0.02658248831597575,
      0.02390446098673394,
      0.02176931707242897,
      0.01960051115047987,
      0.018060596937167734,
      0.0165225688358929,
      0.015349302272313107,
      0.01405996123533223
    ],
    "metrics": {
      "accuracy": 0.9594594594594594,
      "precision": 0.6122448979591837,
      "recall": 0.6818181818181818,
      "f1": 0.6451612903225806
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_14/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 15,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1433647181487885,
      0.3089306161454425,
      0.17348262731523875,
      0.12425636141930907,
      0.10173930439903799,
      0.08776419821525577,
      0.07763469473459081,
      0.06851304732130878,
      0.0628149223056503,
      0.05741228328709097,
      0.05336530491864294,
      0.05006615739084888,
      0.04655928251979587,
      0.04545146004362182,
      0.04144162380289355
    ],
    "metrics": {
      "accuracy": 0.8918918918918919,
      "precision": 0.8732943469785575,
      "recall": 0.9511677282377919,
      "f1": 0.9105691056910569
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_15/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 15,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5264669146379616,
      0.15103418202249527,
      0.08643489394773234,
      0.05561138179184731,
      0.04083988435694568,
      0.03376001437504069,
      0.02802133885088422,
      0.024601824689679887,
      0.021301485453672563,
      0.019173049080151775,
      0.016826814123300452,
      0.015587687803129278,
      0.014072808414421021,
      0.012970845385370947,
      0.011842837029879386
    ],
    "metrics": {
      "accuracy": 0.9348894348894349,
      "precision": 0.8235294117647058,
      "recall": 0.7058823529411765,
      "f1": 0.7601809954751131
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_15/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 15,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.020492979486295,
      0.6920645194010692,
      0.19687748791097195,
      0.10787263061874654,
      0.08005293568536749,
      0.05206307641696058,
      0.047469143185702514,
      0.043014611616637125,
      0.03840496988853665,
      0.03498624919458854,
      0.03227226591129756,
      0.029586307395024845,
      0.02733179542851064,
      0.02511651002998491,
      0.023204184643499128
    ],
    "metrics": {
      "accuracy": 0.9533169533169533,
      "precision": 0.5535714285714286,
      "recall": 0.7045454545454546,
      "f1": 0.62
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_15/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 16,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.3675440193817259,
      0.4180795359901968,
      0.25131704181701214,
      0.1651743085734056,
      0.13443702112536532,
      0.11187236846599818,
      0.09505375713687629,
      0.08515377286562267,
      0.07514074061156426,
      0.06865770296747165,
      0.06194426269030721,
      0.05752652464777744,
      0.052128914744678886,
      0.04855658910119026,
      0.045674200135926685
    ],
    "metrics": {
      "accuracy": 0.8771498771498771,
      "precision": 0.8546845124282982,
      "recall": 0.9490445859872612,
      "f1": 0.8993963782696177
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_16/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 16,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6041341184544622,
      0.17951232179848833,
      0.09534523676172683,
      0.0630580450770723,
      0.046136926842582394,
      0.03779502276379748,
      0.03255424516948274,
      0.02789663817858618,
      0.024358811897843256,
      0.021840874880649924,
      0.019652856260242154,
      0.01756300716646933,
      0.016163561697703527,
      0.01441237116077421,
      0.013340112799740443
    ],
    "metrics": {
      "accuracy": 0.941031941031941,
      "precision": 0.8380952380952381,
      "recall": 0.7394957983193278,
      "f1": 0.7857142857142857
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_16/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 16,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5523754480474639,
      0.1190140561080926,
      0.04955774632115004,
      0.0355719091414433,
      0.02870730897490522,
      0.024521652061706794,
      0.02135251311440638,
      0.018393614824679244,
      0.01634727775118228,
      0.014360222259105175,
      0.012876748908710304,
      0.011664220447729716,
      0.010354611348109577,
      0.009506930559243038,
      0.008752739720159409
    ],
    "metrics": {
      "accuracy": 0.9606879606879607,
      "precision": 0.625,
      "recall": 0.6818181818181818,
      "f1": 0.6521739130434783
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_16/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 17,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9802231379392334,
      0.331814490704142,
      0.17498525249569136,
      0.13957257430523495,
      0.11187027473691184,
      0.09125617384471237,
      0.0754175040867854,
      0.06576115807043931,
      0.06040434784721456,
      0.0542235901028044,
      0.04929177115238855,
      0.045309832744216974,
      0.042155919711982945,
      0.039738202679606364,
      0.03682837797541892
    ],
    "metrics": {
      "accuracy": 0.8894348894348895,
      "precision": 0.8670520231213873,
      "recall": 0.9554140127388535,
      "f1": 0.9090909090909091
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_17/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 17,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6068961520501573,
      0.16749412174469586,
      0.09000713622780761,
      0.058245158965571996,
      0.042140936678305464,
      0.03520440189012764,
      0.028038774751642386,
      0.023590045059193866,
      0.02057610907284998,
      0.018438519039929907,
      0.016018857988761546,
      0.014074350150549694,
      0.012145037321694686,
      0.01090183907813679,
      0.010021246211649558
    ],
    "metrics": {
      "accuracy": 0.9336609336609336,
      "precision": 0.7927927927927928,
      "recall": 0.7394957983193278,
      "f1": 0.7652173913043478
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_17/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 17,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8082658406850454,
      0.19168197760653893,
      0.0835035170301075,
      0.057356866175746646,
      0.04310665853630976,
      0.03513137467932429,
      0.030140332375235352,
      0.025782300530287808,
      0.02203648691613521,
      0.018866392133700012,
      0.016363568420359447,
      0.014151449967913052,
      0.012209113343020557,
      0.010994037693679647,
      0.009694174903696909
    ],
    "metrics": {
      "accuracy": 0.9656019656019657,
      "precision": 0.6666666666666666,
      "recall": 0.7272727272727273,
      "f1": 0.6956521739130435
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_17/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 18,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8805616879655206,
      0.2982510404364841,
      0.18444260982926217,
      0.13444927189150307,
      0.10718466185690306,
      0.0862318001160718,
      0.07942225080092292,
      0.0648816338766477,
      0.057583915468873856,
      0.051108681432314985,
      0.047245358393550194,
      0.04265225956223065,
      0.04037276884160047,
      0.03650610346714232,
      0.03341084780334743
    ],
    "metrics": {
      "accuracy": 0.8734643734643734,
      "precision": 0.851145038167939,
      "recall": 0.9469214437367304,
      "f1": 0.8964824120603015
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_18/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 18,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.057676904649966,
      0.3116967740371811,
      0.20008794587067882,
      0.12025634230501236,
      0.09575318958922517,
      0.07107346857217306,
      0.05966932373540895,
      0.05115895765398024,
      0.04483458200973539,
      0.03987221099352889,
      0.035502859329488996,
      0.03246570631445732,
      0.02985324185222607,
      0.027581517658100536,
      0.02506752611793132
    ],
    "metrics": {
      "accuracy": 0.941031941031941,
      "precision": 0.8446601941747572,
      "recall": 0.7310924369747899,
      "f1": 0.7837837837837838
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_18/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 18,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.9598617496372182,
      0.8209253327095734,
      0.33637085521592164,
      0.14271403002569724,
      0.1189353423075633,
      0.06375589888553569,
      0.053642149932261476,
      0.04604027596732778,
      0.039955571736228164,
      0.036984189860207475,
      0.03340806163910501,
      0.030200092195342018,
      0.02832600074916073,
      0.026406719467043063,
      0.024729048636714733
    ],
    "metrics": {
      "accuracy": 0.9594594594594594,
      "precision": 0.6,
      "recall": 0.75,
      "f1": 0.6666666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_18/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 19,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.3691507706608306,
      0.42613317648830096,
      0.24658950716623218,
      0.16990732395303987,
      0.12453871371884051,
      0.10192390162128585,
      0.08786035476772634,
      0.0752915931006712,
      0.06652291069468806,
      0.059712247799450405,
      0.05258964669097183,
      0.04823901645743616,
      0.04302646878037888,
      0.03939303033381351,
      0.037864752449939365
    ],
    "metrics": {
      "accuracy": 0.8722358722358723,
      "precision": 0.8535645472061657,
      "recall": 0.940552016985138,
      "f1": 0.8949494949494949
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_19/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 19,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6144052753268192,
      0.21439963262380715,
      0.11681446715998188,
      0.07463811807302133,
      0.054756849605784357,
      0.0410678422517328,
      0.03453529254924135,
      0.029006302249425915,
      0.024245881952737934,
      0.021058543290309314,
      0.017968721304636996,
      0.01586313506345784,
      0.013872152120775003,
      0.012725068711495948,
      0.011327697994879546
    ],
    "metrics": {
      "accuracy": 0.9324324324324325,
      "precision": 0.8018867924528302,
      "recall": 0.7142857142857143,
      "f1": 0.7555555555555555
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_19/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 19,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7956359569830482,
      0.1707031927309237,
      0.07249798283536203,
      0.05146103669817318,
      0.04183479067758885,
      0.03363928983866184,
      0.028265682114946723,
      0.02284121667392147,
      0.020269728066369692,
      0.017124150087179754,
      0.015186463107784369,
      0.01378409489934299,
      0.012102760979155682,
      0.010664311632994026,
      0.009798675387604008
    ],
    "metrics": {
      "accuracy": 0.9631449631449631,
      "precision": 0.6521739130434783,
      "recall": 0.6818181818181818,
      "f1": 0.6666666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_19/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 20,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.023365596368799,
      0.3422842848147976,
      0.16951986922776474,
      0.12378312453501478,
      0.09494364169689921,
      0.08005415673240299,
      0.06664453214987881,
      0.06064240597524084,
      0.05133274181306346,
      0.04398773792839233,
      0.040593118467598284,
      0.03521476184820627,
      0.03300836932096135,
      0.030221476187240998,
      0.027631372123867185
    ],
    "metrics": {
      "accuracy": 0.8918918918918919,
      "precision": 0.8762278978388998,
      "recall": 0.9469214437367304,
      "f1": 0.9102040816326531
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_20/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 20,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8811998085151629,
      0.25687967501163744,
      0.15147126233548439,
      0.09309693728656251,
      0.0655929377808996,
      0.05020223246287801,
      0.04047323120724885,
      0.033547258091500116,
      0.028531100283397975,
      0.02410313489290329,
      0.021008990409064742,
      0.018222165571125503,
      0.01602714266667436,
      0.014746381089380131,
      0.01314442095108007
    ],
    "metrics": {
      "accuracy": 0.9471744471744472,
      "precision": 0.8392857142857143,
      "recall": 0.7899159663865546,
      "f1": 0.8138528138528138
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_20/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 20,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9268079568885436,
      0.17375466866414144,
      0.06984293940935997,
      0.05233036741561457,
      0.03670647908373345,
      0.02848488826496888,
      0.024613935133752977,
      0.019739932362056317,
      0.01739389773820805,
      0.01479784145731598,
      0.01242909181281851,
      0.010439720105480504,
      0.012010847971363514,
      0.006955685126797329,
      0.0063279061479810965
    ],
    "metrics": {
      "accuracy": 0.9606879606879607,
      "precision": 0.6304347826086957,
      "recall": 0.6590909090909091,
      "f1": 0.6444444444444445
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_20/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 21,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9885791932465826,
      0.3438784295772875,
      0.1698837907196165,
      0.1328061999778034,
      0.10371293596783004,
      0.08036180496889078,
      0.0720948683716552,
      0.0572832273291396,
      0.050753317939876745,
      0.04346647606599428,
      0.03723935836861523,
      0.03286604183071824,
      0.029469530967425495,
      0.02679148144611172,
      0.02396242895259957
    ],
    "metrics": {
      "accuracy": 0.8992628992628993,
      "precision": 0.8882235528942116,
      "recall": 0.9447983014861996,
      "f1": 0.9156378600823045
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_21/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 21,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      4.532027043705263,
      1.488373182231925,
      0.4983914537297334,
      0.32199384039000933,
      0.25242070259677396,
      0.15937439303457687,
      0.1317800293480019,
      0.10169598853168285,
      0.08166890760816058,
      0.07139521513826821,
      0.0643859311385035,
      0.057284236523299115,
      0.05187194467856036,
      0.0475708252587362,
      0.04349491475523739
    ],
    "metrics": {
      "accuracy": 0.9373464373464373,
      "precision": 0.8207547169811321,
      "recall": 0.7310924369747899,
      "f1": 0.7733333333333333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_21/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 21,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.0050562804362957,
      0.7170571514143177,
      0.20818944958908422,
      0.17180017036328118,
      0.08818402691939278,
      0.07459044781084591,
      0.06693630651099221,
      0.05789669654671527,
      0.051124180133937325,
      0.04539516972248832,
      0.04079450415093945,
      0.037727366872485235,
      0.03454562304467736,
      0.0310612495712999,
      0.027676935740035925
    ],
    "metrics": {
      "accuracy": 0.952088452088452,
      "precision": 0.5510204081632653,
      "recall": 0.6136363636363636,
      "f1": 0.5806451612903226
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_21/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 22,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.2318565828891974,
      0.6603957818174766,
      0.3533074322730962,
      0.2390384764300973,
      0.16470039335473327,
      0.12257772420489524,
      0.11469256639919938,
      0.0890930304916511,
      0.0709968769331464,
      0.05976666646361592,
      0.04968698744016562,
      0.04028766302528165,
      0.035573163738719854,
      0.030802973982637254,
      0.027326362175305575
    ],
    "metrics": {
      "accuracy": 0.9115479115479116,
      "precision": 0.9147609147609148,
      "recall": 0.9341825902335457,
      "f1": 0.9243697478991597
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_22/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 22,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.7826227162042472,
      0.545194871351428,
      0.3231943740468516,
      0.1808452429160259,
      0.11844040467061862,
      0.08848341814654953,
      0.07036590273498394,
      0.058262662462220956,
      0.04778248213034265,
      0.041342341846784154,
      0.03527581725404818,
      0.029248308080192346,
      0.02415963576892007,
      0.02184127285566009,
      0.018559222477898835
    ],
    "metrics": {
      "accuracy": 0.9348894348894349,
      "precision": 0.7844827586206896,
      "recall": 0.7647058823529411,
      "f1": 0.774468085106383
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_22/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 22,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.8192648475299662,
      0.43239884111860427,
      0.15626577276725312,
      0.12174709566996667,
      0.07733303540618391,
      0.06380921649514465,
      0.055624533278362656,
      0.04786162605926643,
      0.041993134391612306,
      0.03739407371120426,
      0.03344607918563678,
      0.03150936479316915,
      0.028400568196327795,
      0.025659550974112336,
      0.019798787315296013
    ],
    "metrics": {
      "accuracy": 0.9484029484029484,
      "precision": 0.5151515151515151,
      "recall": 0.7727272727272727,
      "f1": 0.6181818181818182
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_22/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 23,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.9613590574707125,
      0.6153451900175612,
      0.34707558867777105,
      0.2556661462018212,
      0.20247489855063602,
      0.16975573907369088,
      0.14957814158196986,
      0.12046544059352488,
      0.10384148232783251,
      0.08252193803008856,
      0.06779744842252687,
      0.05686737255478309,
      0.04918381096241092,
      0.04093598834956698,
      0.03967237043192693
    ],
    "metrics": {
      "accuracy": 0.8771498771498771,
      "precision": 0.8702594810379242,
      "recall": 0.9256900212314225,
      "f1": 0.897119341563786
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_23/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 23,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.9532157303432345,
      0.8851479207626497,
      0.5114730290301732,
      0.22507542768788735,
      0.17682062173651242,
      0.1125338191097618,
      0.10171670100933645,
      0.07297969401969519,
      0.0634751536223727,
      0.050085917996955054,
      0.0434710213890614,
      0.03700873922885131,
      0.03081520942250562,
      0.02664838349794343,
      0.022753979479115855
    ],
    "metrics": {
      "accuracy": 0.9312039312039312,
      "precision": 0.7560975609756098,
      "recall": 0.7815126050420168,
      "f1": 0.768595041322314
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_23/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 23,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.5247955119190013,
      0.22639758751068875,
      0.16562154218696878,
      0.1143859645396047,
      0.07548473228237976,
      0.063211337271432,
      0.054096085091871284,
      0.036613853909661404,
      0.027337399185954236,
      0.021134220817732214,
      0.015297623517240098,
      0.011594453810895688,
      0.00748816258441189,
      0.004044822035441259,
      0.0024150831511660135
    ],
    "metrics": {
      "accuracy": 0.9508599508599509,
      "precision": 0.5344827586206896,
      "recall": 0.7045454545454546,
      "f1": 0.6078431372549019
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_23/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 24,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6679388438942586,
      0.5935647782653269,
      0.5317083534454342,
      0.4807723671352476,
      0.4384183776922119,
      0.4031266888291856,
      0.37325867475982966,
      0.34766440757825146,
      0.3253796693245765,
      0.30583232543587585,
      0.2885229894527802,
      0.27300909425989056,
      0.2591596563478132,
      0.2467253569644753,
      0.23542929902253762
    ],
    "metrics": {
      "accuracy": 0.8882063882063882,
      "precision": 0.8667953667953668,
      "recall": 0.9532908704883227,
      "f1": 0.9079878665318504
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_24/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 24,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6300350740377023,
      0.5442713968844287,
      0.4763127996675505,
      0.4225633827968923,
      0.38048449475160556,
      0.34636131272334203,
      0.3183944230111544,
      0.29460411997008057,
      0.27440329847555817,
      0.2567684800937922,
      0.24105598261097302,
      0.22711204354420667,
      0.21447024675233098,
      0.20306789565047312,
      0.19269235386586145
    ],
    "metrics": {
      "accuracy": 0.9348894348894349,
      "precision": 0.9583333333333334,
      "recall": 0.5798319327731093,
      "f1": 0.7225130890052356
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_24/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 24,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "linear",
    "num_hidden_layers": 0,
    "hidden_units": [],
    "total_params": 1025,
    "activation": "none",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6553672040026272,
      0.5536108366654865,
      0.4724078482531017,
      0.4075693439711582,
      0.3568276538163497,
      0.3165905606525373,
      0.2843506317417901,
      0.2578558405053248,
      0.23561701634982685,
      0.2166131156985629,
      0.20006713335822587,
      0.18562300543527346,
      0.17290735421709894,
      0.16157527843964675,
      0.1515388586198636
    ],
    "metrics": {
      "accuracy": 0.9656019656019657,
      "precision": 0.7857142857142857,
      "recall": 0.5,
      "f1": 0.6111111111111112
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/linear/probes/WAVLM_LARGE/layer_24/nasal.pt"
  }
]
[
  {
    "model": "HUBERT_BASE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5748346454668187,
      0.31737605951165465,
      0.21602494632721467,
      0.18162836309002936,
      0.15928027156328306,
      0.1451019691417288,
      0.13415777516789526,
      0.12639641337305282,
      0.11970626786006926,
      0.11416162225815485,
      0.10825942717968494,
      0.10286272055722345,
      0.09797457298180369,
      0.09392690364717951,
      0.08908252080851321
    ],
    "metrics": {
      "accuracy": 0.8858024691358025,
      "precision": 0.896640826873385,
      "recall": 0.910761154855643,
      "f1": 0.9036458333333334
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_00/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5231710083622685,
      0.2825724008728804,
      0.1932664040631009,
      0.15782991537713395,
      0.13567381989708022,
      0.12117896277632652,
      0.11137207673235282,
      0.10207942228427105,
      0.09443321469872501,
      0.08795189956310943,
      0.08203420266164778,
      0.07626107431387215,
      0.07165811831178663,
      0.06714030028961054,
      0.06297620860786339
    ],
    "metrics": {
      "accuracy": 0.8966049382716049,
      "precision": 0.6555555555555556,
      "recall": 0.6210526315789474,
      "f1": 0.6378378378378379
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_00/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.48831033500908316,
      0.22259002110254314,
      0.1244769421322299,
      0.08293792754654718,
      0.06364769306510776,
      0.05216788001749366,
      0.045825389094628466,
      0.04176082978286831,
      0.03795404362128493,
      0.03508259329593483,
      0.033081984933699626,
      0.030976965982941838,
      0.02952920068404732,
      0.027961882515793974,
      0.02624298875620343
    ],
    "metrics": {
      "accuracy": 0.9444444444444444,
      "precision": 0.7288135593220338,
      "recall": 0.6825396825396826,
      "f1": 0.7049180327868853
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_00/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5829750517361447,
      0.3405364005623644,
      0.21245315701344572,
      0.1649564832862093,
      0.1409299078924755,
      0.12591707774496946,
      0.11610863254701485,
      0.10876424265526727,
      0.10220688917238967,
      0.09825327120200873,
      0.09374828503592957,
      0.08954017323202075,
      0.08616903471854369,
      0.08290935727152755,
      0.07975266390834758
    ],
    "metrics": {
      "accuracy": 0.8811728395061729,
      "precision": 0.8857868020304569,
      "recall": 0.916010498687664,
      "f1": 0.9006451612903226
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_01/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5496986477505937,
      0.31960557792847105,
      0.2113902612965727,
      0.15818928568121465,
      0.12853752192262724,
      0.10904301911770697,
      0.09561838139153331,
      0.08591769367343027,
      0.0787735468515335,
      0.07224542532368308,
      0.06696061116419723,
      0.062193335468604144,
      0.05866381782682961,
      0.055170521682842685,
      0.051690648527338505
    ],
    "metrics": {
      "accuracy": 0.9012345679012346,
      "precision": 0.6666666666666666,
      "recall": 0.6526315789473685,
      "f1": 0.6595744680851063
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_01/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5258130216669796,
      0.26440926170375045,
      0.13702251574621474,
      0.07826921897888443,
      0.05536558283844795,
      0.04442057445479269,
      0.038656240550142475,
      0.03473845505228782,
      0.03191574862706301,
      0.029629344872464044,
      0.027438627955430096,
      0.02590881577852661,
      0.02434510679180919,
      0.022931179509541974,
      0.02173384678476399
    ],
    "metrics": {
      "accuracy": 0.9521604938271605,
      "precision": 0.8076923076923077,
      "recall": 0.6666666666666666,
      "f1": 0.7304347826086957
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_01/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5598686014821783,
      0.3087658991662015,
      0.19171989988814103,
      0.1497477497556152,
      0.12791840426500287,
      0.11217175031014517,
      0.10382525471159867,
      0.09582253730420219,
      0.09019351237233031,
      0.0849742016862125,
      0.08060809694884685,
      0.0766453395644975,
      0.0733741446883985,
      0.07002748972446447,
      0.06708642218558644
    ],
    "metrics": {
      "accuracy": 0.8796296296296297,
      "precision": 0.8796992481203008,
      "recall": 0.9212598425196851,
      "f1": 0.9
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_02/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5501687480043088,
      0.31150067659800196,
      0.20742153803448082,
      0.15040541060125093,
      0.11804806905945185,
      0.09652365421302683,
      0.08254026761518998,
      0.07269264709434292,
      0.06549715434919236,
      0.05972994924134358,
      0.054753875290530954,
      0.05076107173119187,
      0.04697638892040333,
      0.04381735712091344,
      0.04074612610825834
    ],
    "metrics": {
      "accuracy": 0.904320987654321,
      "precision": 0.6853932584269663,
      "recall": 0.6421052631578947,
      "f1": 0.6630434782608695
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_02/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5360830817234908,
      0.2648003421405892,
      0.13985802793582194,
      0.07997087426291241,
      0.05512434441710692,
      0.044144747005666715,
      0.03801680117092174,
      0.03404020675014756,
      0.030999070490611964,
      0.028450767263834907,
      0.026294496741736183,
      0.024477847952311633,
      0.02277190051922237,
      0.021089409084557236,
      0.01974312904396923
    ],
    "metrics": {
      "accuracy": 0.9490740740740741,
      "precision": 0.7586206896551724,
      "recall": 0.6984126984126984,
      "f1": 0.7272727272727273
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_02/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5709845373393336,
      0.3246780682206316,
      0.191672819557965,
      0.13990582910308894,
      0.11584627396040036,
      0.10241086840564773,
      0.09343617871812777,
      0.0868805902816414,
      0.08035333665732328,
      0.07502691633442428,
      0.07084031878168345,
      0.06720236131628268,
      0.06295218231314938,
      0.058952975231413934,
      0.05546709457698416
    ],
    "metrics": {
      "accuracy": 0.8904320987654321,
      "precision": 0.9015544041450777,
      "recall": 0.9133858267716536,
      "f1": 0.9074315514993481
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_03/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5681256558963804,
      0.34392925164530413,
      0.21139488278296564,
      0.1405878305783509,
      0.10089771230645593,
      0.07988133599622706,
      0.06767669922998011,
      0.0580406638207109,
      0.05135845615356132,
      0.046214412375839065,
      0.04167425052469662,
      0.0383917990100873,
      0.03500594253281952,
      0.032227030037096024,
      0.03013435969411209
    ],
    "metrics": {
      "accuracy": 0.9212962962962963,
      "precision": 0.7558139534883721,
      "recall": 0.6842105263157895,
      "f1": 0.7182320441988951
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_03/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5567119902779013,
      0.28980364098630546,
      0.14904348223947836,
      0.08097508667757343,
      0.05086965558908173,
      0.03858530863569697,
      0.03168161801455153,
      0.027808826586844707,
      0.024974166158689012,
      0.022545049377099655,
      0.02064705281066535,
      0.019060843303945443,
      0.017442961755282337,
      0.01620549595904402,
      0.014904308542416825
    ],
    "metrics": {
      "accuracy": 0.9444444444444444,
      "precision": 0.7213114754098361,
      "recall": 0.6984126984126984,
      "f1": 0.7096774193548387
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_03/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5803985721749371,
      0.3401677027348754,
      0.19744335547936095,
      0.13642447444044012,
      0.11048469975991689,
      0.09653261487786619,
      0.08735487974327555,
      0.08028968609515076,
      0.07483311135602341,
      0.0696486624235707,
      0.06525923998342419,
      0.06132429572073912,
      0.05813757794043168,
      0.05407392589836608,
      0.05131705061763679
    ],
    "metrics": {
      "accuracy": 0.8842592592592593,
      "precision": 0.8768472906403941,
      "recall": 0.9343832020997376,
      "f1": 0.9047013977128335
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_04/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5820230899070326,
      0.34071591092244735,
      0.19637288750797616,
      0.12224853221153915,
      0.08635984124227464,
      0.06622778325078117,
      0.05413890942793464,
      0.04649404221378645,
      0.041556251181892545,
      0.03755184272154821,
      0.03427310694807993,
      0.031137505399894055,
      0.0290238392797784,
      0.02701618556833423,
      0.024846181935689216
    ],
    "metrics": {
      "accuracy": 0.9212962962962963,
      "precision": 0.7558139534883721,
      "recall": 0.6842105263157895,
      "f1": 0.7182320441988951
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_04/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5337582785625048,
      0.28203729351161777,
      0.14299366820414255,
      0.07462634690172745,
      0.045072523273525594,
      0.033763922006195574,
      0.027832526666018327,
      0.02395659532057758,
      0.021233468516986716,
      0.01909641258835744,
      0.017331007781982034,
      0.015516625001892896,
      0.014105759096286582,
      0.012889291996961056,
      0.012021433241304884
    ],
    "metrics": {
      "accuracy": 0.9444444444444444,
      "precision": 0.7288135593220338,
      "recall": 0.6825396825396826,
      "f1": 0.7049180327868853
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_04/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6087306569892125,
      0.3714808088973606,
      0.21561746009263244,
      0.13707461509247065,
      0.10291413010608634,
      0.08475525436209544,
      0.07431926601572703,
      0.066279373798731,
      0.06025958024765299,
      0.05509738388771789,
      0.05081761094758484,
      0.047201067518081376,
      0.04420694552329563,
      0.040782446754054874,
      0.038183269582812346
    ],
    "metrics": {
      "accuracy": 0.9182098765432098,
      "precision": 0.9270833333333334,
      "recall": 0.9343832020997376,
      "f1": 0.930718954248366
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_05/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5465270634188734,
      0.3137053812196573,
      0.18424722871465443,
      0.11372063968752869,
      0.07607803210822678,
      0.056147778617862645,
      0.04476081022598329,
      0.03790511616682125,
      0.03277544251745139,
      0.02912932859805088,
      0.026379972785917857,
      0.023447866224007668,
      0.02138000392066692,
      0.019409103553967976,
      0.017497883559657517
    ],
    "metrics": {
      "accuracy": 0.9320987654320988,
      "precision": 0.8227848101265823,
      "recall": 0.6842105263157895,
      "f1": 0.7471264367816092
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_05/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5378449734834005,
      0.28474776640830074,
      0.1510623206353343,
      0.07887439121529925,
      0.04663722615939147,
      0.03381582077002276,
      0.026623980817821694,
      0.02197961868618527,
      0.018918638734527177,
      0.016653944211919593,
      0.014824952602135354,
      0.013015761224820817,
      0.011603412832016772,
      0.010317884397230482,
      0.00927753261204168
    ],
    "metrics": {
      "accuracy": 0.9459876543209876,
      "precision": 0.7258064516129032,
      "recall": 0.7142857142857143,
      "f1": 0.72
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_05/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5959832875681299,
      0.37103546603797216,
      0.21161215946576492,
      0.13225898269354308,
      0.09565760549254053,
      0.07862740453939199,
      0.06856797991579205,
      0.06149516434093052,
      0.05596649985822218,
      0.05134177037073513,
      0.04754457837838976,
      0.0443848582386128,
      0.041051074961966375,
      0.03838342449471626,
      0.03572537513770271
    ],
    "metrics": {
      "accuracy": 0.8996913580246914,
      "precision": 0.9114583333333334,
      "recall": 0.9186351706036745,
      "f1": 0.9150326797385621
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_06/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5526789476622638,
      0.33084918524169765,
      0.19243290640675006,
      0.1151923867518178,
      0.07642312354369474,
      0.05581830419067391,
      0.04415885690163257,
      0.036713268908085496,
      0.03177359041163749,
      0.027985442902656896,
      0.02514984263155278,
      0.022353002363595668,
      0.020101395030345207,
      0.01829322234842117,
      0.016521797393182595
    ],
    "metrics": {
      "accuracy": 0.9351851851851852,
      "precision": 0.8192771084337349,
      "recall": 0.7157894736842105,
      "f1": 0.7640449438202247
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_06/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.565536942105152,
      0.29788702267461836,
      0.15448107752472073,
      0.08001193195605738,
      0.04768727329028272,
      0.03364910648694729,
      0.026233608470675282,
      0.02207008382590545,
      0.019036135281613093,
      0.016761735302668758,
      0.014736137532617174,
      0.013187501531931718,
      0.011840268335596019,
      0.010529310839566102,
      0.009266605933474543
    ],
    "metrics": {
      "accuracy": 0.9429012345679012,
      "precision": 0.7166666666666667,
      "recall": 0.6825396825396826,
      "f1": 0.6991869918699187
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_06/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.592229067315288,
      0.367910136393018,
      0.2127618183257561,
      0.13224981342864833,
      0.0952973035519847,
      0.07660159641802392,
      0.06489261276827588,
      0.0564829274651537,
      0.050732725044977216,
      0.04511674782035953,
      0.04094907455348829,
      0.03747566527231098,
      0.03413448831839596,
      0.031381298469181584,
      0.028872470366109095
    ],
    "metrics": {
      "accuracy": 0.8811728395061729,
      "precision": 0.8877551020408163,
      "recall": 0.9133858267716536,
      "f1": 0.9003880983182406
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_07/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6125683949333263,
      0.3747611031256217,
      0.23106512938481563,
      0.14492118803540724,
      0.09672922015465547,
      0.06966119921622181,
      0.05304967840061657,
      0.0433195904666848,
      0.036781664537764595,
      0.03222136400876955,
      0.028666929086428778,
      0.02561011359593764,
      0.02296657479244362,
      0.02109925397151545,
      0.019151821601391648
    ],
    "metrics": {
      "accuracy": 0.933641975308642,
      "precision": 0.8421052631578947,
      "recall": 0.6736842105263158,
      "f1": 0.7485380116959064
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_07/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5626049433576895,
      0.31532193334344355,
      0.1781757320519147,
      0.09595224993380881,
      0.055920239070141306,
      0.03724782980703067,
      0.027255675115236026,
      0.02165133333009331,
      0.01817079763540547,
      0.015523003908919718,
      0.013756924924992793,
      0.012076165312184738,
      0.010778370559657031,
      0.009755547001248326,
      0.008871415084074514
    ],
    "metrics": {
      "accuracy": 0.9382716049382716,
      "precision": 0.7017543859649122,
      "recall": 0.6349206349206349,
      "f1": 0.6666666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_07/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6192033642188594,
      0.4129696220248638,
      0.25613422423285226,
      0.16118577723554633,
      0.11154823438382143,
      0.088012233044376,
      0.07421456112927087,
      0.06455370363381674,
      0.05715686691604447,
      0.05230294617126334,
      0.04705507973055617,
      0.043137341189940163,
      0.039462005895225534,
      0.036326293975062166,
      0.03347022388840246
    ],
    "metrics": {
      "accuracy": 0.8626543209876543,
      "precision": 0.8543689320388349,
      "recall": 0.9238845144356955,
      "f1": 0.8877679697351829
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_08/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.561100651369564,
      0.33821751423165924,
      0.20606293879018006,
      0.12925588927269954,
      0.08658703548525397,
      0.0631706529681969,
      0.048197823933311276,
      0.038863582600877154,
      0.03267252820939611,
      0.027823449901782826,
      0.024216491286522604,
      0.02146355350650938,
      0.019164825417759563,
      0.017121320477473927,
      0.015582586885826092
    ],
    "metrics": {
      "accuracy": 0.9351851851851852,
      "precision": 0.8045977011494253,
      "recall": 0.7368421052631579,
      "f1": 0.7692307692307693
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_08/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5401469341566071,
      0.3066101033350928,
      0.181214977344374,
      0.10371599887725808,
      0.06295349229492711,
      0.04277826112536316,
      0.031486895825935626,
      0.025102490199247304,
      0.02108425919911271,
      0.017852410586506783,
      0.015419308256411576,
      0.013502398380879582,
      0.011973981342913057,
      0.0104067700287997,
      0.009194213406899987
    ],
    "metrics": {
      "accuracy": 0.9382716049382716,
      "precision": 0.6885245901639344,
      "recall": 0.6666666666666666,
      "f1": 0.6774193548387096
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_08/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5934761072604933,
      0.38123304071423797,
      0.22850996265595425,
      0.1449751154167492,
      0.1022847784471985,
      0.08042957271836834,
      0.06738508459698023,
      0.0584785857377865,
      0.05221664874563077,
      0.048341505370222054,
      0.043182816874356364,
      0.04056403191963205,
      0.03689944274879468,
      0.034015004111230616,
      0.031683207979893095
    ],
    "metrics": {
      "accuracy": 0.8796296296296297,
      "precision": 0.8778054862842892,
      "recall": 0.9238845144356955,
      "f1": 0.9002557544757033
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_09/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5593395005444788,
      0.3403486952926841,
      0.20852006760813938,
      0.12699211517221806,
      0.08331317995700475,
      0.05866855358009787,
      0.04415409881687417,
      0.03580863452429161,
      0.030648944058237062,
      0.026501387433655463,
      0.02337730421651014,
      0.02106765484815546,
      0.018821683053112558,
      0.017082665837566048,
      0.015469184312660608
    ],
    "metrics": {
      "accuracy": 0.9166666666666666,
      "precision": 0.759493670886076,
      "recall": 0.631578947368421,
      "f1": 0.6896551724137931
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_09/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.589018171970596,
      0.3321230604851755,
      0.1848895013186555,
      0.09798136759436983,
      0.05722220265616636,
      0.04072510760017276,
      0.031186857311645905,
      0.025130048666081536,
      0.020990898980768957,
      0.017875644472787385,
      0.015519927235304515,
      0.013772385794219803,
      0.01226560527382337,
      0.01098189085289597,
      0.009869989438312035
    ],
    "metrics": {
      "accuracy": 0.941358024691358,
      "precision": 0.7551020408163265,
      "recall": 0.5873015873015873,
      "f1": 0.6607142857142857
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_09/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5815170781059608,
      0.34296351298588584,
      0.19028877807752242,
      0.11712802166069095,
      0.08304215542370615,
      0.06650505445089538,
      0.05573535429682865,
      0.048989545400516435,
      0.044363174630016634,
      0.03978822225126098,
      0.03644732908872555,
      0.03320455159683142,
      0.030919636884002007,
      0.028359005126933037,
      0.026661761610339146
    ],
    "metrics": {
      "accuracy": 0.9027777777777778,
      "precision": 0.9015151515151515,
      "recall": 0.937007874015748,
      "f1": 0.918918918918919
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_10/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5729897736887402,
      0.3271884159019182,
      0.19799662866842554,
      0.1196957197274226,
      0.07931320764049463,
      0.05637718569340509,
      0.04285806432248911,
      0.03538468274986308,
      0.030395066328640377,
      0.026955784865778792,
      0.02445370959663284,
      0.02180356746876157,
      0.019711132463828218,
      0.01774157430611087,
      0.016288627712671186
    ],
    "metrics": {
      "accuracy": 0.933641975308642,
      "precision": 0.7954545454545454,
      "recall": 0.7368421052631579,
      "f1": 0.7650273224043715
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_10/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.570282665550401,
      0.29177717251698587,
      0.14210139577091954,
      0.07050518959975334,
      0.04166169186938097,
      0.02991773571806916,
      0.02381222894439055,
      0.019860209737172525,
      0.016959176249204688,
      0.014969282860777306,
      0.013414915765251648,
      0.0120392559521122,
      0.010914356807349581,
      0.009978203567911419,
      0.008995036763164637
    ],
    "metrics": {
      "accuracy": 0.9475308641975309,
      "precision": 0.7377049180327869,
      "recall": 0.7142857142857143,
      "f1": 0.7258064516129032
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_10/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5833157324197986,
      0.32626370861660564,
      0.17118146721922725,
      0.10370271237575675,
      0.07520415769197851,
      0.06073788177200749,
      0.0532247108392383,
      0.04686484716935921,
      0.04262588751740545,
      0.039082558522343665,
      0.03561342345688874,
      0.03323769178843978,
      0.030741320140497796,
      0.028334832270043672,
      0.02626819658207323
    ],
    "metrics": {
      "accuracy": 0.9089506172839507,
      "precision": 0.917098445595855,
      "recall": 0.9291338582677166,
      "f1": 0.9230769230769231
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_11/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5658357089370708,
      0.3174698666147189,
      0.17348256285147162,
      0.09981672831343451,
      0.06507499300330254,
      0.04724809768290486,
      0.03766981478184097,
      0.03239630824235931,
      0.028234505938322007,
      0.024661940236184284,
      0.02202605702146001,
      0.019696982153424282,
      0.017670632936424957,
      0.015944494234489646,
      0.014338754063062563
    ],
    "metrics": {
      "accuracy": 0.9398148148148148,
      "precision": 0.8255813953488372,
      "recall": 0.7473684210526316,
      "f1": 0.7845303867403315
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_11/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5142991058315781,
      0.24152090275504726,
      0.10932683837165907,
      0.05573022105184529,
      0.03579839522975413,
      0.02751780736527691,
      0.022681278200907675,
      0.019071954413114375,
      0.016343972682659233,
      0.014125352803102311,
      0.012337873073041107,
      0.010881812621305966,
      0.009480159097361513,
      0.008479617356334604,
      0.007640802209827767
    ],
    "metrics": {
      "accuracy": 0.9459876543209876,
      "precision": 0.7413793103448276,
      "recall": 0.6825396825396826,
      "f1": 0.7107438016528925
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_11/nasal.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5735326046430407,
      0.30587740628882637,
      0.16863578453469646,
      0.10934124311437812,
      0.08540928928820975,
      0.07144007086855103,
      0.06306348418648329,
      0.05680047386316023,
      0.052904590927864356,
      0.04895726615043074,
      0.04509539980179073,
      0.042987869943604255,
      0.039503920025927085,
      0.03747943490662631,
      0.035729580018370656
    ],
    "metrics": {
      "accuracy": 0.9058641975308642,
      "precision": 0.9166666666666666,
      "recall": 0.9238845144356955,
      "f1": 0.9202614379084967
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_12/voiced.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.48456056753427124,
      0.2687692139849581,
      0.157763741189499,
      0.09961177648879743,
      0.0643307068756042,
      0.04640170156684347,
      0.03700622334341197,
      0.03129965212772271,
      0.027269261173517134,
      0.024399546251717582,
      0.022160664415450223,
      0.02013697714265613,
      0.018310869575614074,
      0.017025598377236436,
      0.01568204990569649
    ],
    "metrics": {
      "accuracy": 0.9367283950617284,
      "precision": 0.8375,
      "recall": 0.7052631578947368,
      "f1": 0.7657142857142857
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_12/fricative.pt"
  },
  {
    "model": "HUBERT_BASE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3679,
    "test_samples": 648,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46154395192173003,
      0.21382318117123447,
      0.11293662186346484,
      0.060917243133642066,
      0.04194415935329621,
      0.030859040415365593,
      0.02526329347476987,
      0.02163155601653806,
      0.018966932133114567,
      0.016527818431346174,
      0.014951373948648544,
      0.013290439928307437,
      0.012318958623775744,
      0.011134022889093282,
      0.010279979221634192
    ],
    "metrics": {
      "accuracy": 0.9444444444444444,
      "precision": 0.7368421052631579,
      "recall": 0.6666666666666666,
      "f1": 0.7
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_BASE/layer_12/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4159881939036935,
      0.2233352772484443,
      0.17793121295136943,
      0.16093176906016668,
      0.14362245039901134,
      0.13243105836394253,
      0.12662226099048085,
      0.11748992948346393,
      0.10711855683908907,
      0.10007882184192693,
      0.0967921077324149,
      0.09234673736533988,
      0.0830988292267891,
      0.07946104240679681,
      0.07443568458465943
    ],
    "metrics": {
      "accuracy": 0.8720136518771331,
      "precision": 0.8616187989556136,
      "recall": 0.9375,
      "f1": 0.8979591836734694
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_00/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.45954516558428044,
      0.21949046998840316,
      0.17424115506448343,
      0.14218806353694888,
      0.12739876154199573,
      0.11311631351625863,
      0.10378540315842488,
      0.09302750807887,
      0.08595796645263826,
      0.07913364294021863,
      0.07247277661640292,
      0.06879598156147959,
      0.06373874684151196,
      0.05683387376516264,
      0.05178943107937457
    ],
    "metrics": {
      "accuracy": 0.8890784982935154,
      "precision": 0.7447698744769874,
      "recall": 0.7206477732793523,
      "f1": 0.7325102880658436
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_00/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.42396766243778583,
      0.15392186318368395,
      0.10679991571475358,
      0.08066595394376214,
      0.06925026681425525,
      0.06168457525647899,
      0.052940962577808066,
      0.04724507102715131,
      0.04261882560059917,
      0.03848848333250878,
      0.035197319793255265,
      0.03218614611368648,
      0.029932503126881043,
      0.027216202528553873,
      0.02582505435789039
    ],
    "metrics": {
      "accuracy": 0.9633105802047781,
      "precision": 0.7123287671232876,
      "recall": 0.7027027027027027,
      "f1": 0.7074829931972789
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_00/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.32688480025665134,
      0.18505009353311164,
      0.15774853578482934,
      0.1351699398830011,
      0.11187235008362596,
      0.10234609721596416,
      0.09173038361803361,
      0.08605951500409924,
      0.07870914614202262,
      0.07296541027367766,
      0.06735907986021135,
      0.06095180586063919,
      0.057320306093778285,
      0.05292066855527801,
      0.04486728143119184
    ],
    "metrics": {
      "accuracy": 0.8924914675767918,
      "precision": 0.8884408602150538,
      "recall": 0.9389204545454546,
      "f1": 0.9129834254143646
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_01/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4271480300891429,
      0.20251273393681082,
      0.15235224686840662,
      0.12465137250994927,
      0.10601229057171058,
      0.09216047369797513,
      0.08210449092743544,
      0.07355858631375692,
      0.06592957369208703,
      0.0603743987551972,
      0.053878325577559144,
      0.04862899734263128,
      0.044655842272865905,
      0.03964465170677017,
      0.035624681057867195
    ],
    "metrics": {
      "accuracy": 0.8993174061433447,
      "precision": 0.7569721115537849,
      "recall": 0.7692307692307693,
      "f1": 0.7630522088353414
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_01/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5495339559219438,
      0.17146045110679267,
      0.1331653262857263,
      0.0942390491128068,
      0.07154854266278281,
      0.06066528332291046,
      0.05029197107571519,
      0.04376096796358156,
      0.03936636584329986,
      0.035148631139408144,
      0.03225327968601587,
      0.029341336305267036,
      0.026675171285354148,
      0.02459285575473766,
      0.02255405076829266
    ],
    "metrics": {
      "accuracy": 0.9650170648464164,
      "precision": 0.7142857142857143,
      "recall": 0.7432432432432432,
      "f1": 0.7284768211920529
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_01/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5719742691627101,
      0.22662756521683777,
      0.172206174741943,
      0.1414326567439747,
      0.12144790166030246,
      0.10931720208448667,
      0.10077002935339069,
      0.09339230331420298,
      0.08478872528736515,
      0.07804943546214402,
      0.0717956913213965,
      0.06550651560538821,
      0.06098061483629981,
      0.05591160984922271,
      0.05122967313429193
    ],
    "metrics": {
      "accuracy": 0.886518771331058,
      "precision": 0.8873812754409769,
      "recall": 0.9289772727272727,
      "f1": 0.9077029840388618
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_02/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.580500294962461,
      0.20868703635275349,
      0.15028169927776744,
      0.12955221769045835,
      0.10582603522544817,
      0.09287255723942692,
      0.08171529638296283,
      0.0723007597189953,
      0.06502572900275617,
      0.05735934774150498,
      0.050913777625103164,
      0.04522084608427715,
      0.03994228646188398,
      0.03586205707758072,
      0.03113172003520774
    ],
    "metrics": {
      "accuracy": 0.9052901023890785,
      "precision": 0.7741935483870968,
      "recall": 0.7773279352226721,
      "f1": 0.7757575757575758
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_02/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.45922256990720256,
      0.1104140136757295,
      0.07636547817919861,
      0.059495809420413014,
      0.04074089499553167,
      0.036589049263686384,
      0.032487489908315716,
      0.02756993014612813,
      0.025538833339563704,
      0.02302397864707113,
      0.02074424164256451,
      0.01818234584526242,
      0.01672503314797502,
      0.014435459236264997,
      0.01277882706803972
    ],
    "metrics": {
      "accuracy": 0.9658703071672355,
      "precision": 0.7125,
      "recall": 0.7702702702702703,
      "f1": 0.7402597402597403
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_02/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6024604831866839,
      0.2029152460569559,
      0.15885831900181038,
      0.13272585454074634,
      0.10993883059234572,
      0.09516808060779396,
      0.08679448905679885,
      0.07766774453746735,
      0.06965574747409163,
      0.06312261310135427,
      0.056766399100702594,
      0.05076595101245614,
      0.04596883145495769,
      0.04085993310543595,
      0.03701414400750798
    ],
    "metrics": {
      "accuracy": 0.8890784982935154,
      "precision": 0.8836898395721925,
      "recall": 0.9389204545454546,
      "f1": 0.9104683195592287
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_03/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.303704151935389,
      0.13156165204718856,
      0.09113540302082149,
      0.06936398187783226,
      0.05734464076198126,
      0.0463375181302065,
      0.03910232468203658,
      0.03292300651655223,
      0.02794684889095108,
      0.023446927395612462,
      0.019836308657976885,
      0.016356209237165027,
      0.013636675720179021,
      0.011580098848335881,
      0.009762639774003844
    ],
    "metrics": {
      "accuracy": 0.8976109215017065,
      "precision": 0.7613168724279835,
      "recall": 0.7489878542510121,
      "f1": 0.7551020408163265
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_03/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.559927798847285,
      0.09157336115185771,
      0.08322805736154426,
      0.04444405056158345,
      0.04308078095471368,
      0.03636859489396595,
      0.031546665403577555,
      0.029314701265607705,
      0.026384002472719964,
      0.02378772899433323,
      0.02160471743904315,
      0.019381735480655873,
      0.017619691277170724,
      0.015965421170280172,
      0.014518686082646247
    ],
    "metrics": {
      "accuracy": 0.9701365187713311,
      "precision": 0.7468354430379747,
      "recall": 0.7972972972972973,
      "f1": 0.7712418300653595
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_03/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3004943568120653,
      0.14325234582859048,
      0.10631197531263713,
      0.08068548656663964,
      0.06917843426888014,
      0.06031394784951217,
      0.04874429237081845,
      0.04101533297961852,
      0.03451623603739168,
      0.029069446274135487,
      0.02410907949495546,
      0.020457168770695675,
      0.0175587206882701,
      0.01551132973384777,
      0.013140598795556511
    ],
    "metrics": {
      "accuracy": 0.8813993174061433,
      "precision": 0.8833107191316146,
      "recall": 0.9247159090909091,
      "f1": 0.9035392088827203
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_04/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4244050584518465,
      0.1826617328408854,
      0.11546557602277153,
      0.0911078213660047,
      0.07230096383651254,
      0.058739508506621456,
      0.049349181708934826,
      0.042341135585256304,
      0.03588243323289804,
      0.031170194761388673,
      0.025630084884896535,
      0.021828464349028808,
      0.01790238271680582,
      0.014902109248914884,
      0.012327603514873288
    ],
    "metrics": {
      "accuracy": 0.9010238907849829,
      "precision": 0.7630522088353414,
      "recall": 0.7692307692307693,
      "f1": 0.7661290322580645
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_04/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.1702692227479322,
      0.049327760119628895,
      0.031216336187193394,
      0.024853801354243997,
      0.01877150255336034,
      0.014413401477182904,
      0.011236998116486369,
      0.00975824932054491,
      0.008255933420030668,
      0.005907538608024478,
      0.005246970361935246,
      0.004060086661179436,
      0.003432215678189331,
      0.002848119845949938,
      0.0023512973788834463
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7375,
      "recall": 0.7972972972972973,
      "f1": 0.7662337662337663
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_04/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.40001903894352425,
      0.17364090103650834,
      0.1305481570212572,
      0.09268159222856694,
      0.07221460246795966,
      0.06342361548758414,
      0.052850857381227474,
      0.04569735405478667,
      0.039231689069101745,
      0.03312690641535835,
      0.028967612432135893,
      0.024896435925471378,
      0.021374093647863593,
      0.018465277679373098,
      0.01653716692105499
    ],
    "metrics": {
      "accuracy": 0.8822525597269625,
      "precision": 0.8803763440860215,
      "recall": 0.9303977272727273,
      "f1": 0.9046961325966851
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_05/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.40119889930086866,
      0.14893416659768205,
      0.09400105764674485,
      0.06473058997190242,
      0.04830628069538835,
      0.04018295379279875,
      0.032157455996601615,
      0.02684592695384341,
      0.022698640771174703,
      0.019344298443533886,
      0.016230085982611515,
      0.01345744072680139,
      0.01130045482533407,
      0.009327748037549035,
      0.007990565685658152
    ],
    "metrics": {
      "accuracy": 0.9232081911262798,
      "precision": 0.823045267489712,
      "recall": 0.8097165991902834,
      "f1": 0.8163265306122449
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_05/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3168719605119723,
      0.07137960701571289,
      0.04273605241569928,
      0.03496304123291084,
      0.026087063718790698,
      0.02191625317544555,
      0.01711984632657327,
      0.014594397819440516,
      0.01142938725538625,
      0.009770817571400794,
      0.007951856682530577,
      0.006216339836652271,
      0.005204808170356338,
      0.004224501627829561,
      0.003448924361371938
    ],
    "metrics": {
      "accuracy": 0.9675767918088737,
      "precision": 0.725,
      "recall": 0.7837837837837838,
      "f1": 0.7532467532467533
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_05/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6121354816957961,
      0.18488124456140767,
      0.14032076525066908,
      0.10141321451607523,
      0.08247360354772165,
      0.07294138511561919,
      0.0625990819990735,
      0.05472174006271309,
      0.047227201831461035,
      0.04069758560659839,
      0.03554082139554095,
      0.03102291684152032,
      0.02686852512374399,
      0.024267032402224418,
      0.020981789451498516
    ],
    "metrics": {
      "accuracy": 0.8882252559726962,
      "precision": 0.8866396761133604,
      "recall": 0.9332386363636364,
      "f1": 0.9093425605536333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_06/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.29674261970809274,
      0.09293612407018872,
      0.05459352512237203,
      0.04291686068403016,
      0.03135901300717248,
      0.02322042790578423,
      0.018616671121527113,
      0.014217832764262544,
      0.011250538556815931,
      0.0087943890666431,
      0.006996631908052256,
      0.005809664065276635,
      0.0044654277643242585,
      0.0036636283827340714,
      0.00305660022386791
    ],
    "metrics": {
      "accuracy": 0.9138225255972696,
      "precision": 0.7991803278688525,
      "recall": 0.7894736842105263,
      "f1": 0.7942973523421588
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_06/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5367001605262673,
      0.0740776376338959,
      0.06091839691238365,
      0.046974024858819435,
      0.03404079625395023,
      0.029240429315806837,
      0.02584852916823946,
      0.020989394999579174,
      0.01785066317945393,
      0.014758060411773214,
      0.011987880717792842,
      0.009477618116750774,
      0.0075160783084574434,
      0.005903312548069697,
      0.004700755856124359
    ],
    "metrics": {
      "accuracy": 0.9735494880546075,
      "precision": 0.7866666666666666,
      "recall": 0.7972972972972973,
      "f1": 0.7919463087248322
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_06/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5394597048768145,
      0.1753265012977303,
      0.12158886718379246,
      0.09606542186923774,
      0.07878183173294928,
      0.06581229373549641,
      0.05557168165624192,
      0.04838724231045264,
      0.04110688092090496,
      0.03556859772365345,
      0.02974411269347686,
      0.025283929408870014,
      0.021696846149329478,
      0.018292901030764856,
      0.015578211142957361
    ],
    "metrics": {
      "accuracy": 0.8916382252559727,
      "precision": 0.8851802403204272,
      "recall": 0.9417613636363636,
      "f1": 0.9125946317962835
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_07/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.31325209216765576,
      0.0909572544824212,
      0.05982823714793446,
      0.04176871564461591,
      0.03022240899434341,
      0.023423273866053102,
      0.017528897833729382,
      0.012858565567433417,
      0.010199891101661834,
      0.008008500538676619,
      0.006245473613278848,
      0.005002707188688563,
      0.004105548762906062,
      0.0034430642548607207,
      0.0027933403485971035
    ],
    "metrics": {
      "accuracy": 0.9163822525597269,
      "precision": 0.7944664031620553,
      "recall": 0.8137651821862348,
      "f1": 0.804
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_07/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.43376603789374957,
      0.06557390849090618,
      0.06286520154352915,
      0.03713703865191121,
      0.03068779675933486,
      0.025686970618092886,
      0.019795319431822285,
      0.016341103939143807,
      0.013658837729589542,
      0.011408297150897091,
      0.009271633931983374,
      0.007850413287800086,
      0.006482356720864689,
      0.005439660521435509,
      0.004577297353310707
    ],
    "metrics": {
      "accuracy": 0.9684300341296929,
      "precision": 0.7402597402597403,
      "recall": 0.7702702702702703,
      "f1": 0.7549668874172185
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_07/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5622569063892883,
      0.16597523977606862,
      0.11345602211230073,
      0.0788951743071605,
      0.06693968272661756,
      0.05478401851189774,
      0.04606378969962639,
      0.038747259436301,
      0.03253898430906881,
      0.027857554871896863,
      0.023064505309388396,
      0.019467109332054762,
      0.016393680638759185,
      0.014141560440559987,
      0.01162385847236837
    ],
    "metrics": {
      "accuracy": 0.8899317406143344,
      "precision": 0.896551724137931,
      "recall": 0.9232954545454546,
      "f1": 0.9097270818754374
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_08/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2241901475972707,
      0.06022377218033426,
      0.038599922186304925,
      0.024079635828570613,
      0.013498369487444538,
      0.010040790865259884,
      0.00690364693472844,
      0.004758335851484105,
      0.0037860746933687474,
      0.002814371692085611,
      0.002307097218951858,
      0.0018356899266635113,
      0.0015364123553217176,
      0.001299399122805589,
      0.0011162970306870545
    ],
    "metrics": {
      "accuracy": 0.9274744027303754,
      "precision": 0.8432203389830508,
      "recall": 0.805668016194332,
      "f1": 0.8240165631469979
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_08/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3499854212226521,
      0.07164638362351036,
      0.040464034728323856,
      0.031293440843457664,
      0.02126123740539502,
      0.014825012139912353,
      0.010664402399865535,
      0.008718666330378625,
      0.006536354263839968,
      0.004944116628093921,
      0.003981206830272346,
      0.003058041799103731,
      0.0025053366859325798,
      0.0020042279931962175,
      0.0016401824302622737
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7435897435897436,
      "recall": 0.7837837837837838,
      "f1": 0.7631578947368421
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_08/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6599539031866185,
      0.170538845955574,
      0.11366021650892641,
      0.0751566645577362,
      0.05987395430398642,
      0.04903360316360254,
      0.04006614438974413,
      0.03385222052623491,
      0.028128906826648634,
      0.023538250128539478,
      0.019788496514626264,
      0.016124301515394363,
      0.013269521423366832,
      0.010939870863937887,
      0.009017757555137423
    ],
    "metrics": {
      "accuracy": 0.8805460750853242,
      "precision": 0.8831521739130435,
      "recall": 0.9232954545454546,
      "f1": 0.9027777777777778
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_09/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46382529211916085,
      0.13493282668048276,
      0.05947429135245547,
      0.04307255169345939,
      0.03213047967484165,
      0.026694030158324014,
      0.02073441132898924,
      0.017305215372361866,
      0.01393587989343811,
      0.011615074455214085,
      0.009669206943858751,
      0.007525442933737313,
      0.006295423085899681,
      0.005195202579125282,
      0.0042432907182132495
    ],
    "metrics": {
      "accuracy": 0.9266211604095563,
      "precision": 0.8232931726907631,
      "recall": 0.8299595141700404,
      "f1": 0.8266129032258065
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_09/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2292884296668982,
      0.050501969371551506,
      0.029314561045847877,
      0.020512806986343522,
      0.012751183272296348,
      0.008638712760837606,
      0.006457651383928489,
      0.004616736782243453,
      0.0036932252247395864,
      0.002740350020646216,
      0.0021824960645265264,
      0.001635776875136406,
      0.001364069096186937,
      0.0010824759141802966,
      0.0008961104209854224
    ],
    "metrics": {
      "accuracy": 0.9709897610921502,
      "precision": 0.7631578947368421,
      "recall": 0.7837837837837838,
      "f1": 0.7733333333333333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_09/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5466599081804452,
      0.13455517177957219,
      0.09381850269010135,
      0.06310760541084467,
      0.04950086668375895,
      0.03895520826378401,
      0.030978982987883846,
      0.025093093375096336,
      0.020250096002791436,
      0.016553327690681578,
      0.013680251881231795,
      0.01110816629758508,
      0.009379908605198184,
      0.007871761557699069,
      0.006670630843065205
    ],
    "metrics": {
      "accuracy": 0.8916382252559727,
      "precision": 0.8935879945429741,
      "recall": 0.9303977272727273,
      "f1": 0.9116214335421016
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_10/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6220739481077705,
      0.1233665716016817,
      0.07130038672283137,
      0.04274326863336727,
      0.031024868606072276,
      0.02397236660353549,
      0.019118279246856065,
      0.014898199484464116,
      0.011795899397846228,
      0.009576190718778185,
      0.007788575585914839,
      0.006210212834528028,
      0.005132976549388681,
      0.0042983700298701855,
      0.003589241366450377
    ],
    "metrics": {
      "accuracy": 0.924061433447099,
      "precision": 0.8291666666666667,
      "recall": 0.805668016194332,
      "f1": 0.8172484599589322
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_10/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.42696877962678176,
      0.05733916841908709,
      0.05060620898102705,
      0.02761584868653043,
      0.02137861487111998,
      0.016804448248801295,
      0.012796488953777791,
      0.009615901274396262,
      0.007295507002432963,
      0.005799722375280886,
      0.0043342070359555064,
      0.0034655384152071354,
      0.002745903609333569,
      0.0023012882036319523,
      0.0018672033934077651
    ],
    "metrics": {
      "accuracy": 0.9701365187713311,
      "precision": 0.7532467532467533,
      "recall": 0.7837837837837838,
      "f1": 0.7682119205298014
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_10/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4046652461048534,
      0.11091860393769402,
      0.06750968173167124,
      0.04983966767842211,
      0.03365171645916988,
      0.02627230305918778,
      0.019801371184700375,
      0.015359882805230287,
      0.012177625912405773,
      0.009623060622934903,
      0.007914688187928202,
      0.006605678367926631,
      0.005414779900796827,
      0.004622341959814743,
      0.003952858712144236
    ],
    "metrics": {
      "accuracy": 0.8916382252559727,
      "precision": 0.9012517385257302,
      "recall": 0.9204545454545454,
      "f1": 0.9107519325368939
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_11/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.18167488262762907,
      0.03656853684405547,
      0.02134596133637525,
      0.010595172577641714,
      0.00558148228734811,
      0.0029475264521704506,
      0.002103495968535227,
      0.0014972359875702966,
      0.0011828415805975466,
      0.0009487568502635094,
      0.0007866374703152087,
      0.0006786183197617282,
      0.0005965443737645711,
      0.0005357471852982535,
      0.0004802553343794599
    ],
    "metrics": {
      "accuracy": 0.9308873720136519,
      "precision": 0.8577586206896551,
      "recall": 0.805668016194332,
      "f1": 0.8308977035490606
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_11/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.16256106691317554,
      0.03817661019116765,
      0.023523500174572068,
      0.015578638521641801,
      0.00777980294425649,
      0.0038958129751722782,
      0.002402856159136148,
      0.0015989367860040852,
      0.001200947228364561,
      0.0009709316940473757,
      0.0007668941176345619,
      0.000634386353453378,
      0.0005416579886190081,
      0.000468017064563619,
      0.0004191715409235523
    ],
    "metrics": {
      "accuracy": 0.9718430034129693,
      "precision": 0.7808219178082192,
      "recall": 0.7702702702702703,
      "f1": 0.7755102040816326
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_11/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.288973144383182,
      0.07834994070947955,
      0.04493409944512942,
      0.026309236853847187,
      0.015956785013175337,
      0.010754927865739177,
      0.007283847129732291,
      0.005348815638404971,
      0.003816311569656351,
      0.003172476167674992,
      0.0024725016009878773,
      0.002010243183247689,
      0.00167341527413461,
      0.0014570647708155187,
      0.0012666640452928131
    ],
    "metrics": {
      "accuracy": 0.8976109215017065,
      "precision": 0.9033149171270718,
      "recall": 0.9289772727272727,
      "f1": 0.9159663865546218
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_12/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2972119418879656,
      0.05872864796030869,
      0.02823656282245979,
      0.016134075649786177,
      0.009980149758923836,
      0.006151505295355807,
      0.003726834483088758,
      0.0026701636033502696,
      0.0020168676052417876,
      0.0016130980746922338,
      0.0012601610651921087,
      0.0010441719159289765,
      0.0008860622200218276,
      0.0007598150523995804,
      0.0006628156442359053
    ],
    "metrics": {
      "accuracy": 0.9300341296928327,
      "precision": 0.8733031674208145,
      "recall": 0.7813765182186235,
      "f1": 0.8247863247863247
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_12/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.38084407904780054,
      0.051139030352957145,
      0.04110699750662568,
      0.022210671488925266,
      0.01637145460307448,
      0.011447195298750549,
      0.007541013310545193,
      0.0053206885379130315,
      0.0040036248239934125,
      0.002971240503671215,
      0.0024098693430682073,
      0.0018169552580453194,
      0.0015148486901018804,
      0.0012969271943722579,
      0.00109807132388671
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7375,
      "recall": 0.7972972972972973,
      "f1": 0.7662337662337663
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_12/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 13,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4383557862838332,
      0.09362414823915485,
      0.06027985030394303,
      0.04186996045079042,
      0.028437511448749193,
      0.019999540502006648,
      0.013627697041471671,
      0.010709021341459578,
      0.007984142452238337,
      0.006560847352648456,
      0.005229866231039363,
      0.004348194329696949,
      0.0036741135747355384,
      0.003123815127320402,
      0.0026685096036839022
    ],
    "metrics": {
      "accuracy": 0.8882252559726962,
      "precision": 0.9006993006993007,
      "recall": 0.9147727272727273,
      "f1": 0.9076814658210007
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_13/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 13,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4428761667979301,
      0.10831542843031629,
      0.04430532723698639,
      0.022876364581076062,
      0.014887166728544015,
      0.011580593696108851,
      0.006408377907779845,
      0.004441986436770097,
      0.0031934672125434344,
      0.002441091874680117,
      0.001950622466862521,
      0.0016488593515669146,
      0.001386779254039086,
      0.001202588192450546,
      0.001048182140996392
    ],
    "metrics": {
      "accuracy": 0.924061433447099,
      "precision": 0.8590909090909091,
      "recall": 0.7651821862348178,
      "f1": 0.8094218415417559
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_13/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 13,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.32660261054363326,
      0.06485295614489123,
      0.04340392032167964,
      0.023913329115419803,
      0.017536475486232973,
      0.01204344849202664,
      0.006355665903094854,
      0.005701657295781304,
      0.003172618275065717,
      0.002896420481625467,
      0.0015273928006147533,
      0.0016924251494869176,
      0.0010538429256720934,
      0.0009241710432890451,
      0.000836434073423412
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7435897435897436,
      "recall": 0.7837837837837838,
      "f1": 0.7631578947368421
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_13/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 14,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.617389307206804,
      0.13853161118383933,
      0.09482697243615672,
      0.05822295279488172,
      0.04660676116200514,
      0.03039942138913667,
      0.0231943626440049,
      0.017529943699586555,
      0.014083812754621072,
      0.010720804091266354,
      0.00853476052256768,
      0.007133412704734942,
      0.00587422041153041,
      0.005037753010086734,
      0.0042557218376913465
    ],
    "metrics": {
      "accuracy": 0.8907849829351536,
      "precision": 0.8988919667590027,
      "recall": 0.921875,
      "f1": 0.9102384291725105
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_14/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 14,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7738896544556152,
      0.15795235519951617,
      0.08086268105078358,
      0.043612815095771924,
      0.031393887334221146,
      0.01935175606084825,
      0.01442556023654082,
      0.010336009525107081,
      0.007549446051364671,
      0.005561694514312207,
      0.004699315325560298,
      0.003728907098944079,
      0.0029112995077294063,
      0.002463320777658869,
      0.0020991236020508988
    ],
    "metrics": {
      "accuracy": 0.9274744027303754,
      "precision": 0.875,
      "recall": 0.7651821862348178,
      "f1": 0.816414686825054
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_14/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 14,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.25695145569802263,
      0.07647971736158132,
      0.044123188300492985,
      0.019840908254285125,
      0.015514018371049916,
      0.00950052954270104,
      0.005867314916631193,
      0.003895580783133043,
      0.0023540262447064183,
      0.00151076368143329,
      0.0011850527663704485,
      0.0009659748389484801,
      0.0008321974642801029,
      0.0007092215903684613,
      0.000595496468176571
    ],
    "metrics": {
      "accuracy": 0.9701365187713311,
      "precision": 0.76,
      "recall": 0.7702702702702703,
      "f1": 0.7651006711409396
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_14/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 15,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9119535170873363,
      0.22563309016832955,
      0.13441006702121214,
      0.07390926110290219,
      0.05419005673878682,
      0.044106768918583526,
      0.03223726094399523,
      0.025762877383463254,
      0.02017531351442847,
      0.016043481574612745,
      0.012895259570667526,
      0.010299189696774727,
      0.00872458826904998,
      0.007155545131019198,
      0.006000709128256863
    ],
    "metrics": {
      "accuracy": 0.8848122866894198,
      "precision": 0.8945908460471568,
      "recall": 0.9161931818181818,
      "f1": 0.9052631578947369
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_15/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 15,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5530468551559453,
      0.1667506037142705,
      0.06403419802852056,
      0.027821441436993805,
      0.022704342747580507,
      0.014023515481411009,
      0.009875925370335733,
      0.006023489279084328,
      0.004671352849185099,
      0.0033283315968988623,
      0.00249641163613356,
      0.0019381265185327674,
      0.001677385633494303,
      0.0014643271502736788,
      0.0012645954024813847
    ],
    "metrics": {
      "accuracy": 0.9223549488054608,
      "precision": 0.8714285714285714,
      "recall": 0.7408906882591093,
      "f1": 0.8008752735229759
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_15/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 15,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2666214584686336,
      0.06149215402557055,
      0.04569228479112103,
      0.023358681433593802,
      0.012470868207502804,
      0.008238681070347394,
      0.0052868920705485,
      0.0023857379014741837,
      0.0014092023605749566,
      0.0010452940737795734,
      0.0008143467872943593,
      0.0006722689341680917,
      0.0005774230889818934,
      0.0004970147753436808,
      0.00044989489753093624
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7435897435897436,
      "recall": 0.7837837837837838,
      "f1": 0.7631578947368421
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_15/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 16,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3497780548420631,
      0.11207024454569475,
      0.05799521360015061,
      0.04085379885914079,
      0.02910736546574829,
      0.018320713265289876,
      0.014700085219829798,
      0.01035382344605885,
      0.007548527264198809,
      0.007726186616870745,
      0.005735990652408995,
      0.005580720624138316,
      0.004291391661523746,
      0.003948588168815313,
      0.002967800860431251
    ],
    "metrics": {
      "accuracy": 0.8796928327645052,
      "precision": 0.8861454046639232,
      "recall": 0.9176136363636364,
      "f1": 0.9016050244242847
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_16/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 16,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.50764210081695,
      0.11734973474957089,
      0.06892066780539347,
      0.0277606152962506,
      0.02302033368327949,
      0.01246768936557128,
      0.00855311166738288,
      0.006448435552760596,
      0.004336672610636935,
      0.003624868668452987,
      0.0025773917056847668,
      0.002135345860913868,
      0.0016370213853923875,
      0.0014204868344401141,
      0.0012617457164078325
    ],
    "metrics": {
      "accuracy": 0.9189419795221843,
      "precision": 0.88,
      "recall": 0.7125506072874493,
      "f1": 0.7874720357941835
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_16/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 16,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7943972524941285,
      0.10143467244914213,
      0.08240692194318464,
      0.05170606266165454,
      0.028033759601520672,
      0.01875611231786283,
      0.013539594686314835,
      0.009708229296977204,
      0.0064737879437347205,
      0.004596206717585592,
      0.003474904543285186,
      0.0025220026665790703,
      0.0017946243069415693,
      0.0014796938742796713,
      0.0012647570169570734
    ],
    "metrics": {
      "accuracy": 0.9709897610921502,
      "precision": 0.7631578947368421,
      "recall": 0.7837837837837838,
      "f1": 0.7733333333333333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_16/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 17,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6969017035597411,
      0.19475563963977988,
      0.10399619635830208,
      0.06622835323026649,
      0.051927727175071214,
      0.03772465838028056,
      0.03319057186402153,
      0.024728287922092664,
      0.015537979622609218,
      0.012884555117306204,
      0.010508615787916823,
      0.008252849655722195,
      0.007177242833200365,
      0.005933498486309709,
      0.005114698121321572
    ],
    "metrics": {
      "accuracy": 0.8762798634812287,
      "precision": 0.8813096862210096,
      "recall": 0.9176136363636364,
      "f1": 0.8990953375086986
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_17/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 17,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.17447279084502032,
      0.03446699577167371,
      0.021852840611261793,
      0.010992899668212739,
      0.004374746759426037,
      0.0025344316929299046,
      0.0018496512137635244,
      0.0015779226433768091,
      0.0007980239455467865,
      0.0006229466298487039,
      0.00047760168358586513,
      0.00040425421397486674,
      0.00033994947280623875,
      0.0003135662854270557,
      0.00028532873981682656
    ],
    "metrics": {
      "accuracy": 0.9180887372013652,
      "precision": 0.861244019138756,
      "recall": 0.728744939271255,
      "f1": 0.7894736842105263
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_17/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 17,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8212149734422252,
      0.105585230894869,
      0.05830490814705094,
      0.03523541344958599,
      0.026928971543736937,
      0.017116924253328652,
      0.013140646395821236,
      0.009079834750576091,
      0.006561926312945025,
      0.005972374676322029,
      0.004318470003683007,
      0.003802190804590478,
      0.002857040430443415,
      0.002405532281511795,
      0.0021026762972569417
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7435897435897436,
      "recall": 0.7837837837837838,
      "f1": 0.7631578947368421
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_17/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 18,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9717948738768442,
      0.19800186702503014,
      0.10863621104545171,
      0.07568047039521845,
      0.055529151370701385,
      0.04176724105384477,
      0.03316473087849621,
      0.026864123805463897,
      0.02170873453183547,
      0.018323034600767812,
      0.015507418554277272,
      0.013326747432188282,
      0.011316539616365499,
      0.009989372758718265,
      0.008556762299090456
    ],
    "metrics": {
      "accuracy": 0.8771331058020477,
      "precision": 0.8804347826086957,
      "recall": 0.9204545454545454,
      "f1": 0.9
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_18/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 18,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5608912603916592,
      0.12297691062873536,
      0.051671126003056955,
      0.03390309232962703,
      0.019586749506906056,
      0.011233677800288635,
      0.007194186753389063,
      0.005278873348475007,
      0.003410974080442368,
      0.0024966810026935946,
      0.0019095831449018595,
      0.0015634111726056897,
      0.0012813078956318402,
      0.0011404722583375538,
      0.000978043399248601
    ],
    "metrics": {
      "accuracy": 0.9197952218430034,
      "precision": 0.8805970149253731,
      "recall": 0.7165991902834008,
      "f1": 0.7901785714285714
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_18/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 18,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46801576185340005,
      0.06270108806503256,
      0.05852886788916541,
      0.028585951534718584,
      0.01898926017301261,
      0.01175295044927662,
      0.006676875322764391,
      0.004889587516678275,
      0.002828862374746568,
      0.001931750514766613,
      0.0011468807075333928,
      0.0008688717385584113,
      0.0007216836686894422,
      0.000626860094424619,
      0.0005540518428154111
    ],
    "metrics": {
      "accuracy": 0.9692832764505119,
      "precision": 0.7435897435897436,
      "recall": 0.7837837837837838,
      "f1": 0.7631578947368421
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_18/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 19,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0301540061000616,
      0.1935927249130063,
      0.11677350616774061,
      0.07031741283017735,
      0.051881297461481846,
      0.04036020540258369,
      0.03187321551336181,
      0.02547089266205876,
      0.018973450985877795,
      0.014828144884507807,
      0.01252748139210945,
      0.010348176118508336,
      0.008964516180855791,
      0.007925424499749829,
      0.006775763559315127
    ],
    "metrics": {
      "accuracy": 0.8796928327645052,
      "precision": 0.8829931972789116,
      "recall": 0.921875,
      "f1": 0.9020152883947186
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_19/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 19,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5702198169234087,
      0.1527400313972859,
      0.07664641686009321,
      0.035408549699655734,
      0.024819525314923443,
      0.01450991886674431,
      0.010116576288875561,
      0.006693574295656609,
      0.004973485104532996,
      0.0036142442679295197,
      0.0028455705198222646,
      0.0023021057850122033,
      0.0018916239877304225,
      0.0016369670483533686,
      0.0014311655842182173
    ],
    "metrics": {
      "accuracy": 0.924061433447099,
      "precision": 0.898989898989899,
      "recall": 0.7206477732793523,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_19/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 19,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.2213802778209815,
      0.15227011486190678,
      0.10099993405655407,
      0.052504907405219445,
      0.02975713821901982,
      0.026554537549276717,
      0.018527148752041426,
      0.013383948390546149,
      0.01048279902173645,
      0.008197734106966689,
      0.007255979679573435,
      0.004774410344211974,
      0.003973529113857945,
      0.003044443699136182,
      0.002753633866601974
    ],
    "metrics": {
      "accuracy": 0.9684300341296929,
      "precision": 0.7341772151898734,
      "recall": 0.7837837837837838,
      "f1": 0.7581699346405228
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_19/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 20,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.641157496089059,
      0.46015173785073243,
      0.22196458352316858,
      0.11762611307861358,
      0.10052979030247394,
      0.0770791407374983,
      0.05376372602944382,
      0.044191553452855636,
      0.036063308576286326,
      0.030328430077773444,
      0.025621390042204956,
      0.021532451849285712,
      0.018267223906866907,
      0.015912158413155804,
      0.013896366631944629
    ],
    "metrics": {
      "accuracy": 0.878839590443686,
      "precision": 0.8849315068493151,
      "recall": 0.9176136363636364,
      "f1": 0.900976290097629
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_20/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 20,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1227447672630433,
      0.27007652051343944,
      0.09627284609359597,
      0.06071616581889821,
      0.029827727880365425,
      0.02071289494727616,
      0.01431603683719793,
      0.009812486392171084,
      0.006811225818249359,
      0.004975451491292984,
      0.0038148533497694604,
      0.0030973427783505788,
      0.002500993862258086,
      0.0021772390128676714,
      0.0018309523875277899
    ],
    "metrics": {
      "accuracy": 0.9155290102389079,
      "precision": 0.8737373737373737,
      "recall": 0.7004048582995951,
      "f1": 0.7775280898876404
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_20/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 20,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46123210433218187,
      0.081608927264104,
      0.04564510081010344,
      0.035153082643684365,
      0.017559038766373537,
      0.010053044541660122,
      0.007786470353154533,
      0.004376158529142861,
      0.002889330905422651,
      0.0010757969180924432,
      0.0007118815840112344,
      0.0006434732379924645,
      0.0004953397481883496,
      0.0004210729923325782,
      0.0003662780165450105
    ],
    "metrics": {
      "accuracy": 0.9658703071672355,
      "precision": 0.7125,
      "recall": 0.7702702702702703,
      "f1": 0.7402597402597403
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_20/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 21,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.4115491298341256,
      0.354829362424758,
      0.2199092047468024,
      0.08894915800279647,
      0.07593756020444888,
      0.05522713828158666,
      0.041070791784935924,
      0.03260990310096046,
      0.02630072269451972,
      0.021464911968760145,
      0.017905443484048676,
      0.015254888966946784,
      0.012958828869734235,
      0.01117522348189227,
      0.009612020877789854
    ],
    "metrics": {
      "accuracy": 0.8839590443686007,
      "precision": 0.8901098901098901,
      "recall": 0.9204545454545454,
      "f1": 0.9050279329608939
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_21/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 21,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0129852020864094,
      0.22471095478168954,
      0.10662652719760683,
      0.035439372820475414,
      0.02828572254234434,
      0.020033205722887398,
      0.012475280823385925,
      0.0090939240756114,
      0.006054232994934221,
      0.004870345878382713,
      0.0036057851757566135,
      0.0028130432603432976,
      0.0022261312268476055,
      0.00192063525998216,
      0.001594826940213022
    ],
    "metrics": {
      "accuracy": 0.9257679180887372,
      "precision": 0.8603603603603603,
      "recall": 0.7732793522267206,
      "f1": 0.814498933901919
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_21/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 21,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.2907687495088136,
      0.16397727349954147,
      0.11400212522968754,
      0.03877770169289732,
      0.03512022300691465,
      0.024497425594385613,
      0.01856902741252203,
      0.013223759597624032,
      0.010821362188084348,
      0.008431720500472702,
      0.006727192444235199,
      0.005277933733437067,
      0.004043872112762648,
      0.0035755489722902045,
      0.002592055851741832
    ],
    "metrics": {
      "accuracy": 0.9675767918088737,
      "precision": 0.7307692307692307,
      "recall": 0.7702702702702703,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_21/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 22,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      3.2031620721684746,
      0.526713660749343,
      0.2816657807754181,
      0.1148651169211666,
      0.0947693720560142,
      0.07349672945073821,
      0.05416502257035072,
      0.04740021750122167,
      0.04092932968776444,
      0.03461191039318446,
      0.02916986293909128,
      0.025906707739739833,
      0.021827527618572706,
      0.01855816339625635,
      0.01637563527697156
    ],
    "metrics": {
      "accuracy": 0.8950511945392492,
      "precision": 0.9006896551724138,
      "recall": 0.9275568181818182,
      "f1": 0.913925822253324
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_22/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 22,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      4.441176775357542,
      1.0181154274254094,
      0.29120738213137104,
      0.11907124118532376,
      0.07197853544365294,
      0.05416822173358947,
      0.04244197952138606,
      0.03130295328351255,
      0.024002733546692506,
      0.01881626339012934,
      0.01476484784659684,
      0.012245269660057975,
      0.009729546562367443,
      0.008027335760384823,
      0.006224027878671893
    ],
    "metrics": {
      "accuracy": 0.9325938566552902,
      "precision": 0.8962264150943396,
      "recall": 0.7692307692307693,
      "f1": 0.8278867102396514
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_22/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 22,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      5.395545525255574,
      2.8224801332484977,
      0.4167738937240216,
      0.1501825676432976,
      0.1619790055256459,
      0.07239237287634727,
      0.06324228218817417,
      0.04863853871292111,
      0.03452605277281093,
      0.028351488007291523,
      0.023429354276475734,
      0.020166085393664615,
      0.017998211100931326,
      0.015624239384234536,
      0.013738830181913287
    ],
    "metrics": {
      "accuracy": 0.9633105802047781,
      "precision": 0.6867469879518072,
      "recall": 0.7702702702702703,
      "f1": 0.7261146496815286
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_22/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 23,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.5920606551967973,
      0.6516373561323107,
      0.2571935175045694,
      0.13740337144663836,
      0.08902718165185346,
      0.05814461385099017,
      0.03663694871024328,
      0.024948083431063063,
      0.01688517751571435,
      0.011844694370946136,
      0.008041876503754366,
      0.0060858998750877935,
      0.004896903195272026,
      0.0036918579397994984,
      0.002934270833064947
    ],
    "metrics": {
      "accuracy": 0.8950511945392492,
      "precision": 0.905160390516039,
      "recall": 0.921875,
      "f1": 0.9134412385643913
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_23/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 23,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      3.6096634967683174,
      0.7303728659335356,
      0.3426254137569731,
      0.1433192053974159,
      0.08871767184814257,
      0.056012172392994275,
      0.038781132078297705,
      0.026911462304613176,
      0.017646549384504488,
      0.011728452661059824,
      0.007884878188718197,
      0.0051841343181303285,
      0.003548120707430052,
      0.0027814060731586898,
      0.0014842689241123203
    ],
    "metrics": {
      "accuracy": 0.9232081911262798,
      "precision": 0.8257261410788381,
      "recall": 0.805668016194332,
      "f1": 0.8155737704918032
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_23/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 23,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.0229249903887854,
      0.28518220142644807,
      0.2541689588997537,
      0.13171608565058418,
      0.06228789068710473,
      0.04308295567564585,
      0.0332770714717407,
      0.022346490388696988,
      0.01572649006262885,
      0.010350928179276875,
      0.006554215133339417,
      0.004253977110790559,
      0.002897595116658813,
      0.001815064589373071,
      0.0013863052661206054
    ],
    "metrics": {
      "accuracy": 0.962457337883959,
      "precision": 0.6744186046511628,
      "recall": 0.7837837837837838,
      "f1": 0.725
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_23/nasal.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 24,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5802574704243844,
      0.3284169002703573,
      0.17810499380243763,
      0.10909162725836799,
      0.07938343494437462,
      0.06565593969224047,
      0.055777052160103,
      0.04933190809207391,
      0.04424799100800401,
      0.03947112756567564,
      0.03570505794222263,
      0.03213241618177776,
      0.029179903531160532,
      0.026490548369859607,
      0.02401854033858778
    ],
    "metrics": {
      "accuracy": 0.8856655290102389,
      "precision": 0.9036827195467422,
      "recall": 0.90625,
      "f1": 0.9049645390070922
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_24/voiced.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 24,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5498745877657928,
      0.2984787596102087,
      0.16463861974156113,
      0.09283510887821571,
      0.059432518396826145,
      0.042013350538606734,
      0.0320251253881051,
      0.02630331143047937,
      0.02184886410863719,
      0.018974066390474578,
      0.016290887060365647,
      0.014566420470216956,
      0.013055649223043558,
      0.011484698187867761,
      0.01036692584550875
    ],
    "metrics": {
      "accuracy": 0.9257679180887372,
      "precision": 0.8636363636363636,
      "recall": 0.7692307692307693,
      "f1": 0.8137044967880086
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_24/fricative.pt"
  },
  {
    "model": "HUBERT_LARGE",
    "layer": 24,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3569,
    "test_samples": 1172,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5289369508745156,
      0.2641246872777931,
      0.1309985379526915,
      0.06886728277649656,
      0.04438580560914673,
      0.034673877962248835,
      0.028974825502251937,
      0.02496834306902797,
      0.02157352250262481,
      0.0191189790148216,
      0.01692746906405856,
      0.015211474842974604,
      0.013827873753218315,
      0.012618994515135562,
      0.01148293346884739
    ],
    "metrics": {
      "accuracy": 0.9667235494880546,
      "precision": 0.7215189873417721,
      "recall": 0.7702702702702703,
      "f1": 0.7450980392156863
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/HUBERT_LARGE/layer_24/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5509659999900324,
      0.28089820072940663,
      0.19042484937444862,
      0.16352261598941673,
      0.14414808169853735,
      0.12901646199991712,
      0.1190442566512598,
      0.11018406144457733,
      0.10245709746603607,
      0.09666916959903042,
      0.08984819666200775,
      0.08456830236485013,
      0.07998098053697551,
      0.07526169457870241,
      0.07155889561461332
    ],
    "metrics": {
      "accuracy": 0.851063829787234,
      "precision": 0.839622641509434,
      "recall": 0.89,
      "f1": 0.8640776699029126
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_00/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5251341188363386,
      0.27648560330763833,
      0.18442951100663119,
      0.14248891278727366,
      0.11676631102552502,
      0.10236244539839746,
      0.09050189352137882,
      0.08140790969468013,
      0.0732866786253027,
      0.06642574744306436,
      0.06091929017769141,
      0.05546435919963069,
      0.05107503399213523,
      0.04693528490148416,
      0.0431208092222283
    ],
    "metrics": {
      "accuracy": 0.851063829787234,
      "precision": 0.82,
      "recall": 0.6833333333333333,
      "f1": 0.7454545454545455
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_00/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5053519661864327,
      0.23114974770001093,
      0.10821498104689774,
      0.06433806006490318,
      0.04791510094306586,
      0.040090234762690025,
      0.03550844156088571,
      0.03223663450291324,
      0.02994040178929799,
      0.027969768786091784,
      0.026170953295022604,
      0.024394452565963547,
      0.0230776145778685,
      0.02162939027158477,
      0.02020269579265163
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_00/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5599487710109318,
      0.29401565555143544,
      0.18675106026458616,
      0.15078917281158377,
      0.13185085474342462,
      0.11649743722089846,
      0.10521512703190077,
      0.09711560872303447,
      0.0904714449275595,
      0.08436482007390127,
      0.07901410694323883,
      0.0747429020909526,
      0.07031445380600472,
      0.06655247301611276,
      0.06266749037264832
    ],
    "metrics": {
      "accuracy": 0.8829787234042553,
      "precision": 0.8545454545454545,
      "recall": 0.94,
      "f1": 0.8952380952380953
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_01/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5390552229578933,
      0.3058556961021146,
      0.20080273035259197,
      0.1446946443859463,
      0.11274746222571622,
      0.09185393722715592,
      0.07887397679344037,
      0.06973125398296819,
      0.06300272034724763,
      0.05747606461889835,
      0.0524569558321721,
      0.04883009826806294,
      0.04526729245068532,
      0.0418507594374086,
      0.03892613886566427
    ],
    "metrics": {
      "accuracy": 0.8297872340425532,
      "precision": 0.7692307692307693,
      "recall": 0.6666666666666666,
      "f1": 0.7142857142857143
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_01/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.49192464461887214,
      0.21622668208266502,
      0.10920946203969428,
      0.0638508340562823,
      0.048738551980359396,
      0.04132587978200522,
      0.036345672614311444,
      0.03294859919081906,
      0.03008404329537243,
      0.027912151979348935,
      0.025457206323172017,
      0.023483905197912273,
      0.021607183183997358,
      0.019938364351608714,
      0.018463459332895563
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_01/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5658593704158753,
      0.31914054369123324,
      0.186477395163817,
      0.13759594361249805,
      0.11402778611118601,
      0.1004049845856751,
      0.09029944255416586,
      0.08243855980656736,
      0.07557642495695162,
      0.07013725906689226,
      0.06540976049700847,
      0.060863910626270654,
      0.05712889437828228,
      0.05321208923228351,
      0.049719538674486835
    ],
    "metrics": {
      "accuracy": 0.898936170212766,
      "precision": 0.8785046728971962,
      "recall": 0.94,
      "f1": 0.9082125603864735
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_02/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5701318333690674,
      0.3291838672745338,
      0.20320877778876567,
      0.1405098124964549,
      0.10439693601789689,
      0.08133584815846409,
      0.06807777142174336,
      0.05862777787439102,
      0.051749791756095155,
      0.04596021926741619,
      0.04122437045293094,
      0.036897141786594846,
      0.0333196743171234,
      0.030161126923982345,
      0.027368053346577062
    ],
    "metrics": {
      "accuracy": 0.8670212765957447,
      "precision": 0.8070175438596491,
      "recall": 0.7666666666666667,
      "f1": 0.7863247863247863
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_02/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5288444691321651,
      0.25446001595597284,
      0.12628509245192832,
      0.06845815349739326,
      0.04848546279960926,
      0.03967958617674942,
      0.03431455210304008,
      0.030535274082142738,
      0.02750674087106394,
      0.024770658779175784,
      0.022534014545922392,
      0.020507068519174186,
      0.018748462147508776,
      0.01723647139489139,
      0.0159105396599483
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_02/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5637777393056348,
      0.3071845489693129,
      0.17504502114405562,
      0.12613888712823784,
      0.1041194713395212,
      0.09141356910786824,
      0.08107466792375283,
      0.07293089642982974,
      0.06605989359210945,
      0.06086933212047209,
      0.055874723247209344,
      0.05139654746065052,
      0.04756743762164796,
      0.04408422085201882,
      0.040739587615176424
    ],
    "metrics": {
      "accuracy": 0.9202127659574468,
      "precision": 0.9047619047619048,
      "recall": 0.95,
      "f1": 0.926829268292683
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_03/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5407314494704948,
      0.303852709564854,
      0.18718291704138174,
      0.12657778705599443,
      0.09140870602828509,
      0.07065114294285818,
      0.05852956777362244,
      0.05016842804740883,
      0.043748152174813426,
      0.03880708936941435,
      0.035034660953669125,
      0.03141767133219239,
      0.028459344164540934,
      0.025813681197253056,
      0.023404105613930852
    ],
    "metrics": {
      "accuracy": 0.8723404255319149,
      "precision": 0.8,
      "recall": 0.8,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_03/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.585618407927857,
      0.3046335439740273,
      0.14969608728211653,
      0.07691099070790107,
      0.05033594824206404,
      0.03890148369568342,
      0.032830295485876196,
      0.02866910961475051,
      0.02548394394765363,
      0.023039502976277704,
      0.02074543298757297,
      0.01876375986167194,
      0.01706605994756502,
      0.01550050594572032,
      0.014261452802992087
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_03/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5720786885982145,
      0.33755968363470884,
      0.19346900490583802,
      0.1278611842754495,
      0.09764778500070975,
      0.08221173439189654,
      0.07153102116587927,
      0.06436484724952492,
      0.05835024524908242,
      0.05355412914975001,
      0.04909909821584171,
      0.045790057044717405,
      0.04221963284972716,
      0.03926301131337448,
      0.03627188936997909
    ],
    "metrics": {
      "accuracy": 0.8563829787234043,
      "precision": 0.8476190476190476,
      "recall": 0.89,
      "f1": 0.8682926829268293
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_04/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5606170811694081,
      0.321541042025527,
      0.19281595954019454,
      0.12200230311213585,
      0.08255480074543935,
      0.05944042101974846,
      0.04656266248052942,
      0.03859331774054147,
      0.033309939936236474,
      0.02907295168194147,
      0.025848368223623682,
      0.022995805545479964,
      0.02064509388881205,
      0.018415573607426496,
      0.016605012184267316
    ],
    "metrics": {
      "accuracy": 0.8936170212765957,
      "precision": 0.8333333333333334,
      "recall": 0.8333333333333334,
      "f1": 0.8333333333333334
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_04/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5482452633043892,
      0.2831281956349213,
      0.14727368881948086,
      0.0769159569745807,
      0.04851800382156983,
      0.03716298108194589,
      0.030543677563455492,
      0.026574570255518903,
      0.023564227766885153,
      0.021340787860649777,
      0.019415712615418464,
      0.017567980951842418,
      0.016118708479524523,
      0.014622691292635595,
      0.013338155424667712
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.7777777777777778,
      "recall": 0.7777777777777778,
      "f1": 0.7777777777777778
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_04/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5911551104117888,
      0.3591886515976416,
      0.2113028115057725,
      0.1354174603854492,
      0.09934242801984361,
      0.08057946432061995,
      0.06867995196202945,
      0.06067732501494522,
      0.05440909501504709,
      0.04919915685683607,
      0.04472237488690424,
      0.04112701566798841,
      0.03754452003542545,
      0.03423815407104977,
      0.031650636117792195
    ],
    "metrics": {
      "accuracy": 0.8882978723404256,
      "precision": 0.8910891089108911,
      "recall": 0.9,
      "f1": 0.8955223880597015
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_05/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5372737742635659,
      0.31241604884596763,
      0.19651338050985903,
      0.1268063380133208,
      0.08621551471232108,
      0.062055571827068036,
      0.047671857413244055,
      0.039006869767545235,
      0.03288593208921711,
      0.028286383871377854,
      0.024859117550708975,
      0.021823640710020947,
      0.01950733724248299,
      0.01738970895965868,
      0.01548366733166036
    ],
    "metrics": {
      "accuracy": 0.8829787234042553,
      "precision": 0.8166666666666667,
      "recall": 0.8166666666666667,
      "f1": 0.8166666666666667
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_05/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5528270111846167,
      0.2985917952763042,
      0.1605604370093881,
      0.08636663720070764,
      0.05242302341477716,
      0.037610963795978766,
      0.02932222742424931,
      0.02460005818035754,
      0.02120479876729149,
      0.018885760250423825,
      0.01686966974765574,
      0.01519523284728965,
      0.01386813385771339,
      0.012539389008801317,
      0.011433618542057914
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_05/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5877888828082948,
      0.36551317708023,
      0.22144755036859248,
      0.14400219833835112,
      0.10267475248367343,
      0.0801486590047966,
      0.06656722810852637,
      0.058025171153020985,
      0.051229041167184255,
      0.046256801744866405,
      0.0420177847348754,
      0.03807976863677939,
      0.03478761191628726,
      0.03207987326454455,
      0.029334489517947326
    ],
    "metrics": {
      "accuracy": 0.8617021276595744,
      "precision": 0.8363636363636363,
      "recall": 0.92,
      "f1": 0.8761904761904762
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_06/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.594257885280657,
      0.37137357035117863,
      0.24171635173900913,
      0.15878869406534468,
      0.10650985369672863,
      0.07525077903522683,
      0.05694392163951142,
      0.0462077032504025,
      0.038831969103536014,
      0.03355420487422294,
      0.029787428961522984,
      0.02641838731212219,
      0.023654702716707554,
      0.02139652943856217,
      0.019336509709510966
    ],
    "metrics": {
      "accuracy": 0.8776595744680851,
      "precision": 0.8245614035087719,
      "recall": 0.7833333333333333,
      "f1": 0.8034188034188035
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_06/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5535159385739733,
      0.2951247601205166,
      0.16247477761347984,
      0.08851967353762534,
      0.055260214047159514,
      0.03914896077925494,
      0.029783874521305098,
      0.02428779828077972,
      0.02089675325048962,
      0.01833604411363523,
      0.016342212848089725,
      0.014636916184952898,
      0.013192757791894903,
      0.012064705506370673,
      0.01089757178815345
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_06/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5944070389358969,
      0.37642631815793176,
      0.22952123665038,
      0.14666131243916766,
      0.10473885370253572,
      0.08209808968017407,
      0.06859451911782494,
      0.05990373684755247,
      0.052767156737720006,
      0.047618222969880664,
      0.0428403926435046,
      0.039283356323464226,
      0.035732928786520284,
      0.03287755041733837,
      0.030181179924952936
    ],
    "metrics": {
      "accuracy": 0.8936170212765957,
      "precision": 0.8846153846153846,
      "recall": 0.92,
      "f1": 0.9019607843137255
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_07/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.544955802436234,
      0.3324376111773865,
      0.2230520847057887,
      0.14786351437297807,
      0.10135761430509181,
      0.07330998216744615,
      0.05548060446721717,
      0.04560039066752638,
      0.0385405646811782,
      0.033412653156107135,
      0.02963306990549303,
      0.026157841177920527,
      0.023478430150325264,
      0.021177931443900067,
      0.0189932263885653
    ],
    "metrics": {
      "accuracy": 0.8351063829787234,
      "precision": 0.7843137254901961,
      "recall": 0.6666666666666666,
      "f1": 0.7207207207207207
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_07/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5635268319314506,
      0.29585819663664464,
      0.1677097769087498,
      0.09619341377301764,
      0.062131175709841585,
      0.04356929958555626,
      0.03333236311059175,
      0.027444682182692474,
      0.023450670893275752,
      0.020738500977719947,
      0.01855195017317445,
      0.016532616078105595,
      0.015001612382263062,
      0.013559720683178546,
      0.012263536376477547
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_07/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5739980329925507,
      0.34112729727040825,
      0.2011295098609622,
      0.1328779017515825,
      0.09832554634370136,
      0.0794107476620882,
      0.06737610772252083,
      0.059550052130277434,
      0.05353334398455475,
      0.04855059684503976,
      0.04479697567350483,
      0.041411123053715755,
      0.0380123199902406,
      0.035062547755406744,
      0.03229781757238047
    ],
    "metrics": {
      "accuracy": 0.8882978723404256,
      "precision": 0.8691588785046729,
      "recall": 0.93,
      "f1": 0.8985507246376812
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_08/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.56648830399803,
      0.3154104434829722,
      0.20123394431652133,
      0.13339796782996569,
      0.09271957935123179,
      0.06761515813152573,
      0.0528717518522056,
      0.043278478048594186,
      0.03655084180430346,
      0.032147499106952346,
      0.027918170358065413,
      0.024937261869857775,
      0.022296667639584412,
      0.019900754634955286,
      0.01810022850608259
    ],
    "metrics": {
      "accuracy": 0.8085106382978723,
      "precision": 0.7608695652173914,
      "recall": 0.5833333333333334,
      "f1": 0.660377358490566
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_08/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5370048867979011,
      0.2716312876229557,
      0.12795682585696092,
      0.0654375262273035,
      0.04291852864398667,
      0.03284384175013047,
      0.026954712600126135,
      0.02357678249911399,
      0.020825137700418026,
      0.01875392553695481,
      0.017055389329377696,
      0.015533268299627966,
      0.014157038529205433,
      0.013028922576157074,
      0.011960131862745811
    ],
    "metrics": {
      "accuracy": 0.973404255319149,
      "precision": 0.75,
      "recall": 0.6666666666666666,
      "f1": 0.7058823529411765
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_08/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5816954090069276,
      0.32578803074879564,
      0.18106829333297486,
      0.12027729970342732,
      0.09147188926467492,
      0.07508361070285227,
      0.0647975547645177,
      0.05764272478329143,
      0.05139568711051538,
      0.04670899953678388,
      0.042475448517298606,
      0.03894637269872183,
      0.03609562974910361,
      0.03330912683036085,
      0.03120876946677226
    ],
    "metrics": {
      "accuracy": 0.9148936170212766,
      "precision": 0.9117647058823529,
      "recall": 0.93,
      "f1": 0.9207920792079208
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_09/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.587769995277435,
      0.32201494232036637,
      0.1958922674822839,
      0.12885931893454833,
      0.09030425638708445,
      0.0677629082942261,
      0.0543109271385002,
      0.04514525519090962,
      0.0388183703993003,
      0.0340654809180465,
      0.0299796694444303,
      0.026765070204060805,
      0.024133469652054804,
      0.021525115118198383,
      0.01955680259585853
    ],
    "metrics": {
      "accuracy": 0.8031914893617021,
      "precision": 0.7446808510638298,
      "recall": 0.5833333333333334,
      "f1": 0.6542056074766355
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_09/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5231521860532748,
      0.23323367631340908,
      0.09936048155416743,
      0.05340554809278982,
      0.037938634754014613,
      0.031162957897313836,
      0.026941784337172814,
      0.02405977407113564,
      0.021701549259820263,
      0.020002136301726616,
      0.01830649275918303,
      0.016712831817518137,
      0.015421615638296506,
      0.014297789360102528,
      0.013117787823612498
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_09/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5564350138882193,
      0.2865538944774449,
      0.16842316082596306,
      0.1251114063033812,
      0.10087012992864242,
      0.08414018086232786,
      0.07383329498051337,
      0.06593300467024864,
      0.058966830807837656,
      0.05413208633287265,
      0.04910850372544368,
      0.04503050133576088,
      0.04175086590502032,
      0.039080412129292086,
      0.03618541768748348
    ],
    "metrics": {
      "accuracy": 0.9042553191489362,
      "precision": 0.91,
      "recall": 0.91,
      "f1": 0.91
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_10/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5311210436109193,
      0.2805699777217333,
      0.18122483313162388,
      0.13140258859532986,
      0.09877673864876421,
      0.07895428075146328,
      0.06469606985307275,
      0.05329414552355694,
      0.045494771287179846,
      0.039246535402091526,
      0.03450298436832475,
      0.030432861073919456,
      0.027047746914932246,
      0.024483698055325284,
      0.021813018667749085
    ],
    "metrics": {
      "accuracy": 0.8085106382978723,
      "precision": 0.7608695652173914,
      "recall": 0.5833333333333334,
      "f1": 0.660377358490566
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_10/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5140245844303696,
      0.21416024883404433,
      0.09029047296258229,
      0.05008373218766922,
      0.039008170586015384,
      0.03345893228345377,
      0.03017083169939181,
      0.02770514418561715,
      0.0250862463013253,
      0.023192981676822294,
      0.02165881431350285,
      0.020114730753230923,
      0.01886857381998469,
      0.017655649993327523,
      0.016644965895160027
    ],
    "metrics": {
      "accuracy": 0.9680851063829787,
      "precision": 0.6666666666666666,
      "recall": 0.6666666666666666,
      "f1": 0.6666666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_10/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6119763997775876,
      0.45114531382386874,
      0.3639564215349553,
      0.3292055298267929,
      0.30649306763903467,
      0.2888765456969388,
      0.2729105362174061,
      0.2588394362238313,
      0.2457211392401389,
      0.23582121044830412,
      0.22362363071548735,
      0.2146107944385536,
      0.20544303380828868,
      0.19758224559743623,
      0.19222308746889685
    ],
    "metrics": {
      "accuracy": 0.8297872340425532,
      "precision": 0.7786885245901639,
      "recall": 0.95,
      "f1": 0.8558558558558559
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_11/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5770093405419958,
      0.45031910525287944,
      0.3890743820638921,
      0.34618173325077545,
      0.31726130595137925,
      0.293903276989608,
      0.2769027750865314,
      0.26006437681388983,
      0.2454354731457079,
      0.23451847434437575,
      0.22312869247703604,
      0.21262918700472683,
      0.2034373798568781,
      0.1945652315922111,
      0.18615005823391118
    ],
    "metrics": {
      "accuracy": 0.7606382978723404,
      "precision": 0.8,
      "recall": 0.3333333333333333,
      "f1": 0.47058823529411764
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_11/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5983953553824003,
      0.36707949872218476,
      0.19549294086554564,
      0.1121408110231043,
      0.08050524046450185,
      0.06955259714467522,
      0.06438081342938554,
      0.06064814032895719,
      0.05791908048162215,
      0.056150648078562564,
      0.054469504722122156,
      0.05220786887005739,
      0.05120969171016975,
      0.04989292505031139,
      0.048439343103368816
    ],
    "metrics": {
      "accuracy": 0.9787234042553191,
      "precision": 0.8571428571428571,
      "recall": 0.6666666666666666,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_11/nasal.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5526168638601643,
      0.40314320929771685,
      0.32641217120414995,
      0.28537038452086705,
      0.2566340110261028,
      0.23603127671988827,
      0.21761124632081394,
      0.20578172738753664,
      0.20250710517837317,
      0.19663275001937205,
      0.17834177014456085,
      0.17205570838961606,
      0.1693635976731856,
      0.16590750027679232,
      0.1622275877935883
    ],
    "metrics": {
      "accuracy": 0.8829787234042553,
      "precision": 0.8611111111111112,
      "recall": 0.93,
      "f1": 0.8942307692307693
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_12/voiced.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4900345430742639,
      0.39095507716880606,
      0.35221650585473135,
      0.31797695735486686,
      0.2881305977328135,
      0.2635488499462841,
      0.24042856943260885,
      0.22137221268807566,
      0.20361868513150133,
      0.1900809724272636,
      0.1784158922643296,
      0.17105224095530994,
      0.1589961518069712,
      0.15205847999693695,
      0.14422200041056624
    ],
    "metrics": {
      "accuracy": 0.7606382978723404,
      "precision": 0.7272727272727273,
      "recall": 0.4,
      "f1": 0.5161290322580645
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_12/fricative.pt"
  },
  {
    "model": "WAV2VEC2_BASE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3785,
    "test_samples": 188,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3471993566582981,
      0.1406181747642502,
      0.09782027311652623,
      0.08275266916662101,
      0.07089709250977363,
      0.06281770354473921,
      0.05800076523301151,
      0.05442727275655323,
      0.05165979731114412,
      0.04901649139703423,
      0.046946881997892376,
      0.04515820703367104,
      0.04347037853257266,
      0.041972818452978074,
      0.04011472051266871
    ],
    "metrics": {
      "accuracy": 0.9680851063829787,
      "precision": 0.6666666666666666,
      "recall": 0.6666666666666666,
      "f1": 0.6666666666666666
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_BASE/layer_12/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.44661438139852067,
      0.20131825119711025,
      0.17230567101626515,
      0.15229103029021926,
      0.1354367491611153,
      0.12357266399999074,
      0.12054823102052853,
      0.11109006635204907,
      0.10303470511350606,
      0.09815430393922361,
      0.09204736953379375,
      0.08690340138373283,
      0.0841842314398685,
      0.07674777223793093,
      0.07208060056507752
    ],
    "metrics": {
      "accuracy": 0.8768472906403941,
      "precision": 0.8899082568807339,
      "recall": 0.9165354330708662,
      "f1": 0.9030256012412723
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_00/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4349167617899559,
      0.18992105104091095,
      0.13977133591667107,
      0.11291969790848339,
      0.100797255163873,
      0.08929776012319607,
      0.08100937571469437,
      0.07411114828108999,
      0.06710985664102839,
      0.06189719551137114,
      0.057319117052650845,
      0.05196099254893464,
      0.0473506534745571,
      0.043717517919446294,
      0.04008709033435195
    ],
    "metrics": {
      "accuracy": 0.896551724137931,
      "precision": 0.6121212121212121,
      "recall": 0.7112676056338029,
      "f1": 0.6579804560260586
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_00/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4214712494958471,
      0.13714909043751264,
      0.0726866408625303,
      0.05236539422815609,
      0.04281647815433565,
      0.03776651971516847,
      0.033458848557643944,
      0.03141009125683116,
      0.03126760089042444,
      0.02745011509409035,
      0.025238379217565596,
      0.023719197090642935,
      0.022058332153309622,
      0.02060819854676063,
      0.019226752756385343
    ],
    "metrics": {
      "accuracy": 0.9339901477832512,
      "precision": 0.7096774193548387,
      "recall": 0.6226415094339622,
      "f1": 0.6633165829145728
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_00/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46045150411756414,
      0.19428723081327212,
      0.1562301008407429,
      0.13575466896440844,
      0.12031913445514325,
      0.11015328929199737,
      0.10196902489191607,
      0.09356318534741441,
      0.08949863376544784,
      0.08446775690298992,
      0.07959218061118906,
      0.07240052992617324,
      0.07024305307221214,
      0.06388768975589414,
      0.06158228948598836
    ],
    "metrics": {
      "accuracy": 0.8837438423645321,
      "precision": 0.8887218045112782,
      "recall": 0.9307086614173228,
      "f1": 0.9092307692307692
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_01/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4897444540608953,
      0.2181759270274408,
      0.14426451859443637,
      0.11400266499400469,
      0.09306098774612115,
      0.08218993229218798,
      0.07304406121084234,
      0.06524066720931813,
      0.060050353191153164,
      0.05446211965316055,
      0.05011821619526501,
      0.04712299816000825,
      0.04729722731300421,
      0.04296247227287689,
      0.03900768843033142
    ],
    "metrics": {
      "accuracy": 0.8906403940886699,
      "precision": 0.5906432748538012,
      "recall": 0.7112676056338029,
      "f1": 0.645367412140575
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_01/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3798971258537261,
      0.10954483605075081,
      0.05301082809545987,
      0.04238503512867063,
      0.035435108254325685,
      0.03264548716617753,
      0.029547397402267375,
      0.027671400302830166,
      0.02541811461676521,
      0.023786438980921483,
      0.02195561151084725,
      0.020195375099633706,
      0.018273062455929672,
      0.016739266100300895,
      0.015193368102890797
    ],
    "metrics": {
      "accuracy": 0.9320197044334976,
      "precision": 0.7032967032967034,
      "recall": 0.6037735849056604,
      "f1": 0.649746192893401
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_01/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4627143767236673,
      0.1939443231330684,
      0.14890328972210845,
      0.12131135406751711,
      0.1079642660503077,
      0.09623804657082809,
      0.09187147951687472,
      0.08241894115949272,
      0.07569153946811473,
      0.0710978675210575,
      0.06709360745438785,
      0.06150710981628158,
      0.057181106173430786,
      0.05329971959365537,
      0.050277693491233025
    ],
    "metrics": {
      "accuracy": 0.8798029556650246,
      "precision": 0.8857142857142857,
      "recall": 0.9275590551181102,
      "f1": 0.9061538461538462
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_02/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46766348106378997,
      0.21698478893725165,
      0.13574408926792092,
      0.10775685983599058,
      0.08820638545167082,
      0.0776390200362146,
      0.06718909799887533,
      0.060498746420538,
      0.05468954921511732,
      0.05017042543708122,
      0.044985965220386635,
      0.04211069719447984,
      0.040130273717612935,
      0.0359879928936413,
      0.03288116054274039
    ],
    "metrics": {
      "accuracy": 0.8975369458128079,
      "precision": 0.61875,
      "recall": 0.6971830985915493,
      "f1": 0.6556291390728477
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_02/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.41041417900380006,
      0.13836176161166702,
      0.06239612535921821,
      0.042758852453422515,
      0.03610633947006801,
      0.03266498124551988,
      0.029444215733588897,
      0.026714945374278563,
      0.02447513586266219,
      0.02248987828812193,
      0.02083278354631422,
      0.01871439767775701,
      0.017103401420204552,
      0.01569113899396418,
      0.014419399056366937
    ],
    "metrics": {
      "accuracy": 0.9349753694581281,
      "precision": 0.7127659574468085,
      "recall": 0.6320754716981132,
      "f1": 0.67
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_02/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.49821892857056244,
      0.20287397831595835,
      0.14750715231734465,
      0.11803331695847895,
      0.10274314637246885,
      0.09256659545561613,
      0.08518802441058067,
      0.08131730090878346,
      0.07571490975174217,
      0.07067096489081752,
      0.0654580459906784,
      0.06093541409335308,
      0.059630146915727704,
      0.056677335531675255,
      0.054389750858423125
    ],
    "metrics": {
      "accuracy": 0.8866995073891626,
      "precision": 0.891566265060241,
      "recall": 0.9322834645669291,
      "f1": 0.9114703618167821
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_03/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.49279392989058246,
      0.21332015893796144,
      0.1266319311061394,
      0.09439745900786155,
      0.07518041050087382,
      0.06453558838103286,
      0.05807131212256292,
      0.05122875482865565,
      0.04730019759273265,
      0.04185809359222733,
      0.03878240981616513,
      0.03601692350493574,
      0.03232332020585227,
      0.02936152871749738,
      0.02853376607815645
    ],
    "metrics": {
      "accuracy": 0.9133004926108375,
      "precision": 0.6901408450704225,
      "recall": 0.6901408450704225,
      "f1": 0.6901408450704225
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_03/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4528472179521154,
      0.14697986481262376,
      0.060810747177151764,
      0.041522776882920075,
      0.03471138853363053,
      0.03067831746109057,
      0.027905937069330436,
      0.025130232887915296,
      0.022640112377290415,
      0.02057597478800079,
      0.018625903328096396,
      0.01677104361288229,
      0.015391315741160075,
      0.01396046543217824,
      0.012833481566810212
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.7317073170731707,
      "recall": 0.5660377358490566,
      "f1": 0.6382978723404256
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_03/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4752479939249414,
      0.19419241274327784,
      0.12866587140223326,
      0.10603701223792132,
      0.09212096056119226,
      0.0819106594352387,
      0.07311879968131348,
      0.06677401389854437,
      0.06136463558162018,
      0.058834975489371374,
      0.05432855720087432,
      0.04937284720385669,
      0.048681875917843835,
      0.04427720205110196,
      0.039820368379519584
    ],
    "metrics": {
      "accuracy": 0.8798029556650246,
      "precision": 0.8904109589041096,
      "recall": 0.9212598425196851,
      "f1": 0.9055727554179567
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_04/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5248674139917062,
      0.2376873050039825,
      0.13393612992317722,
      0.09212990216188484,
      0.06836745286479055,
      0.05620896539823707,
      0.04832378296062887,
      0.04251052234167042,
      0.03680418664770113,
      0.032842921150894704,
      0.029783594215655095,
      0.026099471262865118,
      0.023632597497089087,
      0.022280675347203033,
      0.020576093313374514
    ],
    "metrics": {
      "accuracy": 0.9251231527093596,
      "precision": 0.7291666666666666,
      "recall": 0.7394366197183099,
      "f1": 0.7342657342657343
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_04/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4606117995491979,
      0.13983892080608828,
      0.051935961611383176,
      0.03508759106811229,
      0.029916729438673302,
      0.026734143363471838,
      0.02345663816036032,
      0.020694009006188518,
      0.018482985978022507,
      0.01688401739917943,
      0.015503916786235455,
      0.014186070042654583,
      0.013068326820756137,
      0.011884382376421521,
      0.011012330502684426
    ],
    "metrics": {
      "accuracy": 0.9369458128078818,
      "precision": 0.7333333333333333,
      "recall": 0.6226415094339622,
      "f1": 0.673469387755102
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_04/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5208306515811223,
      0.22264410280454852,
      0.13503770172761087,
      0.10329548137009639,
      0.08733246906188387,
      0.07608452224665402,
      0.06713439605077548,
      0.0626668178349981,
      0.05632066806917623,
      0.051588376999479255,
      0.04611949536154805,
      0.04202651707584508,
      0.03944117716639986,
      0.03639793598307219,
      0.035970827081650905
    ],
    "metrics": {
      "accuracy": 0.8866995073891626,
      "precision": 0.9012345679012346,
      "recall": 0.9196850393700787,
      "f1": 0.9103663289166017
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_05/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5005773349316827,
      0.21551442463312123,
      0.11438412469840116,
      0.07682346707400853,
      0.05819721665862855,
      0.04678225957393811,
      0.039606631349080816,
      0.03362967316628823,
      0.028977436363346192,
      0.025365926882566836,
      0.022852970834968515,
      0.02117968879825851,
      0.01907011316753821,
      0.016552197564795736,
      0.01536624902895448
    ],
    "metrics": {
      "accuracy": 0.9270935960591133,
      "precision": 0.7266666666666667,
      "recall": 0.7676056338028169,
      "f1": 0.7465753424657534
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_05/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.45578724518211927,
      0.13780850461397806,
      0.04972903540001929,
      0.03267163040008076,
      0.027995452070170162,
      0.02441016262735129,
      0.02096653764453456,
      0.018221712541712287,
      0.016183978514204066,
      0.01513552623014082,
      0.013880552327224257,
      0.012394784536171405,
      0.01104714774473124,
      0.009925829494562919,
      0.009034038612353319
    ],
    "metrics": {
      "accuracy": 0.9339901477832512,
      "precision": 0.7191011235955056,
      "recall": 0.6037735849056604,
      "f1": 0.6564102564102564
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_05/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5364223333937309,
      0.23744340118774088,
      0.12860784298041192,
      0.09455959335423572,
      0.07748803786747674,
      0.06863337088159577,
      0.06101171161535704,
      0.05671934560147679,
      0.05174902525015815,
      0.04650008573591544,
      0.04431825213320038,
      0.041239134911602554,
      0.038046271056246396,
      0.03580344095206987,
      0.03228883414511205
    ],
    "metrics": {
      "accuracy": 0.8906403940886699,
      "precision": 0.9119496855345912,
      "recall": 0.9133858267716536,
      "f1": 0.912667191188041
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_06/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.47076661441464834,
      0.18990175944038376,
      0.09787227184901277,
      0.06201074241436089,
      0.045482180779412844,
      0.03799656453617227,
      0.03179067421028613,
      0.026277173442090154,
      0.022297682718907863,
      0.01942795421773377,
      0.019098656267505603,
      0.018411982772030825,
      0.01767355589263162,
      0.015629118365439433,
      0.01317374010007942
    ],
    "metrics": {
      "accuracy": 0.9221674876847291,
      "precision": 0.7032258064516129,
      "recall": 0.7676056338028169,
      "f1": 0.734006734006734
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_06/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4923722463136234,
      0.16367812850138488,
      0.06132490238861034,
      0.035676614418006666,
      0.02840018313483869,
      0.024770054367172254,
      0.021459858029451315,
      0.019071635945088688,
      0.016874412684881972,
      0.014955600895893107,
      0.013565600614922528,
      0.012204187511082046,
      0.011032125009662391,
      0.009972199105587982,
      0.009002193979341072
    ],
    "metrics": {
      "accuracy": 0.9320197044334976,
      "precision": 0.6907216494845361,
      "recall": 0.6320754716981132,
      "f1": 0.6600985221674877
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_06/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5274934694872668,
      0.2304915471544226,
      0.12845547665271734,
      0.09131980596982212,
      0.07225808911128717,
      0.061050220838956885,
      0.05275954652495084,
      0.046596094962322976,
      0.040841789081321196,
      0.037096064539827465,
      0.03264463413545444,
      0.029399894221899953,
      0.026131783342221108,
      0.02293670445118213,
      0.02042982839563877
    ],
    "metrics": {
      "accuracy": 0.8926108374384236,
      "precision": 0.9201277955271565,
      "recall": 0.9070866141732283,
      "f1": 0.9135606661379857
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_07/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5189646782141973,
      0.23280080231603162,
      0.11252048524958275,
      0.06554145310641656,
      0.04663550149071497,
      0.03691282743727401,
      0.03101607250085828,
      0.026346884399569927,
      0.02328805451815396,
      0.02147862508420902,
      0.019112626248790038,
      0.016518974115354863,
      0.014577604224260412,
      0.012817831428778303,
      0.011369827997656616
    ],
    "metrics": {
      "accuracy": 0.9320197044334976,
      "precision": 0.7449664429530202,
      "recall": 0.7816901408450704,
      "f1": 0.7628865979381443
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_07/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46498691945690196,
      0.146563836531791,
      0.053871913299666216,
      0.03368560708956045,
      0.027503195869377776,
      0.023660599737533903,
      0.020445494569445912,
      0.018128974435443364,
      0.016214385743245192,
      0.014115510259721417,
      0.01261615608496349,
      0.010836274935051262,
      0.00978878095818276,
      0.008632350325200015,
      0.007657041627697007
    ],
    "metrics": {
      "accuracy": 0.9349753694581281,
      "precision": 0.7083333333333334,
      "recall": 0.6415094339622641,
      "f1": 0.6732673267326733
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_07/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5317985842597782,
      0.2381192138568186,
      0.12353807923453666,
      0.08658784854218075,
      0.06853951258878958,
      0.06054027586597485,
      0.0548699609605064,
      0.05107371651895159,
      0.045152654566923335,
      0.04026622429613922,
      0.0371788276146602,
      0.03328660206864085,
      0.03039830402262158,
      0.02758364989073983,
      0.025149541075787717
    ],
    "metrics": {
      "accuracy": 0.9014778325123153,
      "precision": 0.9096477794793262,
      "recall": 0.9354330708661417,
      "f1": 0.922360248447205
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_08/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.47482738174559996,
      0.2056410557799392,
      0.10281760034221031,
      0.05923783288458543,
      0.04015019086506889,
      0.02994401124177031,
      0.024202010172633376,
      0.020394310062116533,
      0.017610472418017005,
      0.016694664135781682,
      0.01668826126599287,
      0.015220708854837018,
      0.012005398515353902,
      0.010054661201408592,
      0.008705862904086172
    ],
    "metrics": {
      "accuracy": 0.9270935960591133,
      "precision": 0.7151898734177216,
      "recall": 0.795774647887324,
      "f1": 0.7533333333333333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_08/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4814782851703279,
      0.15084334680413275,
      0.05543253362395509,
      0.03234981419647582,
      0.025794978891280053,
      0.021488246957350965,
      0.017987616567219766,
      0.016437136961812787,
      0.014334295921729377,
      0.013224214126570074,
      0.011793060945424347,
      0.010706614444955895,
      0.009657567068212086,
      0.008761905477359024,
      0.007816413891633296
    ],
    "metrics": {
      "accuracy": 0.9359605911330049,
      "precision": 0.7204301075268817,
      "recall": 0.6320754716981132,
      "f1": 0.6733668341708543
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_08/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.520257215602246,
      0.22001373868569774,
      0.11665821823386935,
      0.08104976934698149,
      0.06470820004703513,
      0.05614656194260246,
      0.05085603664358278,
      0.04585941470127522,
      0.03964181950114606,
      0.03527369958366631,
      0.03144000383749233,
      0.027623431392818937,
      0.026368812455633175,
      0.023364060595012438,
      0.021050677632195796
    ],
    "metrics": {
      "accuracy": 0.8926108374384236,
      "precision": 0.9046153846153846,
      "recall": 0.925984251968504,
      "f1": 0.9151750972762646
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_09/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5009629109394518,
      0.21464587918939354,
      0.10115982473226795,
      0.05824815873624215,
      0.04034407811285799,
      0.03182947481685728,
      0.026044346086701527,
      0.02355119317274675,
      0.019845389594243958,
      0.016884179140887433,
      0.015763430095115195,
      0.018280000971253558,
      0.014115689379624877,
      0.011678679601142281,
      0.010270619658634603
    ],
    "metrics": {
      "accuracy": 0.941871921182266,
      "precision": 0.7902097902097902,
      "recall": 0.795774647887324,
      "f1": 0.7929824561403509
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_09/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.48513085807459505,
      0.16064763362635537,
      0.06014476507241706,
      0.03460920748618171,
      0.026341107053233316,
      0.02155269241086891,
      0.018167661334751714,
      0.015729477557861905,
      0.013847701535289308,
      0.012197215869891202,
      0.01056608148731828,
      0.009162604656854742,
      0.007996131950238633,
      0.00703966449688181,
      0.0060167616094563186
    ],
    "metrics": {
      "accuracy": 0.9359605911330049,
      "precision": 0.7204301075268817,
      "recall": 0.6320754716981132,
      "f1": 0.6733668341708543
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_09/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5342321164059837,
      0.23708288234521807,
      0.1269678486433716,
      0.08556568550456758,
      0.06744927595939662,
      0.057126974952187895,
      0.049966710825499736,
      0.04513605395099793,
      0.04000238749583012,
      0.036359341438457246,
      0.03342937615008669,
      0.030971468835965913,
      0.026938324449506494,
      0.02492168205932113,
      0.022048014556148045
    ],
    "metrics": {
      "accuracy": 0.8926108374384236,
      "precision": 0.9021406727828746,
      "recall": 0.9291338582677166,
      "f1": 0.9154383242823895
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_10/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.46881047627602257,
      0.19788384561806174,
      0.09470232508024021,
      0.05640298024728027,
      0.03837636971944257,
      0.029183082562713906,
      0.02393708488493745,
      0.02071195551351621,
      0.018725491123186253,
      0.016013290566957227,
      0.014373965139327947,
      0.01252710497215741,
      0.011070094211671986,
      0.009466181611100475,
      0.00822558002572228
    ],
    "metrics": {
      "accuracy": 0.9389162561576355,
      "precision": 0.7631578947368421,
      "recall": 0.8169014084507042,
      "f1": 0.7891156462585034
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_10/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4560498319339224,
      0.1470875107948965,
      0.05941164008860278,
      0.0349637190844874,
      0.026756203149824593,
      0.022635563548881344,
      0.02014706505532183,
      0.017915192642958624,
      0.016037829720784092,
      0.014081891364007776,
      0.012888062930436305,
      0.012808019329517709,
      0.01133526980256471,
      0.009794475683372293,
      0.008642833715193799
    ],
    "metrics": {
      "accuracy": 0.9369458128078818,
      "precision": 0.71,
      "recall": 0.6698113207547169,
      "f1": 0.6893203883495146
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_10/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5185924731628386,
      0.24142575290394622,
      0.13753248994700465,
      0.09454459328400461,
      0.07287464877409948,
      0.06118740531257315,
      0.05362484175453886,
      0.0467443355294641,
      0.041587646588311634,
      0.03743810430788267,
      0.03811660834544253,
      0.03230992647873398,
      0.029479369139324595,
      0.025610178261169767,
      0.024470279780616392
    ],
    "metrics": {
      "accuracy": 0.8926108374384236,
      "precision": 0.9109375,
      "recall": 0.9181102362204724,
      "f1": 0.9145098039215687
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_11/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5111113302595397,
      0.22599559385855772,
      0.10963432272880691,
      0.06738754350310218,
      0.04548326801931759,
      0.03411059404576295,
      0.02769585222294786,
      0.022878337502892327,
      0.02032705616009863,
      0.018758811590125025,
      0.015981045243565067,
      0.013637877828402863,
      0.011901226078890203,
      0.01038469574943061,
      0.009067763819506294
    ],
    "metrics": {
      "accuracy": 0.9339901477832512,
      "precision": 0.7551020408163265,
      "recall": 0.7816901408450704,
      "f1": 0.7681660899653979
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_11/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4719118117460584,
      0.15993473906266062,
      0.0650594781784965,
      0.03925145556866462,
      0.029026657997158426,
      0.024060221967078396,
      0.02124900874550199,
      0.01842912668749236,
      0.01632187080864957,
      0.015216454928818254,
      0.013444904714740214,
      0.011846358603810753,
      0.01066690330075002,
      0.009504545380431034,
      0.008499193071823702
    ],
    "metrics": {
      "accuracy": 0.9448275862068966,
      "precision": 0.7717391304347826,
      "recall": 0.6698113207547169,
      "f1": 0.7171717171717171
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_11/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5513041207004452,
      0.2662869086556157,
      0.14955836393331226,
      0.10343799313679956,
      0.07821588938916489,
      0.06512779580465314,
      0.057256696536270205,
      0.05176993973625416,
      0.045404092141961123,
      0.0407917860121443,
      0.037438515530398675,
      0.03490617176068952,
      0.032387190357036376,
      0.027798861248929496,
      0.02471976526019646
    ],
    "metrics": {
      "accuracy": 0.8975369458128079,
      "precision": 0.9028831562974203,
      "recall": 0.937007874015748,
      "f1": 0.919629057187017
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_12/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5184538132431105,
      0.24809138911912976,
      0.1229081191184448,
      0.07091575330974653,
      0.046733470447877436,
      0.0340364681928318,
      0.027333058387949197,
      0.022213041171472818,
      0.02358021858274689,
      0.020668183362183686,
      0.017468681251449597,
      0.014530814140828692,
      0.012621388642679787,
      0.010974275555533881,
      0.009469367543859743
    ],
    "metrics": {
      "accuracy": 0.9349753694581281,
      "precision": 0.7567567567567568,
      "recall": 0.7887323943661971,
      "f1": 0.7724137931034483
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_12/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.47226810234075106,
      0.15494346661580896,
      0.06360227050171995,
      0.03841766370898964,
      0.028988003128639053,
      0.024711073772501913,
      0.02095729416633577,
      0.01891414177013236,
      0.0170535555995557,
      0.015332735486720738,
      0.013287112911275673,
      0.0117121792855025,
      0.010330699970352353,
      0.009880630527442409,
      0.009328720627295839
    ],
    "metrics": {
      "accuracy": 0.9339901477832512,
      "precision": 0.7010309278350515,
      "recall": 0.6415094339622641,
      "f1": 0.6699507389162561
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_12/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 13,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5329154501331149,
      0.2484833048445036,
      0.14152223630460015,
      0.0979532145438432,
      0.07534641595944308,
      0.06296409336421793,
      0.05435371064268816,
      0.04665997196504862,
      0.0412921133464063,
      0.03678414434855004,
      0.03337870120506868,
      0.031214169537715636,
      0.029457748316001363,
      0.028778588846119488,
      0.025389252487477174
    ],
    "metrics": {
      "accuracy": 0.8906403940886699,
      "precision": 0.899390243902439,
      "recall": 0.9291338582677166,
      "f1": 0.9140201394268009
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_13/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 13,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.520417260380663,
      0.23534590601921082,
      0.11980138601028358,
      0.07163283225159235,
      0.047853939763561844,
      0.035529608479662286,
      0.028072470884739197,
      0.024687286374517756,
      0.0215277458058665,
      0.018836059776802968,
      0.016665584486689925,
      0.01489096683065647,
      0.01292196163943765,
      0.012141282756882527,
      0.010413983309450573
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.7569444444444444,
      "recall": 0.7676056338028169,
      "f1": 0.7622377622377622
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_13/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 13,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4917458008531058,
      0.16234643143960314,
      0.06481154064887779,
      0.04014766719243863,
      0.029409164171201537,
      0.024522854946037738,
      0.021208353047555834,
      0.018726560768188905,
      0.017377097741120246,
      0.015559495360154524,
      0.01345835831196891,
      0.01160718881418036,
      0.010436601602985754,
      0.009081255517921919,
      0.007966923273143996
    ],
    "metrics": {
      "accuracy": 0.9399014778325123,
      "precision": 0.7528089887640449,
      "recall": 0.6320754716981132,
      "f1": 0.6871794871794872
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_13/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 14,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5174820030329961,
      0.22741015131618839,
      0.12468560048665367,
      0.08572207376195784,
      0.06656913715014827,
      0.055605815264326716,
      0.04924320768967395,
      0.044286990124433,
      0.03773106758861991,
      0.0344303132135452,
      0.03251774456026935,
      0.02945453487439829,
      0.02766476822268847,
      0.024997573339191996,
      0.021942335623638946
    ],
    "metrics": {
      "accuracy": 0.8857142857142857,
      "precision": 0.8949771689497716,
      "recall": 0.925984251968504,
      "f1": 0.9102167182662538
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_14/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 14,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4571889926191842,
      0.18400181754804384,
      0.08790952545536522,
      0.05250947435806993,
      0.03722490861062528,
      0.02935512021514187,
      0.024394288130744343,
      0.02109275616684779,
      0.018342541641145533,
      0.01690163475737347,
      0.015174061286203832,
      0.013628287189266028,
      0.011728594211443557,
      0.01031396869631933,
      0.009006798542633528
    ],
    "metrics": {
      "accuracy": 0.9310344827586207,
      "precision": 0.7608695652173914,
      "recall": 0.7394366197183099,
      "f1": 0.75
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_14/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 14,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4398543168468158,
      0.1333477060013861,
      0.05275548894649727,
      0.033797867579638464,
      0.02673161527131609,
      0.02235442646417942,
      0.01978175874716935,
      0.01780899145261196,
      0.01583477467649366,
      0.014583667121192962,
      0.013245744461521321,
      0.011808468372021852,
      0.010619109340651875,
      0.009150321516169653,
      0.008274515316024463
    ],
    "metrics": {
      "accuracy": 0.9389162561576355,
      "precision": 0.7619047619047619,
      "recall": 0.6037735849056604,
      "f1": 0.6736842105263158
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_14/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 15,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4972647395985939,
      0.2058791047772212,
      0.11812947307844901,
      0.08215095977456285,
      0.06490321908961373,
      0.056139602713348793,
      0.048855740579304356,
      0.04141765975978979,
      0.03652410650331723,
      0.03256727044684735,
      0.030106676004599996,
      0.029078969203446506,
      0.025876114408065077,
      0.022300155650839787,
      0.019778213045015477
    ],
    "metrics": {
      "accuracy": 0.8886699507389163,
      "precision": 0.9027777777777778,
      "recall": 0.9212598425196851,
      "f1": 0.911925175370226
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_15/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 15,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5008514129389026,
      0.20801537979053658,
      0.10030023182982223,
      0.05551844492162529,
      0.03641459327861873,
      0.02754339982195657,
      0.022532355749252102,
      0.019066830960275227,
      0.01644340123661337,
      0.014891992918011885,
      0.014579390183380106,
      0.013464103242926753,
      0.012369087811332414,
      0.010364725603786531,
      0.008521382105885038
    ],
    "metrics": {
      "accuracy": 0.9330049261083744,
      "precision": 0.7569444444444444,
      "recall": 0.7676056338028169,
      "f1": 0.7622377622377622
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_15/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 15,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4664853835865401,
      0.14624747235400196,
      0.05568545608474277,
      0.03460274523542033,
      0.027569571918604117,
      0.023708674234758618,
      0.02044112821383056,
      0.017803116179899495,
      0.015554131538325978,
      0.014057330595241689,
      0.012356157419000884,
      0.010994402555506315,
      0.00996289530664507,
      0.008961098742609395,
      0.007815452896115316
    ],
    "metrics": {
      "accuracy": 0.9379310344827586,
      "precision": 0.7362637362637363,
      "recall": 0.6320754716981132,
      "f1": 0.6802030456852792
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_15/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 16,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4814071614491312,
      0.18884507170839654,
      0.11200846733107461,
      0.07769102898227706,
      0.058934201508595345,
      0.04836529486314742,
      0.04116911669558435,
      0.03652875570920902,
      0.03152811683693751,
      0.030962655030789467,
      0.027711547676917588,
      0.026683594624916932,
      0.021599353269939607,
      0.01964896451527062,
      0.020534156454814767
    ],
    "metrics": {
      "accuracy": 0.9103448275862069,
      "precision": 0.9276729559748428,
      "recall": 0.9291338582677166,
      "f1": 0.9284028324154209
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_16/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 16,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4763677119713411,
      0.18324496311824406,
      0.08969786600558051,
      0.05279015314009381,
      0.03480448672687248,
      0.027383411434218494,
      0.021780649686123855,
      0.01849073288185713,
      0.016259806724445807,
      0.013731855122305433,
      0.011261647235643418,
      0.009701713051587612,
      0.00832208424156475,
      0.007198326968925894,
      0.006364371767267585
    ],
    "metrics": {
      "accuracy": 0.9221674876847291,
      "precision": 0.7058823529411765,
      "recall": 0.7605633802816901,
      "f1": 0.7322033898305085
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_16/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 16,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4889028517163031,
      0.13736000795773853,
      0.05056781726179856,
      0.031620499568828835,
      0.02539829747787473,
      0.02199839274566672,
      0.018963073087221533,
      0.016741620560648783,
      0.014567604339023706,
      0.012766855398910197,
      0.011843849113855996,
      0.010540223753865334,
      0.009623745406933976,
      0.008636623950722858,
      0.00759550949553456
    ],
    "metrics": {
      "accuracy": 0.9369458128078818,
      "precision": 0.7386363636363636,
      "recall": 0.6132075471698113,
      "f1": 0.6701030927835051
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_16/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 17,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.464637005395176,
      0.18488491699718704,
      0.1130435289025637,
      0.08047007011904941,
      0.0637257955204747,
      0.05550008462045414,
      0.04752725036066655,
      0.041541235371804965,
      0.03590501064739069,
      0.03486717622365978,
      0.029636007923519347,
      0.02757885768968313,
      0.024600178764364232,
      0.023035537779661427,
      0.02041731545407521
    ],
    "metrics": {
      "accuracy": 0.8975369458128079,
      "precision": 0.9154929577464789,
      "recall": 0.9212598425196851,
      "f1": 0.9183673469387755
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_17/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 17,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.45115480623582066,
      0.17091125907412527,
      0.08878062927987107,
      0.053976108468140264,
      0.03664474184328169,
      0.02911999366991738,
      0.02205597826194565,
      0.018176515925665312,
      0.015812818208642283,
      0.013882766386050308,
      0.012476406225269026,
      0.01030823466602785,
      0.010177773801955572,
      0.009711656497837846,
      0.007695180476434178
    ],
    "metrics": {
      "accuracy": 0.941871921182266,
      "precision": 0.782312925170068,
      "recall": 0.8098591549295775,
      "f1": 0.7958477508650519
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_17/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 17,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.41130601322882065,
      0.09472439594339796,
      0.03978437190859932,
      0.028753187717132044,
      0.023822968488770673,
      0.020617058453565446,
      0.018193536518667914,
      0.015855526038280422,
      0.013902926334590133,
      0.01219276698497111,
      0.010663413544833,
      0.009438705377776042,
      0.00857672537419006,
      0.007435040308389596,
      0.0065441449217942035
    ],
    "metrics": {
      "accuracy": 0.9399014778325123,
      "precision": 0.7368421052631579,
      "recall": 0.660377358490566,
      "f1": 0.6965174129353234
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_17/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 18,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4568844569356818,
      0.1813798484379565,
      0.11716965074519371,
      0.088421715144326,
      0.07390912190451186,
      0.0605593885328631,
      0.051369338452692176,
      0.04378854200744439,
      0.03820533640347318,
      0.03301366179190844,
      0.029810735775245525,
      0.02593024509063718,
      0.02851995261917484,
      0.023787079401665117,
      0.024265267819661512
    ],
    "metrics": {
      "accuracy": 0.8916256157635468,
      "precision": 0.9082426127527217,
      "recall": 0.9196850393700787,
      "f1": 0.9139280125195618
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_18/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 18,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4800782201362779,
      0.1830488747960973,
      0.09311518662936799,
      0.05531382495408408,
      0.04029851549735855,
      0.03145077826140495,
      0.02518299768712382,
      0.020490384705034486,
      0.01702245204732689,
      0.016278429359837417,
      0.014632202757114849,
      0.01170319326691474,
      0.009352991853291142,
      0.008123221486894584,
      0.00707360678881283
    ],
    "metrics": {
      "accuracy": 0.9389162561576355,
      "precision": 0.7816901408450704,
      "recall": 0.7816901408450704,
      "f1": 0.7816901408450704
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_18/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 18,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4504567557672384,
      0.1129096056842903,
      0.04298413463447687,
      0.029960241397827287,
      0.02514688159078566,
      0.021565242831974477,
      0.019117348610715026,
      0.017823846452583114,
      0.016039481387638752,
      0.014494831360414769,
      0.013249005956079946,
      0.011952668421326458,
      0.01093274115467408,
      0.009975365366673206,
      0.009118968114473566
    ],
    "metrics": {
      "accuracy": 0.9458128078817734,
      "precision": 0.7575757575757576,
      "recall": 0.7075471698113207,
      "f1": 0.7317073170731707
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_18/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 19,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4682389722636532,
      0.18495915014080064,
      0.12041657132785406,
      0.08944830766097331,
      0.07446396946339479,
      0.06325225029501888,
      0.055219660843838614,
      0.04937143869842519,
      0.045507120357573524,
      0.04027607698519804,
      0.0360450777052347,
      0.03459923478705071,
      0.02888876423549289,
      0.026310886169714116,
      0.022754409309177354
    ],
    "metrics": {
      "accuracy": 0.896551724137931,
      "precision": 0.906441717791411,
      "recall": 0.9307086614173228,
      "f1": 0.9184149184149184
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_19/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 19,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4352926957805401,
      0.16803136109645347,
      0.09457706035607574,
      0.06367466456961103,
      0.04734414335974902,
      0.037333844314197756,
      0.02933874842078732,
      0.025549319036139842,
      0.02081527512448316,
      0.017802261092011246,
      0.01545483551176466,
      0.013045136786357518,
      0.011322646200079006,
      0.010623848463029412,
      0.010274803665546582
    ],
    "metrics": {
      "accuracy": 0.9300492610837439,
      "precision": 0.7232704402515723,
      "recall": 0.8098591549295775,
      "f1": 0.7641196013289037
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_19/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 19,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4332939470408696,
      0.0991902067978709,
      0.039041178173532615,
      0.030528517973472537,
      0.02633422865039589,
      0.02451715667621127,
      0.021470334437170124,
      0.019117180814120373,
      0.016981076546609297,
      0.015482339847554295,
      0.01421102688253091,
      0.01263338871031917,
      0.01214891583233081,
      0.011501218777322766,
      0.009923550416134979
    ],
    "metrics": {
      "accuracy": 0.9428571428571428,
      "precision": 0.7352941176470589,
      "recall": 0.7075471698113207,
      "f1": 0.7211538461538461
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_19/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 20,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.45750995603624806,
      0.18432298463632527,
      0.1373729248786567,
      0.10596444906868102,
      0.08767853020135716,
      0.07727069630393361,
      0.06824464546232756,
      0.061144908044972246,
      0.06252199406851693,
      0.056713271240118136,
      0.050186677290503336,
      0.04766604296212959,
      0.04334925633217943,
      0.038457820058859615,
      0.0382017645726904
    ],
    "metrics": {
      "accuracy": 0.8847290640394089,
      "precision": 0.8888888888888888,
      "recall": 0.9322834645669291,
      "f1": 0.9100691775557264
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_20/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 20,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4589755865345371,
      0.1861588932965931,
      0.11562509961281787,
      0.08124802285119107,
      0.06537070806832194,
      0.05447645186217001,
      0.04755394754936491,
      0.03996557782396385,
      0.03561597858604632,
      0.03119766715800498,
      0.026966654276088336,
      0.023645572170326253,
      0.021001922681029895,
      0.018385863564186148,
      0.0187112325825664
    ],
    "metrics": {
      "accuracy": 0.9142857142857143,
      "precision": 0.6774193548387096,
      "recall": 0.7394366197183099,
      "f1": 0.7070707070707071
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_20/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 20,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.42791374743480104,
      0.10403653182749768,
      0.04371966444203563,
      0.034745787952670575,
      0.03106360775689463,
      0.028315024685702826,
      0.025713573270761136,
      0.023722104314931377,
      0.021786080320930712,
      0.019928286775141708,
      0.018391313827648203,
      0.0170660052353057,
      0.01574990740523176,
      0.014446029869885987,
      0.013266067038009
    ],
    "metrics": {
      "accuracy": 0.9369458128078818,
      "precision": 0.723404255319149,
      "recall": 0.6415094339622641,
      "f1": 0.68
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_20/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 21,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4795317290067012,
      0.21263090755140351,
      0.15829588626395302,
      0.13567375847012053,
      0.11700047153432613,
      0.10545717215273849,
      0.09449630158223274,
      0.08970067760290532,
      0.08354920038638683,
      0.0808372504286819,
      0.07489593267193131,
      0.0668412447316247,
      0.06175860483354149,
      0.05758418225350472,
      0.057389552267964855
    ],
    "metrics": {
      "accuracy": 0.8748768472906404,
      "precision": 0.8825301204819277,
      "recall": 0.9228346456692913,
      "f1": 0.9022324865280985
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_21/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 21,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.47956374801096824,
      0.2028414347247734,
      0.1278868035962831,
      0.0974927779091032,
      0.08414944049559142,
      0.08244185526120035,
      0.06483867061827486,
      0.057253710199095864,
      0.05256348064380835,
      0.04792153640983012,
      0.042884991831891754,
      0.03989367502486112,
      0.03635880702131343,
      0.035968471729194026,
      0.03256914954983379
    ],
    "metrics": {
      "accuracy": 0.9270935960591133,
      "precision": 0.7394366197183099,
      "recall": 0.7394366197183099,
      "f1": 0.7394366197183099
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_21/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 21,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3834735116552448,
      0.09685091561434012,
      0.04698749893239165,
      0.03715558357825735,
      0.03491790689233887,
      0.032872020056693096,
      0.02999262043676104,
      0.02767834834499063,
      0.026157226642836245,
      0.024144708758369708,
      0.02303872064795665,
      0.02152994763198982,
      0.020708976227885572,
      0.019626976100410594,
      0.018594819125706468
    ],
    "metrics": {
      "accuracy": 0.9379310344827586,
      "precision": 0.7362637362637363,
      "recall": 0.6320754716981132,
      "f1": 0.6802030456852792
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_21/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 22,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5359110208099238,
      0.3197803132917082,
      0.2566769837094806,
      0.2241440632006468,
      0.21402850494490436,
      0.19722228086556093,
      0.1875341112490671,
      0.1816545109339368,
      0.17326726002045945,
      0.194421240514005,
      0.17252431365756776,
      0.16005386194198745,
      0.1504900769967782,
      0.1458979008930872,
      0.1427666756502479
    ],
    "metrics": {
      "accuracy": 0.8837438423645321,
      "precision": 0.8970814132104454,
      "recall": 0.9196850393700787,
      "f1": 0.9082426127527217
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_22/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 22,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4768800231888684,
      0.3375215440575766,
      0.2799955994220982,
      0.23322435165045993,
      0.20557958211264782,
      0.18930007384424394,
      0.17413265464873856,
      0.16106309588596102,
      0.1473909515835902,
      0.13726403991642752,
      0.12852458520237758,
      0.12176495248508586,
      0.11556498415334733,
      0.11205071122114678,
      0.10702279406984097
    ],
    "metrics": {
      "accuracy": 0.9014778325123153,
      "precision": 0.6521739130434783,
      "recall": 0.6338028169014085,
      "f1": 0.6428571428571429
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_22/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 22,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.44939673069111197,
      0.27475927597598027,
      0.1987569989012219,
      0.14098230483129084,
      0.10792489921122046,
      0.0862542188151061,
      0.07031508621829369,
      0.06021086130590485,
      0.05337203495163171,
      0.04844902509777004,
      0.0451864931556987,
      0.0433136342831183,
      0.040921814793364826,
      0.03887561915127607,
      0.03764349362732961
    ],
    "metrics": {
      "accuracy": 0.9408866995073891,
      "precision": 0.7875,
      "recall": 0.5943396226415094,
      "f1": 0.6774193548387096
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_22/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 23,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6650771636711924,
      0.6084992622734767,
      0.5531436531497501,
      0.49648924346115453,
      0.4465083046468011,
      0.4151274499965837,
      0.39714172933240344,
      0.3880045490912123,
      0.3975638331798966,
      0.3777197634084073,
      0.37321052871582583,
      0.3678491340779862,
      0.3593867107606661,
      0.355405054660385,
      0.3509166225997365
    ],
    "metrics": {
      "accuracy": 0.7596059113300493,
      "precision": 0.8307952622673435,
      "recall": 0.7732283464566929,
      "f1": 0.800978792822186
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_23/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 23,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.561663121084097,
      0.4303399696574647,
      0.4333136683520848,
      0.4152809142736187,
      0.41161108877189934,
      0.4056761760295593,
      0.39989793044708444,
      0.3947529508136316,
      0.38942146681022116,
      0.38365131791608814,
      0.3797022457763429,
      0.37188153415505576,
      0.3679297185835746,
      0.3626529353064513,
      0.35451449649485856
    ],
    "metrics": {
      "accuracy": 0.8600985221674877,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_23/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 23,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5359598751708742,
      0.3201311812671598,
      0.301870462108517,
      0.29967457128693853,
      0.2860677854176043,
      0.2822434147639288,
      0.27737964992708114,
      0.27107312121219584,
      0.2664755783252769,
      0.26265006691547643,
      0.2571969874017457,
      0.25342690223141723,
      0.2487771711190982,
      0.24455315683687162,
      0.23984318522535203
    ],
    "metrics": {
      "accuracy": 0.8955665024630541,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_23/nasal.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 24,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6649711434860969,
      0.6044536765592581,
      0.5660172830988496,
      0.5219791662660002,
      0.48349922005489593,
      0.45003627809461133,
      0.4283738153628035,
      0.41841140795612597,
      0.4085933121948031,
      0.4087082649532117,
      0.39846383993645457,
      0.40933234780779176,
      0.387924127136241,
      0.38453817701075543,
      0.3788856565126752
    ],
    "metrics": {
      "accuracy": 0.7428571428571429,
      "precision": 0.7467018469656992,
      "recall": 0.8913385826771654,
      "f1": 0.8126346015793252
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_24/voiced.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 24,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.511255410107219,
      0.43187661306349523,
      0.427975860015177,
      0.4244030282850741,
      0.421918193405685,
      0.41795682682555135,
      0.41450888671373065,
      0.41221121088949925,
      0.4085904726691523,
      0.40465754438965607,
      0.4005076701786379,
      0.39514304884913226,
      0.3904224007743878,
      0.3874208694184586,
      0.3798117815952882
    ],
    "metrics": {
      "accuracy": 0.8600985221674877,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_24/fricative.pt"
  },
  {
    "model": "WAV2VEC2_LARGE",
    "layer": 24,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3610,
    "test_samples": 1015,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3602377646022226,
      0.31312148828585723,
      0.3013652311467728,
      0.29173505636463537,
      0.28882943467750444,
      0.2846671154954757,
      0.2805663014217757,
      0.2768810537052947,
      0.27239027659813786,
      0.27061359682571856,
      0.26591836139766134,
      0.2578946544523054,
      0.2541188306342862,
      0.24942578411663668,
      0.2413992809787021
    ],
    "metrics": {
      "accuracy": 0.8955665024630541,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAV2VEC2_LARGE/layer_24/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5649363996436491,
      0.3225686813239661,
      0.2213245295938538,
      0.1843013416402374,
      0.16424024596346637,
      0.15194863950317233,
      0.1414260438987779,
      0.1334402054915884,
      0.12664895058555498,
      0.12050836866255196,
      0.11467348512043832,
      0.1097905413653124,
      0.10521928939727096,
      0.10067770912938336,
      0.09694220345411977
    ],
    "metrics": {
      "accuracy": 0.8721804511278195,
      "precision": 0.8805194805194805,
      "recall": 0.9174560216508796,
      "f1": 0.8986083499005965
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_00/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5219040417707965,
      0.29107523259409407,
      0.1965642322010442,
      0.16422780918363164,
      0.1439894333435836,
      0.12975295415638474,
      0.12084593449256853,
      0.11254939641401418,
      0.10554403362402504,
      0.09857324991643612,
      0.09302860027414629,
      0.08724458835223224,
      0.08224507239115883,
      0.07750829994962567,
      0.07324584887029077
    ],
    "metrics": {
      "accuracy": 0.910609857978279,
      "precision": 0.7336683417085427,
      "recall": 0.73,
      "f1": 0.731829573934837
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_00/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5479727720208352,
      0.31542201027303374,
      0.19488627195592217,
      0.12782052346252748,
      0.09629183431984431,
      0.07719401142423915,
      0.06429545272623152,
      0.056384621014155895,
      0.051450785205607856,
      0.047816702838593385,
      0.04547473600691428,
      0.043294818972150984,
      0.04028498432132955,
      0.038899646670394895,
      0.03707798522979831
    ],
    "metrics": {
      "accuracy": 0.9415204678362573,
      "precision": 0.5684210526315789,
      "recall": 0.6506024096385542,
      "f1": 0.6067415730337079
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_00/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5823669914842353,
      0.3551114711368455,
      0.2270576719905871,
      0.17975859128028565,
      0.15568484094402255,
      0.1416484790629354,
      0.1314701523756092,
      0.12413552547156192,
      0.11769070098438215,
      0.1129328817409028,
      0.10827503444635804,
      0.1043796338702839,
      0.1011309336932527,
      0.09734043335050704,
      0.09417244145933372
    ],
    "metrics": {
      "accuracy": 0.873015873015873,
      "precision": 0.8787096774193548,
      "recall": 0.9215155615696887,
      "f1": 0.8996036988110965
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_01/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5494765411463979,
      0.31713699652829824,
      0.21317421777144113,
      0.16637465885817118,
      0.1441978322530548,
      0.12689147146853674,
      0.115480236995277,
      0.1070282593419614,
      0.0995075907720081,
      0.09294527995927279,
      0.08736256164539619,
      0.08217721683515498,
      0.0776110048391988,
      0.0736813097795352,
      0.07001719148612871
    ],
    "metrics": {
      "accuracy": 0.9223057644110275,
      "precision": 0.783068783068783,
      "recall": 0.74,
      "f1": 0.7609254498714653
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_01/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.539318433922815,
      0.2999818961527423,
      0.18177816714179726,
      0.11201664672776501,
      0.07772753123044633,
      0.06241396751504403,
      0.05161551582042931,
      0.04603047602198222,
      0.041980301971224335,
      0.03879356838163288,
      0.03652106350920165,
      0.03460782397155138,
      0.03259691636239677,
      0.03083127816626763,
      0.02940168965817801
    ],
    "metrics": {
      "accuracy": 0.9582289055973267,
      "precision": 0.7391304347826086,
      "recall": 0.6144578313253012,
      "f1": 0.6710526315789473
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_01/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5935321411132011,
      0.3831076436695145,
      0.24455366057025507,
      0.1817228982586937,
      0.14909553111334758,
      0.1299114101029826,
      0.11773581221545147,
      0.1085834275562455,
      0.10212933851125564,
      0.09715809249054126,
      0.09241417017985967,
      0.08911122477352035,
      0.0854293615908425,
      0.08314088793413493,
      0.07895958296618343
    ],
    "metrics": {
      "accuracy": 0.8830409356725146,
      "precision": 0.8884565499351491,
      "recall": 0.9269282814614344,
      "f1": 0.9072847682119205
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_02/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5448507892757963,
      0.3319290483535957,
      0.23665130310928184,
      0.17765242927860472,
      0.1460314666335911,
      0.12165641367335195,
      0.10359221684947748,
      0.0915361477053229,
      0.08231231247949305,
      0.07531867766366943,
      0.06899145003570072,
      0.06383419787667363,
      0.05954421189007119,
      0.05581848193529209,
      0.05199586181792519
    ],
    "metrics": {
      "accuracy": 0.9264828738512949,
      "precision": 0.8010752688172043,
      "recall": 0.745,
      "f1": 0.772020725388601
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_02/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5746650970847726,
      0.3204597192115399,
      0.204096623974452,
      0.1310699732678091,
      0.0849212732135765,
      0.06468692590893234,
      0.0526432893117553,
      0.04558291532702897,
      0.04137090763392019,
      0.038261007555695954,
      0.03566261215690541,
      0.033455800958539644,
      0.03150537875221161,
      0.029665881654554166,
      0.02812553620640056
    ],
    "metrics": {
      "accuracy": 0.9690893901420217,
      "precision": 0.7948717948717948,
      "recall": 0.7469879518072289,
      "f1": 0.7701863354037267
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_02/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6013328880865366,
      0.38632068028796246,
      0.23917916343180046,
      0.1681715752485589,
      0.13517349475917945,
      0.11717599319967195,
      0.10533445049834446,
      0.09683908130070192,
      0.09029026523562483,
      0.08467077962450531,
      0.07954895537516835,
      0.07548550991349305,
      0.07168468966232083,
      0.06808074801650607,
      0.06477438033938843
    ],
    "metrics": {
      "accuracy": 0.8696741854636592,
      "precision": 0.8751608751608752,
      "recall": 0.9201623815967523,
      "f1": 0.8970976253298153
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_03/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5644277151489178,
      0.3536232526909914,
      0.2261213137843143,
      0.1562939956533598,
      0.11685765555944636,
      0.0914273611430464,
      0.07496898140907622,
      0.06520438259235109,
      0.057613090255078665,
      0.05195242112420472,
      0.04721253186585457,
      0.04314313543412677,
      0.03956670924929266,
      0.03678875903614369,
      0.03388187707092938
    ],
    "metrics": {
      "accuracy": 0.9264828738512949,
      "precision": 0.7947368421052632,
      "recall": 0.755,
      "f1": 0.7743589743589744
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_03/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5512068149236059,
      0.31076836672472896,
      0.17089949013941555,
      0.09671479304205445,
      0.06164179911525235,
      0.04724147730045603,
      0.039626156759297176,
      0.03492505958589446,
      0.031840244213598,
      0.02914413927007547,
      0.026995992872321975,
      0.02471511705953733,
      0.02293047199575614,
      0.0213258560482681,
      0.019803240705194812
    ],
    "metrics": {
      "accuracy": 0.9690893901420217,
      "precision": 0.7804878048780488,
      "recall": 0.7710843373493976,
      "f1": 0.7757575757575758
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_03/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5927928160946009,
      0.38759572402515896,
      0.24192859656860222,
      0.16598855868453968,
      0.13087335829854113,
      0.1107917327923637,
      0.098749175066202,
      0.0899688213340936,
      0.08341697470828335,
      0.07721605097793016,
      0.0724277108017891,
      0.06812742200633341,
      0.06420175905488505,
      0.060354353627646906,
      0.05715686075947082
    ],
    "metrics": {
      "accuracy": 0.87468671679198,
      "precision": 0.8849673202614379,
      "recall": 0.9161028416779432,
      "f1": 0.9002659574468085
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_04/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6139129710224185,
      0.4007077555145775,
      0.24993960634563228,
      0.16140413874583248,
      0.11208284249827412,
      0.08566985656759268,
      0.06940497183101264,
      0.0591689043774687,
      0.05225055148855858,
      0.04675180798243467,
      0.042112735432463265,
      0.03841764201340403,
      0.03527277182157898,
      0.03242761813540702,
      0.02986680010591096
    ],
    "metrics": {
      "accuracy": 0.923141186299081,
      "precision": 0.8,
      "recall": 0.72,
      "f1": 0.7578947368421053
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_04/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5679375234023175,
      0.3356339733056538,
      0.17840717950136614,
      0.09482666628891125,
      0.058171920955623936,
      0.04352537448796565,
      0.03704228666946522,
      0.032978098788869155,
      0.02992350701086029,
      0.027705034897992982,
      0.025360682356255642,
      0.023645898268746333,
      0.02206806742951988,
      0.0206285959179115,
      0.019366187618417186
    ],
    "metrics": {
      "accuracy": 0.9741019214703425,
      "precision": 0.8095238095238095,
      "recall": 0.8192771084337349,
      "f1": 0.8143712574850299
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_04/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6183729507958552,
      0.4179200360946773,
      0.2557353381728605,
      0.1644307289190041,
      0.11944389447281599,
      0.09585755880068823,
      0.08199955913193058,
      0.07340024903788432,
      0.06684659206929044,
      0.06194247308317473,
      0.05759717629324798,
      0.05398904214077113,
      0.05070100497858578,
      0.04756505827685515,
      0.04486804692069957
    ],
    "metrics": {
      "accuracy": 0.8930659983291562,
      "precision": 0.9100671140939597,
      "recall": 0.9174560216508796,
      "f1": 0.9137466307277629
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_05/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5605543657431323,
      0.3341980435566171,
      0.19811985017807504,
      0.1227325348584031,
      0.0832889214041088,
      0.061078291830225825,
      0.048070599638575226,
      0.04066576082431739,
      0.03510719433715105,
      0.031160446190394573,
      0.02819395354913168,
      0.025180157967995855,
      0.022955414955275782,
      0.02087238785855938,
      0.019247614813825982
    ],
    "metrics": {
      "accuracy": 0.9323308270676691,
      "precision": 0.8216216216216217,
      "recall": 0.76,
      "f1": 0.7896103896103897
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_05/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5614739255324311,
      0.31537350178399876,
      0.17807678769692206,
      0.10052853683179455,
      0.061788771984530054,
      0.04451998394741911,
      0.03556481135979332,
      0.030364994844252032,
      0.02691418592242891,
      0.02423498712904085,
      0.02233812847950937,
      0.02029039715720904,
      0.018705950826427366,
      0.017161802541989887,
      0.015916318278357634
    ],
    "metrics": {
      "accuracy": 0.9715956558061821,
      "precision": 0.7752808988764045,
      "recall": 0.8313253012048193,
      "f1": 0.8023255813953488
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_05/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6105336242274206,
      0.41257016055384105,
      0.25453010961760114,
      0.16133522163979439,
      0.11224875569067852,
      0.08683115140936239,
      0.07349617080984912,
      0.06495790590015418,
      0.05919642925141304,
      0.054270492696924175,
      0.05018963809520683,
      0.04665376018928084,
      0.04342339143370058,
      0.04057377572337185,
      0.038026987868203216
    ],
    "metrics": {
      "accuracy": 0.9039264828738512,
      "precision": 0.9182305630026809,
      "recall": 0.9269282814614344,
      "f1": 0.9225589225589226
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_06/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6033800580119231,
      0.38252258199685624,
      0.24290711321782624,
      0.15577774900313282,
      0.1034392953808815,
      0.07383877768765854,
      0.05614726141696722,
      0.046193637646252214,
      0.03958976909597615,
      0.03477513860051609,
      0.03121581357802735,
      0.028412008758833804,
      0.025681601978268215,
      0.023616841533394932,
      0.021682931774486203
    ],
    "metrics": {
      "accuracy": 0.9398496240601504,
      "precision": 0.8404255319148937,
      "recall": 0.79,
      "f1": 0.8144329896907216
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_06/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5492025492804238,
      0.3249831817499021,
      0.1961775321125951,
      0.11411460093633782,
      0.06810541535154056,
      0.047868803944537915,
      0.03743068900305015,
      0.03115979939613534,
      0.02671032460296241,
      0.023879289213502176,
      0.021309376601312536,
      0.019443851293286324,
      0.017793205592552586,
      0.01627412053539969,
      0.014727066375183598
    ],
    "metrics": {
      "accuracy": 0.9690893901420217,
      "precision": 0.7674418604651163,
      "recall": 0.7951807228915663,
      "f1": 0.7810650887573964
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_06/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6148399777328196,
      0.4197110733566145,
      0.2568238311399423,
      0.16001181034587966,
      0.10925019042002977,
      0.08498089744667396,
      0.07074690598682225,
      0.061972682779163485,
      0.05508217501801572,
      0.05058674387401949,
      0.0462616669457434,
      0.04294777485897871,
      0.04014430354569418,
      0.03731611904977733,
      0.034820969048119876
    ],
    "metrics": {
      "accuracy": 0.898078529657477,
      "precision": 0.9185888738127544,
      "recall": 0.9161028416779432,
      "f1": 0.9173441734417345
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_07/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5625524311998762,
      0.3643579655646743,
      0.22411246453642947,
      0.1359930671803718,
      0.08812013581574782,
      0.06230395528212929,
      0.04758676533872653,
      0.03979418033126659,
      0.03453586527825505,
      0.030505764544352717,
      0.027298610805232784,
      0.024613950798929758,
      0.02220271263853288,
      0.020238695907967078,
      0.01854670589373564
    ],
    "metrics": {
      "accuracy": 0.9398496240601504,
      "precision": 0.8516483516483516,
      "recall": 0.775,
      "f1": 0.8115183246073299
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_07/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5630712205032892,
      0.341196432362961,
      0.205620991939719,
      0.12076660071246123,
      0.07309496471669315,
      0.050252555534013824,
      0.038026559560601206,
      0.030481956548255668,
      0.025786340416296544,
      0.02227950457589012,
      0.019777876731475127,
      0.017715533592698784,
      0.016078320434481482,
      0.014532139201844093,
      0.013140909420757158
    ],
    "metrics": {
      "accuracy": 0.9724310776942355,
      "precision": 0.8205128205128205,
      "recall": 0.7710843373493976,
      "f1": 0.7950310559006211
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_07/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5993888518841687,
      0.40296168418568257,
      0.2514479138752911,
      0.16024282278468505,
      0.1092688084329615,
      0.08324591443047057,
      0.06854520974571644,
      0.05904567321876802,
      0.052218616330426446,
      0.04710828556561958,
      0.04301800173927931,
      0.03953023446201109,
      0.036801187170631314,
      0.03455708519601842,
      0.031564181983337235
    ],
    "metrics": {
      "accuracy": 0.8972431077694235,
      "precision": 0.9150943396226415,
      "recall": 0.918809201623816,
      "f1": 0.9169480081026333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_08/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6073002089864572,
      0.40104458956682354,
      0.2618105506943761,
      0.16975410048253803,
      0.11342846389357569,
      0.07950478614019953,
      0.05966577452080304,
      0.048186712523643996,
      0.0412479140833626,
      0.03643789833851779,
      0.03311645771596891,
      0.030054048582063456,
      0.02753231773335191,
      0.025365767472551287,
      0.023484347159952085
    ],
    "metrics": {
      "accuracy": 0.948203842940685,
      "precision": 0.896551724137931,
      "recall": 0.78,
      "f1": 0.8342245989304813
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_08/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5731155269948714,
      0.3554630453659434,
      0.22587997146119984,
      0.13926738801584346,
      0.08400252546445643,
      0.056377273076951485,
      0.04182475331657936,
      0.03301177547896296,
      0.027521250392998305,
      0.0238079139584206,
      0.02081272194858088,
      0.018736794087299537,
      0.016742511075392118,
      0.015147978495279046,
      0.013742858610571033
    ],
    "metrics": {
      "accuracy": 0.9741019214703425,
      "precision": 0.7888888888888889,
      "recall": 0.8554216867469879,
      "f1": 0.8208092485549133
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_08/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6048516079695712,
      0.4212323092665698,
      0.2740422350111414,
      0.18109295943102852,
      0.1254943582418087,
      0.09478853289523578,
      0.07717603658732494,
      0.06581705659293714,
      0.05735173521922154,
      0.05145681305220055,
      0.04698187480428689,
      0.04255194085688527,
      0.03922233952797859,
      0.03630570348227913,
      0.03380884213217975
    ],
    "metrics": {
      "accuracy": 0.8964076858813701,
      "precision": 0.9019607843137255,
      "recall": 0.9336941813261164,
      "f1": 0.9175531914893617
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_09/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5957398577367421,
      0.39709431770170706,
      0.2596250787974741,
      0.17226300707109374,
      0.12052489992597706,
      0.08584668310393062,
      0.06453635557892778,
      0.051513026446262794,
      0.04361291748884348,
      0.037905575467870455,
      0.033868629175188965,
      0.030484545119534964,
      0.02762527890996352,
      0.025087676553318304,
      0.02339920613842666
    ],
    "metrics": {
      "accuracy": 0.9365079365079365,
      "precision": 0.8780487804878049,
      "recall": 0.72,
      "f1": 0.7912087912087912
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_09/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5737465821145996,
      0.3490871832188285,
      0.22211027879791165,
      0.1388211188394548,
      0.0864852115716592,
      0.05904315518884222,
      0.04357735955952462,
      0.03382706329777924,
      0.0276301737210523,
      0.023571919837304948,
      0.02063879721965364,
      0.018167883668952306,
      0.016336718275213578,
      0.01458714021286787,
      0.013425221131973017
    ],
    "metrics": {
      "accuracy": 0.974937343358396,
      "precision": 0.8192771084337349,
      "recall": 0.8192771084337349,
      "f1": 0.8192771084337349
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_09/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5938631758607668,
      0.3798416852199099,
      0.23067992834156556,
      0.1496740510634491,
      0.10636515828710595,
      0.08403187066124439,
      0.07009647458891993,
      0.060999042110923364,
      0.05452782026577437,
      0.04937922388402929,
      0.045576334510333806,
      0.04171893245508967,
      0.03900482045407719,
      0.036199833781575666,
      0.033709962056745556
    ],
    "metrics": {
      "accuracy": 0.8913951545530493,
      "precision": 0.9054593874833555,
      "recall": 0.9201623815967523,
      "f1": 0.912751677852349
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_10/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5634367355853862,
      0.34639293119156767,
      0.21570397123071972,
      0.13665428828476256,
      0.09205293575605157,
      0.0641799760898322,
      0.048585816646553,
      0.03932859083751954,
      0.0332401487783103,
      0.029251833780785386,
      0.026268676417859654,
      0.023873748144441403,
      0.02184099716455254,
      0.020107778881130547,
      0.018624331545996454
    ],
    "metrics": {
      "accuracy": 0.9390142021720969,
      "precision": 0.8713450292397661,
      "recall": 0.745,
      "f1": 0.8032345013477089
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_10/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5691884831617552,
      0.34289192411456415,
      0.21369541682279974,
      0.130624632383215,
      0.08230496413184876,
      0.05586686348247535,
      0.04076558862112302,
      0.031865613807106605,
      0.026346241092904128,
      0.02307302216791141,
      0.020248394174371274,
      0.01813036438917367,
      0.01631920632337334,
      0.014879068587667757,
      0.013587062549705528
    ],
    "metrics": {
      "accuracy": 0.9707602339181286,
      "precision": 0.7790697674418605,
      "recall": 0.8072289156626506,
      "f1": 0.7928994082840237
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_10/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.585078726471189,
      0.36629855109758325,
      0.2101712579365568,
      0.12665829352798466,
      0.08764543383478082,
      0.0678580495504595,
      0.05749593636703518,
      0.05057874064185488,
      0.0451873772541849,
      0.04117276462409588,
      0.03764574500210719,
      0.03499562279870856,
      0.0323629218360181,
      0.029873749436009053,
      0.027648543404273737
    ],
    "metrics": {
      "accuracy": 0.898078529657477,
      "precision": 0.9140939597315436,
      "recall": 0.9215155615696887,
      "f1": 0.9177897574123989
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_11/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5670428318589015,
      0.35956410381484505,
      0.22048888490218088,
      0.13541100375753243,
      0.08537255139420405,
      0.05805579025453969,
      0.042495818067689824,
      0.033898312827185285,
      0.028651740858897896,
      0.024916643768711888,
      0.02204914611508641,
      0.01987853684424226,
      0.018074731745884837,
      0.01647288894230139,
      0.015186164528392578
    ],
    "metrics": {
      "accuracy": 0.9373433583959899,
      "precision": 0.8571428571428571,
      "recall": 0.75,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_11/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5876036959015959,
      0.3589018843055005,
      0.21132868252232992,
      0.12398837681181932,
      0.0757083177873575,
      0.05020105034501438,
      0.036416944516350115,
      0.028687367622014986,
      0.023637937558624283,
      0.020165235865239772,
      0.01773898367059057,
      0.015578289343164787,
      0.014054311992914395,
      0.012760938301876726,
      0.011619304014901955
    ],
    "metrics": {
      "accuracy": 0.9724310776942355,
      "precision": 0.8048780487804879,
      "recall": 0.7951807228915663,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_11/nasal.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5442474365635416,
      0.3019990081091304,
      0.16636767208927114,
      0.10863922932400635,
      0.08339553998528926,
      0.06970390003620493,
      0.061471154937849076,
      0.055637823627180234,
      0.050883241213977186,
      0.047218665749018424,
      0.043889787560890195,
      0.04108996895583932,
      0.038533298083052836,
      0.03616471491171293,
      0.03399316504344925
    ],
    "metrics": {
      "accuracy": 0.8930659983291562,
      "precision": 0.9025032938076416,
      "recall": 0.9269282814614344,
      "f1": 0.9145527369826435
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_12/voiced.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5251379259868533,
      0.29680641949226916,
      0.1896492917856182,
      0.10972254110888202,
      0.07213199069712521,
      0.049701027746565846,
      0.0375882035310876,
      0.03136828665096519,
      0.027272423834782508,
      0.024652759845070656,
      0.022338662390005263,
      0.020456931852472656,
      0.0190931951887185,
      0.017567343566799603,
      0.016456848964980748
    ],
    "metrics": {
      "accuracy": 0.9456975772765246,
      "precision": 0.8729281767955801,
      "recall": 0.79,
      "f1": 0.8293963254593176
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_12/fricative.pt"
  },
  {
    "model": "WAVLM_BASE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 768,
    "train_samples": 3567,
    "test_samples": 1197,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 154001,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4846806103169901,
      0.23250453461526588,
      0.14418885669923476,
      0.0800285153038735,
      0.05224165233608752,
      0.03976351723235747,
      0.031544014588019274,
      0.026248802211347635,
      0.022784860655853386,
      0.02004457049527137,
      0.01753464728418371,
      0.015825263281199556,
      0.014406536125379815,
      0.013091500599709068,
      0.011995007815050968
    ],
    "metrics": {
      "accuracy": 0.9674185463659147,
      "precision": 0.782051282051282,
      "recall": 0.7349397590361446,
      "f1": 0.7577639751552795
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_BASE/layer_12/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 0,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4621824662549685,
      0.23082098517787608,
      0.1794951882578459,
      0.16398994495251645,
      0.15279685320658595,
      0.14299695281230002,
      0.13849114137873308,
      0.12800048880325846,
      0.12371518007481387,
      0.11600535075553219,
      0.10648635437001695,
      0.10132352258463945,
      0.09623822687616317,
      0.0915123352075645,
      0.08738773426998518
    ],
    "metrics": {
      "accuracy": 0.8882063882063882,
      "precision": 0.88,
      "recall": 0.9341825902335457,
      "f1": 0.9062821833161689
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_00/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 0,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.40011018037861107,
      0.21042376256098097,
      0.16248741898906383,
      0.13623981392191564,
      0.12044028717533278,
      0.10726377959666993,
      0.09794775911800334,
      0.09142135638553459,
      0.08396191853717673,
      0.07624196692581162,
      0.07031782822077827,
      0.06705973900034881,
      0.061952760530045344,
      0.05781689195921927,
      0.0539582147217988
    ],
    "metrics": {
      "accuracy": 0.9164619164619164,
      "precision": 0.7073170731707317,
      "recall": 0.7310924369747899,
      "f1": 0.71900826446281
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_00/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 0,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4751314935326544,
      0.1609204719049046,
      0.11732132547976637,
      0.09150732740650012,
      0.07443415894778967,
      0.061991907141588115,
      0.05323493294570409,
      0.04832017197269349,
      0.043888134102319516,
      0.03961561308421628,
      0.03634295726376513,
      0.03366026924066235,
      0.03167369853325825,
      0.02930646481761801,
      0.026981185314708514
    ],
    "metrics": {
      "accuracy": 0.952088452088452,
      "precision": 0.5555555555555556,
      "recall": 0.5681818181818182,
      "f1": 0.5617977528089888
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_00/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 1,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.28867025348761355,
      0.15441881862415371,
      0.12916371093489842,
      0.110876614523331,
      0.10037845124394199,
      0.08768387865392101,
      0.08089625214638685,
      0.07736885522924711,
      0.07171830935431672,
      0.05906808734298111,
      0.05059216617358177,
      0.044793351579568375,
      0.04052990718195258,
      0.03584597354748195,
      0.03237014567546105
    ],
    "metrics": {
      "accuracy": 0.8685503685503686,
      "precision": 0.85546875,
      "recall": 0.9299363057324841,
      "f1": 0.8911495422177009
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_01/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 1,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.23455499909531377,
      0.10771901391948992,
      0.08738074703495456,
      0.07188274809206376,
      0.06414325517804903,
      0.0546744275505576,
      0.04417938883120152,
      0.037372812093801264,
      0.032203801456811385,
      0.028186647502647995,
      0.025308950666115482,
      0.020660909319892954,
      0.020552543227627177,
      0.015148548395358943,
      0.013509592682976452
    ],
    "metrics": {
      "accuracy": 0.9287469287469288,
      "precision": 0.7520661157024794,
      "recall": 0.7647058823529411,
      "f1": 0.7583333333333333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_01/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 1,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4115375473916352,
      0.09310256900307001,
      0.06740183358614867,
      0.05238515512273834,
      0.03977862463635017,
      0.0346353480298964,
      0.02957749805140375,
      0.026279416366488173,
      0.023089253602215348,
      0.02053473941491596,
      0.01821725605726405,
      0.016177683472968975,
      0.014788065423872175,
      0.013185277936149743,
      0.011483510233204555
    ],
    "metrics": {
      "accuracy": 0.9545454545454546,
      "precision": 0.5897435897435898,
      "recall": 0.5227272727272727,
      "f1": 0.5542168674698795
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_01/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 2,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.292221558389363,
      0.139716092428971,
      0.11173381114751305,
      0.09427650235420428,
      0.08426053011182258,
      0.07473560163322576,
      0.06341829409437885,
      0.05574643576516176,
      0.04890519248968976,
      0.04407060434144278,
      0.04238989152707853,
      0.03579490535966025,
      0.031756819440181584,
      0.02774413231655512,
      0.022374592193128012
    ],
    "metrics": {
      "accuracy": 0.8820638820638821,
      "precision": 0.8803245436105477,
      "recall": 0.921443736730361,
      "f1": 0.9004149377593361
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_02/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 2,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2679754679047798,
      0.10781123434680832,
      0.08081072945998986,
      0.06389609061399185,
      0.0504447558130474,
      0.04164437234295934,
      0.03393914015852312,
      0.02805235652736618,
      0.022785768407129245,
      0.020147814895167496,
      0.01572306905096382,
      0.014136605658330716,
      0.010624237117031348,
      0.009213745791577932,
      0.007958412371777199
    ],
    "metrics": {
      "accuracy": 0.9226044226044227,
      "precision": 0.7295081967213115,
      "recall": 0.7478991596638656,
      "f1": 0.7385892116182573
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_02/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 2,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5045777946556002,
      0.0858089718525279,
      0.06715683008455413,
      0.04248407633363419,
      0.036009803163144484,
      0.030153162360451697,
      0.027530386356711633,
      0.02349781232890847,
      0.02103350346146745,
      0.018674269061278295,
      0.016547921326986726,
      0.014885535430669868,
      0.013240864012749378,
      0.011802523672263414,
      0.01090654068116181
    ],
    "metrics": {
      "accuracy": 0.9545454545454546,
      "precision": 0.574468085106383,
      "recall": 0.6136363636363636,
      "f1": 0.5934065934065934
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_02/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 3,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.27969806148906307,
      0.12790100770734744,
      0.09343445636057443,
      0.07518598619556609,
      0.06311447975570765,
      0.05451198174955576,
      0.045748141162258144,
      0.03855331161741087,
      0.033413310601611686,
      0.029130503899358576,
      0.02399839471070665,
      0.020002070068651998,
      0.016250315058489267,
      0.01421774448148058,
      0.012147331841690697
    ],
    "metrics": {
      "accuracy": 0.8845208845208845,
      "precision": 0.8747514910536779,
      "recall": 0.9341825902335457,
      "f1": 0.9034907597535934
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_03/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 3,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.30792648554328295,
      0.10873677130201753,
      0.07968248971113734,
      0.059937298167705405,
      0.04887343885963353,
      0.03890466147999668,
      0.031906256708996626,
      0.02598964238558153,
      0.022151398859712682,
      0.017781269986008544,
      0.015224364327092395,
      0.01385673936194563,
      0.01110647723318741,
      0.008748199645920047,
      0.006994649335648432
    ],
    "metrics": {
      "accuracy": 0.9299754299754299,
      "precision": 0.7870370370370371,
      "recall": 0.7142857142857143,
      "f1": 0.748898678414097
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_03/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 3,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.20857661112089348,
      0.05028950275053402,
      0.0333408648049021,
      0.024698569494015592,
      0.01796935972435501,
      0.014396563657451907,
      0.01181650243001885,
      0.009745155964105195,
      0.007944886421633733,
      0.006535246781903132,
      0.005372818458152601,
      0.004484328270973468,
      0.003670080766537428,
      0.0032100505092586286,
      0.0027130364331434836
    ],
    "metrics": {
      "accuracy": 0.9545454545454546,
      "precision": 0.5714285714285714,
      "recall": 0.6363636363636364,
      "f1": 0.6021505376344086
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_03/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 4,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.29587652404679976,
      0.11728257996086341,
      0.089166882035757,
      0.07206160951850195,
      0.05851399334803033,
      0.048466052128794804,
      0.040942505854272206,
      0.0349488598407698,
      0.028816586851040393,
      0.023328906091435047,
      0.020575584028116545,
      0.017760121974196064,
      0.013719403679723415,
      0.011211269179172458,
      0.009133840398646844
    ],
    "metrics": {
      "accuracy": 0.8783783783783784,
      "precision": 0.8675889328063241,
      "recall": 0.9320594479830149,
      "f1": 0.8986693961105425
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_04/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 4,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2876897216079146,
      0.08742126796843086,
      0.06311608412626693,
      0.04724372363614476,
      0.03535435052648077,
      0.028101126038437084,
      0.02247992713627775,
      0.018234319916265018,
      0.01468575218605468,
      0.012378699727938161,
      0.0102042435548148,
      0.008491980812481573,
      0.0071454886650885755,
      0.005725967487787618,
      0.004569332368967843
    ],
    "metrics": {
      "accuracy": 0.9324324324324325,
      "precision": 0.7807017543859649,
      "recall": 0.7478991596638656,
      "f1": 0.7639484978540773
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_04/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 4,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.19931984608095427,
      0.04735254881170777,
      0.03201409165195484,
      0.02353662087264492,
      0.01700015247570884,
      0.013556442995142031,
      0.010756351090326941,
      0.009211749124076038,
      0.007755171594805171,
      0.006107605190885615,
      0.005189013234414659,
      0.004074803269840726,
      0.0032878223146328976,
      0.002757609253350077,
      0.002277102129649063
    ],
    "metrics": {
      "accuracy": 0.9582309582309583,
      "precision": 0.6041666666666666,
      "recall": 0.6590909090909091,
      "f1": 0.6304347826086957
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_04/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 5,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.30688049792307764,
      0.1167997422519031,
      0.08800245157371542,
      0.06716640299903608,
      0.05343551362411852,
      0.0425811366447856,
      0.0349885521122513,
      0.03003679056746726,
      0.024327260131128754,
      0.01986647058210183,
      0.017431669217518344,
      0.013989292151021838,
      0.01112066918957105,
      0.009029725259879297,
      0.008881086603032311
    ],
    "metrics": {
      "accuracy": 0.8955773955773956,
      "precision": 0.8875502008032129,
      "recall": 0.9384288747346072,
      "f1": 0.9122807017543859
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_05/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 5,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.47375702513003004,
      0.1238537143398236,
      0.06847247929642053,
      0.056220276977377706,
      0.043987100994264755,
      0.03675052133337204,
      0.030563594518143427,
      0.026304043401281854,
      0.02239449605205379,
      0.01898590663466791,
      0.01665205973470769,
      0.013904356507270706,
      0.011985008759409345,
      0.010133574614664903,
      0.008483092747059166
    ],
    "metrics": {
      "accuracy": 0.9361179361179361,
      "precision": 0.7964601769911505,
      "recall": 0.7563025210084033,
      "f1": 0.7758620689655172
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_05/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 5,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.12306050486799605,
      0.0299997903791048,
      0.021313744427742035,
      0.013996607744255223,
      0.009938670570130474,
      0.0070142298117519,
      0.005486297267335313,
      0.0040620059017472095,
      0.0031375898335077156,
      0.0021628805022018546,
      0.0017488138371869544,
      0.001337034006261984,
      0.0010289308218587492,
      0.0007853456936379243,
      0.0006768636144796824
    ],
    "metrics": {
      "accuracy": 0.9582309582309583,
      "precision": 0.5892857142857143,
      "recall": 0.75,
      "f1": 0.66
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_05/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 6,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.280859930436207,
      0.10599326756265429,
      0.067470711262588,
      0.05112775347652964,
      0.03612732178237418,
      0.027552607215517878,
      0.02122597609716029,
      0.016252695104051834,
      0.013361154772481598,
      0.010283275483490876,
      0.008588006193392384,
      0.0068582875066526576,
      0.005573816814719451,
      0.004345817652480372,
      0.003673422080521868
    ],
    "metrics": {
      "accuracy": 0.8931203931203932,
      "precision": 0.8779527559055118,
      "recall": 0.9469214437367304,
      "f1": 0.9111338100102145
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_06/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 6,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2444294555529183,
      0.055540662931103935,
      0.03630097956329771,
      0.025350062421810593,
      0.016956828510194994,
      0.011048630928611034,
      0.00847305117309482,
      0.005878675033325274,
      0.00451315934392246,
      0.0035494746469785523,
      0.002739473027636079,
      0.0022448749932857883,
      0.0019680658029150823,
      0.0016557246155110361,
      0.0014334395857095116
    ],
    "metrics": {
      "accuracy": 0.9434889434889435,
      "precision": 0.8173913043478261,
      "recall": 0.7899159663865546,
      "f1": 0.8034188034188035
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_06/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 6,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.27535406667093354,
      0.0412765880800029,
      0.03582340298585239,
      0.02454523002276761,
      0.0172424867949739,
      0.01302879669637692,
      0.010028492926612065,
      0.007676317090071471,
      0.006432728569152725,
      0.005403905728241515,
      0.004350431974651305,
      0.0035906038469518758,
      0.0029452899799545158,
      0.0024489946147249497,
      0.001990600842552846
    ],
    "metrics": {
      "accuracy": 0.9643734643734644,
      "precision": 0.6530612244897959,
      "recall": 0.7272727272727273,
      "f1": 0.6881720430107527
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_06/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 7,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.286296276204286,
      0.09767013843344952,
      0.061031789439820607,
      0.04263056512518298,
      0.03149770398975362,
      0.025339601065637048,
      0.019196788272142832,
      0.014399792151355268,
      0.010707772441397525,
      0.008326044951448862,
      0.0062340592096961165,
      0.005131434810043008,
      0.004399623570049961,
      0.0032421483811059188,
      0.0027092821482790686
    ],
    "metrics": {
      "accuracy": 0.9017199017199017,
      "precision": 0.8886679920477137,
      "recall": 0.9490445859872612,
      "f1": 0.917864476386037
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_07/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 7,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.40102131644311156,
      0.08045980010975946,
      0.04951360739549912,
      0.03040435321874654,
      0.02275195355401757,
      0.015064219539156709,
      0.01175595192457853,
      0.00906081500008332,
      0.007145582722693706,
      0.005626861766868566,
      0.004528423335348286,
      0.0036774336250049882,
      0.003208308820868251,
      0.0026881169733267716,
      0.0022666734310084155
    ],
    "metrics": {
      "accuracy": 0.9533169533169533,
      "precision": 0.8785046728971962,
      "recall": 0.7899159663865546,
      "f1": 0.831858407079646
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_07/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 7,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.24989848791291353,
      0.046680028719912454,
      0.030590198192617813,
      0.019630252350469553,
      0.014109933466622324,
      0.009527650702192489,
      0.006683026282043038,
      0.004880781358816268,
      0.003701540508068266,
      0.00284603798501102,
      0.002341339748678589,
      0.0018625318243338897,
      0.0015283213717464234,
      0.0012739379139586067,
      0.0010927693112910968
    ],
    "metrics": {
      "accuracy": 0.9594594594594594,
      "precision": 0.6078431372549019,
      "recall": 0.7045454545454546,
      "f1": 0.6526315789473685
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_07/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 8,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3181060200794583,
      0.09256986380355657,
      0.05210506962828385,
      0.03978645817816274,
      0.025694698054641446,
      0.019400393539480813,
      0.014070062343831551,
      0.010557776138515964,
      0.007851910117099332,
      0.006126926178666894,
      0.004610569177156275,
      0.0037925446206038154,
      0.003126897014562603,
      0.0026541058672147106,
      0.0021942741097551862
    ],
    "metrics": {
      "accuracy": 0.9054054054054054,
      "precision": 0.8893280632411067,
      "recall": 0.9554140127388535,
      "f1": 0.9211873080859775
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_08/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 8,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2899252979103664,
      0.046716330496687365,
      0.03273036161505261,
      0.018233542089787072,
      0.011586757691044674,
      0.007862955774326786,
      0.005118189991301537,
      0.0034862765293581593,
      0.002632177399902104,
      0.0020752463894284736,
      0.0017978893375568807,
      0.0015246472310327215,
      0.0011951629129443608,
      0.0010070215226800662,
      0.0008757808052169664
    ],
    "metrics": {
      "accuracy": 0.9496314496314496,
      "precision": 0.8421052631578947,
      "recall": 0.8067226890756303,
      "f1": 0.8240343347639485
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_08/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 8,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.319274892308959,
      0.03985084168009873,
      0.030212417012144114,
      0.021047389799377616,
      0.01484076776563381,
      0.0096457596825761,
      0.007107459624681073,
      0.005616414488717576,
      0.004519536348857232,
      0.003823674930165004,
      0.003068979928413825,
      0.002473367307306662,
      0.002026099229008117,
      0.0017327456647993444,
      0.0014618593950761233
    ],
    "metrics": {
      "accuracy": 0.9680589680589681,
      "precision": 0.68,
      "recall": 0.7727272727272727,
      "f1": 0.723404255319149
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_08/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 9,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.22390875013439895,
      0.05852635053614189,
      0.03849592464008587,
      0.025759548430897776,
      0.013449507851663132,
      0.011042515440494912,
      0.006714364904284868,
      0.004956876998271467,
      0.0029477827774588078,
      0.002264761885131297,
      0.001811571606463358,
      0.0014373083464031438,
      0.0011252523839823702,
      0.0009364296049236211,
      0.0008098743741540124
    ],
    "metrics": {
      "accuracy": 0.9127764127764127,
      "precision": 0.9065040650406504,
      "recall": 0.9469214437367304,
      "f1": 0.9262720664589823
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_09/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 9,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3745192151588883,
      0.0649415967589864,
      0.03041049278814904,
      0.019363967289524206,
      0.01366402168271068,
      0.009180931869330845,
      0.006220714191718262,
      0.004577417850571677,
      0.0034935978077781224,
      0.0027552303692075257,
      0.002171444115071315,
      0.001711500889829907,
      0.0014730237685680418,
      0.0012261197204850847,
      0.001061588957617957
    ],
    "metrics": {
      "accuracy": 0.9582309582309583,
      "precision": 0.8828828828828829,
      "recall": 0.8235294117647058,
      "f1": 0.8521739130434782
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_09/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 9,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.20603421152882845,
      0.03507701129495687,
      0.02421719968622007,
      0.015608256082569492,
      0.008365837591180312,
      0.004959505919896935,
      0.0032932361883417417,
      0.0022255004161757545,
      0.0014435989772870429,
      0.0010232785090320642,
      0.0007990747001179737,
      0.0006649391176635432,
      0.0005985099053712841,
      0.0005037175145781661,
      0.0004372991342977866
    ],
    "metrics": {
      "accuracy": 0.9692874692874693,
      "precision": 0.7021276595744681,
      "recall": 0.75,
      "f1": 0.7252747252747253
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_09/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 10,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.29106259489609443,
      0.0733353385903651,
      0.05104859954052827,
      0.02859245498982237,
      0.018631163163305372,
      0.01181257906243502,
      0.00814810943126947,
      0.006153844473891138,
      0.004687931365733943,
      0.0037579023948693386,
      0.0029347838711633223,
      0.0025109132414176723,
      0.0021415901179149557,
      0.0019939745145303497,
      0.0016647213379034546
    ],
    "metrics": {
      "accuracy": 0.9078624078624079,
      "precision": 0.896,
      "recall": 0.9511677282377919,
      "f1": 0.9227600411946447
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_10/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 10,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.22074185206229135,
      0.027544238223800286,
      0.018785183884685495,
      0.008819851876851024,
      0.005919050106968413,
      0.003398980195172283,
      0.0022160544152591004,
      0.001371067009625716,
      0.0010919106667732945,
      0.0008642767499988988,
      0.0007016753946207749,
      0.0006007737505020599,
      0.0005266170346740264,
      0.00046860905721505993,
      0.0004155488583335115
    ],
    "metrics": {
      "accuracy": 0.9508599508599509,
      "precision": 0.8761904761904762,
      "recall": 0.773109243697479,
      "f1": 0.8214285714285714
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_10/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 10,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.1410817772993137,
      0.027864828079312412,
      0.01717785421510741,
      0.00799245230004104,
      0.0037384079418386913,
      0.0018624713298333404,
      0.0011425895731862123,
      0.0008378598701971329,
      0.0006667792671170658,
      0.0005550320705754488,
      0.0004911269416226051,
      0.0004076754912739625,
      0.0003421490278239676,
      0.0003036841476058066,
      0.0002732557027404678
    ],
    "metrics": {
      "accuracy": 0.9680589680589681,
      "precision": 0.68,
      "recall": 0.7727272727272727,
      "f1": 0.723404255319149
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_10/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 11,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.44470511600192114,
      0.09319485677190079,
      0.0624266017239552,
      0.040795788422141474,
      0.030916931068485563,
      0.022690804782006996,
      0.018048620047624885,
      0.013813795986626761,
      0.011814008253836791,
      0.009092934027165704,
      0.006883603941223074,
      0.005696030095786084,
      0.004359844752945618,
      0.0035763959913752788,
      0.0030359183341983494
    ],
    "metrics": {
      "accuracy": 0.9115479115479116,
      "precision": 0.8966202783300199,
      "recall": 0.9575371549893843,
      "f1": 0.9260780287474333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_11/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 11,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3930920679045934,
      0.05910914760725453,
      0.027916555980399937,
      0.02134795511222335,
      0.014741578793648702,
      0.00973907005072475,
      0.006673878889430214,
      0.004421441635720019,
      0.0032316028999091985,
      0.0024893238935107275,
      0.0020104186565719734,
      0.0015896413969285349,
      0.0013431422684603293,
      0.001167779404995696,
      0.0010238437194589737
    ],
    "metrics": {
      "accuracy": 0.952088452088452,
      "precision": 0.8703703703703703,
      "recall": 0.7899159663865546,
      "f1": 0.8281938325991189
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_11/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 11,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.26557009378862556,
      0.044910727034743955,
      0.029434876819370036,
      0.019146566212388243,
      0.011415714137001735,
      0.00686084510240927,
      0.003884379470619441,
      0.0025629374015427478,
      0.001745561713483993,
      0.0013088091661927763,
      0.000987153516241016,
      0.0008041975426889596,
      0.0006571600934274575,
      0.0005637798030877757,
      0.0004946568881194182
    ],
    "metrics": {
      "accuracy": 0.9680589680589681,
      "precision": 0.7045454545454546,
      "recall": 0.7045454545454546,
      "f1": 0.7045454545454546
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_11/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 12,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3808302485528716,
      0.10350639118914425,
      0.05928069165364465,
      0.03858717860678913,
      0.026772249950980296,
      0.01879680103162436,
      0.013525730822211954,
      0.010661765592848541,
      0.007678409433869506,
      0.0064419355322770855,
      0.005168438646276238,
      0.004250892450198543,
      0.0031973677363176505,
      0.0027371558421521508,
      0.002260166343869532
    ],
    "metrics": {
      "accuracy": 0.9176904176904177,
      "precision": 0.9056224899598394,
      "recall": 0.9575371549893843,
      "f1": 0.9308565531475749
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_12/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 12,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.25937231615645423,
      0.043414347072076254,
      0.0279386861256415,
      0.016877789706213706,
      0.007200640085459146,
      0.0037306668822583164,
      0.0023620035260973724,
      0.0015109767981606845,
      0.0011031386791950906,
      0.0008985370558834592,
      0.0007674660169499271,
      0.0006492567812158707,
      0.000573717699447168,
      0.0005162820368702803,
      0.0004668572894980046
    ],
    "metrics": {
      "accuracy": 0.9508599508599509,
      "precision": 0.8691588785046729,
      "recall": 0.7815126050420168,
      "f1": 0.8230088495575221
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_12/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 12,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.4128520867802302,
      0.04583817050105036,
      0.030128296823684484,
      0.019886678830704465,
      0.012629405083045782,
      0.007857382653658401,
      0.00535165148650159,
      0.0028539064539546987,
      0.0020012756175839057,
      0.0013727767732037105,
      0.0010127405503849542,
      0.0008384781434062645,
      0.0006918549901746578,
      0.0006008598244350757,
      0.0005338314045626144
    ],
    "metrics": {
      "accuracy": 0.9656019656019657,
      "precision": 0.6818181818181818,
      "recall": 0.6818181818181818,
      "f1": 0.6818181818181818
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_12/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 13,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2049514576802887,
      0.055144195669894334,
      0.031457366458558046,
      0.019402600996961058,
      0.011234090724512995,
      0.007096035124918631,
      0.004095577820696937,
      0.0027339994762328773,
      0.0020663364408812336,
      0.0015418428846998757,
      0.0012999574315177302,
      0.001040323678709957,
      0.0009227172055595954,
      0.0007328290049009047,
      0.0006220799842757843
    ],
    "metrics": {
      "accuracy": 0.9078624078624079,
      "precision": 0.896,
      "recall": 0.9511677282377919,
      "f1": 0.9227600411946447
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_13/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 13,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2898854471716665,
      0.038361747472270114,
      0.021045345965078253,
      0.011510752224488732,
      0.005412195059652622,
      0.003318068181279802,
      0.0019849509817973713,
      0.0013780905357901432,
      0.0010510973865992623,
      0.0008542805935154228,
      0.0007478128082487656,
      0.000647246522646257,
      0.0005599491841120606,
      0.0004899122980773502,
      0.00043924773426130495
    ],
    "metrics": {
      "accuracy": 0.9533169533169533,
      "precision": 0.9090909090909091,
      "recall": 0.7563025210084033,
      "f1": 0.8256880733944955
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_13/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 13,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.566059883020324,
      0.04775751247511856,
      0.04408319699220764,
      0.022259708147149185,
      0.016501152971986358,
      0.01202898641354515,
      0.007322362052043328,
      0.004735992211007434,
      0.0033114861625513923,
      0.002607698788637066,
      0.0020321230802141177,
      0.0014775909601246473,
      0.0012494185535966132,
      0.0010610986954022535,
      0.0009097850397104611
    ],
    "metrics": {
      "accuracy": 0.9668304668304668,
      "precision": 0.6808510638297872,
      "recall": 0.7272727272727273,
      "f1": 0.7032967032967034
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_13/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 14,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3685469810665061,
      0.08389999983929364,
      0.06341732568874113,
      0.04037315385792951,
      0.026638518594288774,
      0.01839719471081058,
      0.012058938627413248,
      0.010977089584052743,
      0.009426391687332657,
      0.005523919277858023,
      0.004254537883717816,
      0.0032733890513116314,
      0.002554930591239555,
      0.0021487924390243135,
      0.0018813801272623515
    ],
    "metrics": {
      "accuracy": 0.9152334152334153,
      "precision": 0.9036144578313253,
      "recall": 0.9554140127388535,
      "f1": 0.9287925696594427
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_14/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 14,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.24019051251265314,
      0.038615701998777965,
      0.02356605606013515,
      0.013225510277727646,
      0.006181216119998853,
      0.0033536144139953497,
      0.0024078107835963183,
      0.0016354379438841677,
      0.001213872751590742,
      0.0009731732600633871,
      0.0008134350041169068,
      0.0007068168392708807,
      0.0006225480200955962,
      0.000554676590296164,
      0.0005062834000758206
    ],
    "metrics": {
      "accuracy": 0.9484029484029484,
      "precision": 0.9230769230769231,
      "recall": 0.7058823529411765,
      "f1": 0.8
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_14/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 14,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3350939627471369,
      0.04892459944899441,
      0.031230587836679397,
      0.01790359346124865,
      0.011646551337572888,
      0.00693403592423711,
      0.004162738319049576,
      0.0021971895603792053,
      0.0016725460448323431,
      0.0014498234840138928,
      0.000890708101296996,
      0.0007092394090932368,
      0.0005312097248648108,
      0.0004209539752734259,
      0.00035509803470828245
    ],
    "metrics": {
      "accuracy": 0.961916461916462,
      "precision": 0.6382978723404256,
      "recall": 0.6818181818181818,
      "f1": 0.6593406593406593
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_14/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 15,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6645501838366972,
      0.16054873065954345,
      0.08940228198253487,
      0.061180213457642116,
      0.04533506454831259,
      0.033282864751884626,
      0.026769521689678586,
      0.021690178901534768,
      0.017762506911553972,
      0.014980570137182441,
      0.013767529336454405,
      0.011232351385404788,
      0.010026956909040456,
      0.008951898768987611,
      0.008287310835717482
    ],
    "metrics": {
      "accuracy": 0.9176904176904177,
      "precision": 0.9023904382470119,
      "recall": 0.9617834394904459,
      "f1": 0.9311408016443987
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_15/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 15,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.1955342897283406,
      0.0458330157933207,
      0.026011142844955634,
      0.014556369762801584,
      0.010171281114330456,
      0.006070490575192378,
      0.003151222059303356,
      0.002218683290960424,
      0.0012272388773063646,
      0.0009224620115103715,
      0.0007130665837104681,
      0.0006147427318017414,
      0.0005321257249043464,
      0.0004742171049351063,
      0.0004233729724158639
    ],
    "metrics": {
      "accuracy": 0.9385749385749386,
      "precision": 0.8556701030927835,
      "recall": 0.6974789915966386,
      "f1": 0.7685185185185185
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_15/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 15,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.425339968541155,
      0.06898084889224328,
      0.03467257586802343,
      0.0216616741314209,
      0.01730789584721555,
      0.012631384499722936,
      0.007678964107398807,
      0.0047962380545074615,
      0.003216564384939461,
      0.0022705331413086006,
      0.0016663104245261704,
      0.0012209258882290477,
      0.0010237688144029559,
      0.0007845792593828543,
      0.0006929633507540401
    ],
    "metrics": {
      "accuracy": 0.9656019656019657,
      "precision": 0.6818181818181818,
      "recall": 0.6818181818181818,
      "f1": 0.6818181818181818
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_15/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 16,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7121998060198713,
      0.16559745801534934,
      0.07896251220804255,
      0.07052856099359851,
      0.04958514803311163,
      0.03428733905148317,
      0.02836437401070137,
      0.023916973893480072,
      0.018650915735324174,
      0.015171972037565828,
      0.015617390781645583,
      0.013100171959525472,
      0.0098003501899097,
      0.00842566880019427,
      0.007147447859124468
    ],
    "metrics": {
      "accuracy": 0.9127764127764127,
      "precision": 0.8921568627450981,
      "recall": 0.9660297239915074,
      "f1": 0.9276248725790011
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_16/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 16,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3306369969558755,
      0.062015676980905814,
      0.028273354168272462,
      0.018950297311672987,
      0.010686564119774243,
      0.006319422703813492,
      0.004292033042887354,
      0.0030498752538791096,
      0.002303585624579089,
      0.0018800496570784404,
      0.0015648846444476791,
      0.0012198647525912308,
      0.001139203827415519,
      0.0009393079032725597,
      0.0008391899608712264
    ],
    "metrics": {
      "accuracy": 0.9398034398034398,
      "precision": 0.8804347826086957,
      "recall": 0.680672268907563,
      "f1": 0.7677725118483413
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_16/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 16,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.3365413805044254,
      0.04230019325502837,
      0.027802620427985553,
      0.017845941716192037,
      0.0115677235358698,
      0.006605699146252254,
      0.004280767553900868,
      0.002949259120577765,
      0.0017746439097914971,
      0.0011436581254283074,
      0.0007817286514455464,
      0.0006036347350911112,
      0.0004998898939087803,
      0.000440134800810821,
      0.0003852493652411328
    ],
    "metrics": {
      "accuracy": 0.9692874692874693,
      "precision": 0.7111111111111111,
      "recall": 0.7272727272727273,
      "f1": 0.7191011235955056
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_16/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 17,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8683565556677579,
      0.16416555270692473,
      0.0825431778805278,
      0.06347969721737307,
      0.052108731945616084,
      0.04166187835021294,
      0.03131092311074556,
      0.026370570363607557,
      0.021812999552894317,
      0.017645510968706694,
      0.014990977398337251,
      0.01325645397991601,
      0.011797236715456908,
      0.009962590764460507,
      0.00868993837153984
    ],
    "metrics": {
      "accuracy": 0.9164619164619164,
      "precision": 0.899009900990099,
      "recall": 0.9639065817409767,
      "f1": 0.930327868852459
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_17/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 17,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2859953256507503,
      0.06736053846135263,
      0.03268698060622176,
      0.01640702877390734,
      0.008876784950677319,
      0.005974135095156463,
      0.0037061086418325806,
      0.0029609094267350517,
      0.002039635724638119,
      0.0013912659020659164,
      0.0011615019249751424,
      0.0009624083493570532,
      0.0008027643623859465,
      0.0007018127949643827,
      0.0006128799386305718
    ],
    "metrics": {
      "accuracy": 0.9398034398034398,
      "precision": 0.8804347826086957,
      "recall": 0.680672268907563,
      "f1": 0.7677725118483413
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_17/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 17,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.33128085607978575,
      0.041089512746943,
      0.03434900621383459,
      0.020740519496105655,
      0.012197125636752687,
      0.007304982104881024,
      0.003975456737837679,
      0.0025442756599199498,
      0.0016460112448468491,
      0.0010224138413243954,
      0.0008120464699280491,
      0.0006188337899598443,
      0.0005305383238645737,
      0.0004302988589952064,
      0.0003777124715977611
    ],
    "metrics": {
      "accuracy": 0.9668304668304668,
      "precision": 0.6808510638297872,
      "recall": 0.7272727272727273,
      "f1": 0.7032967032967034
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_17/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 18,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8306522234489186,
      0.19047945366835223,
      0.08339604938368703,
      0.06690826345872772,
      0.05053186195884983,
      0.036353119602465025,
      0.029808263138542727,
      0.026562446012885526,
      0.020317545682883412,
      0.017081531998326373,
      0.01468751709140408,
      0.013445004221171938,
      0.010645234489514956,
      0.009703535550237598,
      0.008675224821884394
    ],
    "metrics": {
      "accuracy": 0.9176904176904177,
      "precision": 0.8992094861660079,
      "recall": 0.9660297239915074,
      "f1": 0.9314227226202662
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_18/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 18,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7691846381005387,
      0.18798395980748522,
      0.09687948734210938,
      0.03564061717860708,
      0.02954940245187542,
      0.01841275965030387,
      0.013035176301079083,
      0.008909546394626235,
      0.007082253279024087,
      0.0055531026804913775,
      0.004428026537173699,
      0.003664475934659549,
      0.003054038386525235,
      0.0025589275019703046,
      0.0022091983879237265
    ],
    "metrics": {
      "accuracy": 0.9398034398034398,
      "precision": 0.8977272727272727,
      "recall": 0.6638655462184874,
      "f1": 0.7632850241545893
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_18/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 18,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.8635125346410609,
      0.1214967546636229,
      0.0522186683024067,
      0.03388247129726273,
      0.025410423887709987,
      0.017063493605595313,
      0.012734618630853144,
      0.008324795523864338,
      0.006174693404444665,
      0.004767715437373352,
      0.003390625282806108,
      0.002577801143743938,
      0.002132219756888298,
      0.0016774226711270199,
      0.0013413560863238434
    ],
    "metrics": {
      "accuracy": 0.9643734643734644,
      "precision": 0.6595744680851063,
      "recall": 0.7045454545454546,
      "f1": 0.6813186813186813
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_18/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 19,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5520738542909802,
      0.1244960833476145,
      0.07590378315139429,
      0.060055765326137656,
      0.04241424676009517,
      0.034071077774969115,
      0.021465188146060587,
      0.016140323196347867,
      0.012686631492527984,
      0.009962532293776607,
      0.008722801851690906,
      0.006624046390468864,
      0.005973084787669084,
      0.004778347745077054,
      0.004164205549690093
    ],
    "metrics": {
      "accuracy": 0.902948402948403,
      "precision": 0.8828125,
      "recall": 0.9596602972399151,
      "f1": 0.9196337741607324
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_19/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 19,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5611163331121979,
      0.11451832010198934,
      0.05036011533193858,
      0.02989966327127719,
      0.021989577919460372,
      0.014228325897223643,
      0.00946461734212701,
      0.006577339999136443,
      0.004828286121024514,
      0.0034135235770987645,
      0.0024706617536032413,
      0.0019161734621185702,
      0.0015366347463419618,
      0.0012303509128240829,
      0.0010554602491960983
    ],
    "metrics": {
      "accuracy": 0.9348894348894349,
      "precision": 0.8586956521739131,
      "recall": 0.6638655462184874,
      "f1": 0.7488151658767772
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_19/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 19,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6682600678251601,
      0.12499591447016335,
      0.04740670823871961,
      0.029191262216604442,
      0.020045558172205644,
      0.013119235184270437,
      0.007470291543250698,
      0.006358995914376978,
      0.004479775879334387,
      0.003161702170094893,
      0.002270714413980289,
      0.001745399949642993,
      0.0013356345778213188,
      0.0010791355612270286,
      0.0008634807808918404
    ],
    "metrics": {
      "accuracy": 0.9692874692874693,
      "precision": 0.7111111111111111,
      "recall": 0.7272727272727273,
      "f1": 0.7191011235955056
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_19/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 20,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.1580989780059578,
      0.20569795204940272,
      0.12179619353951049,
      0.06677325511488015,
      0.04804038964649253,
      0.036265620182250775,
      0.027757582563877416,
      0.0233801889827985,
      0.018954218914434863,
      0.015427138468231818,
      0.012809618091688207,
      0.010945804107455227,
      0.009554484824530746,
      0.008308837347270613,
      0.006960707687913411
    ],
    "metrics": {
      "accuracy": 0.9152334152334153,
      "precision": 0.8972332015810277,
      "recall": 0.9639065817409767,
      "f1": 0.9293756397134084
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_20/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 20,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.20798484146098703,
      0.035865177592878425,
      0.017542266200321115,
      0.014615866657302915,
      0.007481128606261849,
      0.0016731429321686564,
      0.0014794970797065929,
      0.0006945458710345676,
      0.0005780455043667548,
      0.0004138247788927731,
      0.00034993477459994906,
      0.00030977969341062177,
      0.00028357193335071316,
      0.00025417427196048036,
      0.00023256306406160105
    ],
    "metrics": {
      "accuracy": 0.9348894348894349,
      "precision": 0.84375,
      "recall": 0.680672268907563,
      "f1": 0.7534883720930232
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_20/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 20,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.6025633815693263,
      0.10654745369103623,
      0.030761369374112096,
      0.02801055786745046,
      0.016055284614628726,
      0.011078898097569474,
      0.007552639021528791,
      0.005628662858671747,
      0.004591007458189476,
      0.003621974958634701,
      0.0028774037426298827,
      0.002469370377125687,
      0.002090151384477932,
      0.0017319981144093344,
      0.0014751073792464919
    ],
    "metrics": {
      "accuracy": 0.9705159705159705,
      "precision": 0.717391304347826,
      "recall": 0.75,
      "f1": 0.7333333333333333
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_20/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 21,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5663748466156254,
      0.11981699079755158,
      0.060386801399382094,
      0.04345388791452429,
      0.027932655803580574,
      0.019165239632338155,
      0.01441012050650369,
      0.009399782176964227,
      0.00711610590746164,
      0.005365937599076307,
      0.004384459061698122,
      0.0036428085870409263,
      0.003107129311158037,
      0.0026524282864982952,
      0.002302704419452039
    ],
    "metrics": {
      "accuracy": 0.9054054054054054,
      "precision": 0.8924302788844621,
      "recall": 0.9511677282377919,
      "f1": 0.920863309352518
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_21/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 21,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7361717703822139,
      0.12580370814332278,
      0.06730521377760824,
      0.02798116696505738,
      0.019608908861838286,
      0.011827292450768006,
      0.007344629528533719,
      0.0047264303827092334,
      0.0030624316133194664,
      0.0020453375829025235,
      0.001886275163036803,
      0.0014493388464252804,
      0.001126362708242005,
      0.001054377784923791,
      0.0009438320099333046
    ],
    "metrics": {
      "accuracy": 0.9447174447174447,
      "precision": 0.8775510204081632,
      "recall": 0.7226890756302521,
      "f1": 0.7926267281105991
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_21/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 21,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.29195110573490035,
      0.06608201104078727,
      0.02888313516154616,
      0.018511465334361703,
      0.00797886995664954,
      0.004797599268418989,
      0.0019819896072079675,
      0.000795974159804846,
      0.0004863768510241163,
      0.00034938734655783093,
      0.0002867900852242105,
      0.00023871270747334854,
      0.00020848213301424533,
      0.00018832728154622954,
      0.00016960517270893754
    ],
    "metrics": {
      "accuracy": 0.9594594594594594,
      "precision": 0.6122448979591837,
      "recall": 0.6818181818181818,
      "f1": 0.6451612903225806
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_21/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 22,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      1.0983366421132734,
      0.2827548207361744,
      0.13800446490609447,
      0.07997616630814382,
      0.05253664308100854,
      0.032874600177121266,
      0.022542971575852874,
      0.013027731038847648,
      0.009231995322865897,
      0.006212460289529006,
      0.004874832963521628,
      0.004040270532478067,
      0.0036134101409635933,
      0.0030583986833131226,
      0.0025312062705033812
    ],
    "metrics": {
      "accuracy": 0.9176904176904177,
      "precision": 0.9056224899598394,
      "recall": 0.9575371549893843,
      "f1": 0.9308565531475749
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_22/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 22,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.9417042428276234,
      0.11772162813023078,
      0.032518725152962155,
      0.029087263581765308,
      0.014894408790068968,
      0.008802684542776138,
      0.005379945871754799,
      0.0036419151586824885,
      0.0023898194849627397,
      0.0019360774166732612,
      0.0013103028189440096,
      0.0009286688716305786,
      0.0007159843702366819,
      0.0005749083549209365,
      0.0004990052388317039
    ],
    "metrics": {
      "accuracy": 0.9422604422604423,
      "precision": 0.8333333333333334,
      "recall": 0.7563025210084033,
      "f1": 0.7929515418502202
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_22/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 22,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.2703049711531184,
      0.0741288060219738,
      0.03355563620882144,
      0.011649962648339339,
      0.007450441382197834,
      0.002386774829266396,
      0.0003989423095138473,
      0.00021781818144081953,
      0.00011959507886961805,
      9.69470786538334e-05,
      7.27623077151924e-05,
      6.144319156169474e-05,
      5.379741787065245e-05,
      4.8459531037255013e-05,
      4.471816402826091e-05
    ],
    "metrics": {
      "accuracy": 0.9680589680589681,
      "precision": 0.7045454545454546,
      "recall": 0.7045454545454546,
      "f1": 0.7045454545454546
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_22/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 23,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.3501391104261566,
      0.3380133163854134,
      0.2082219791158509,
      0.13479876193011228,
      0.0716977422316326,
      0.042744610998387986,
      0.02340269544935543,
      0.012113129989725342,
      0.006099734627872471,
      0.003743109176707803,
      0.00249212268506536,
      0.0017391533706720306,
      0.0015797454706881853,
      0.0012550558293250487,
      0.0010486652570684126
    ],
    "metrics": {
      "accuracy": 0.9041769041769042,
      "precision": 0.8830409356725146,
      "recall": 0.9617834394904459,
      "f1": 0.9207317073170732
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_23/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 23,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      2.6136110726273065,
      0.38492535912222525,
      0.17946578423743706,
      0.08240667758227616,
      0.04616546530954672,
      0.027014809094417704,
      0.013986703955642487,
      0.007447647706772919,
      0.004116320331071562,
      0.002478458988613752,
      0.0008785673204553174,
      0.0003482042981166184,
      0.0002405016833132201,
      0.00018103202997252262,
      0.0001525286590807807
    ],
    "metrics": {
      "accuracy": 0.952088452088452,
      "precision": 0.8703703703703703,
      "recall": 0.7899159663865546,
      "f1": 0.8281938325991189
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_23/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 23,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.7104691883725611,
      0.2576767770182458,
      0.07515043519801409,
      0.0493913753764918,
      0.020745364329626814,
      0.009131087888952108,
      0.004324004078104214,
      0.0003763780070973528,
      0.0001027065813082012,
      6.696554716667183e-05,
      4.5025798926379226e-05,
      3.213164502993921e-05,
      2.2876843901023456e-05,
      1.9467612421503472e-05,
      1.7237231845873654e-05
    ],
    "metrics": {
      "accuracy": 0.9680589680589681,
      "precision": 0.6956521739130435,
      "recall": 0.7272727272727273,
      "f1": 0.7111111111111111
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_23/nasal.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 24,
    "feature": "voiced",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5756048925369449,
      0.3094878670193281,
      0.16000138927549082,
      0.09726732359487698,
      0.07189661596675177,
      0.05867597832970693,
      0.05110270677451192,
      0.04599932465501945,
      0.04089920315154175,
      0.036781483903677775,
      0.033752809431980516,
      0.031229977388928538,
      0.028639933317869192,
      0.025623711254707034,
      0.023766683506871666
    ],
    "metrics": {
      "accuracy": 0.8918918918918919,
      "precision": 0.8837675350701403,
      "recall": 0.9363057324840764,
      "f1": 0.9092783505154639
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_24/voiced.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 24,
    "feature": "fricative",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5412980427336505,
      0.29458764579463387,
      0.1650801516363538,
      0.09098569787642098,
      0.055789929202653785,
      0.03710594860958396,
      0.027908682173314787,
      0.02307662549127354,
      0.019964620420404658,
      0.01740619371595065,
      0.014949476921490037,
      0.01382728547280908,
      0.01294861661782323,
      0.011106233757041109,
      0.009820816016326568
    ],
    "metrics": {
      "accuracy": 0.9434889434889435,
      "precision": 0.8230088495575221,
      "recall": 0.7815126050420168,
      "f1": 0.8017241379310345
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_24/fricative.pt"
  },
  {
    "model": "WAVLM_LARGE",
    "layer": 24,
    "feature": "nasal",
    "input_dim": 1024,
    "train_samples": 3663,
    "test_samples": 814,
    "architecture": "mlp_1x200",
    "num_hidden_layers": 1,
    "hidden_units": [
      200
    ],
    "total_params": 205201,
    "activation": "relu",
    "hyperparameters": {
      "epochs": 15,
      "batch_size": 512,
      "learning_rate": 0.001
    },
    "loss_history": [
      0.5657308825599083,
      0.28695396197043965,
      0.13168926334856249,
      0.06199453639310466,
      0.03737524879062531,
      0.028215278320140584,
      0.02292124951604592,
      0.019194646825677803,
      0.016613986838999003,
      0.014928702681487842,
      0.013314316632979202,
      0.011939207600175911,
      0.010866279574988272,
      0.009911859476668828,
      0.00894487222327098
    ],
    "metrics": {
      "accuracy": 0.9692874692874693,
      "precision": 0.7209302325581395,
      "recall": 0.7045454545454546,
      "f1": 0.7126436781609196
    },
    "probe_path": "02_OUTPUTS/TIMIT_Outputs/datasets/class_probes/mlp_1x200/probes/WAVLM_LARGE/layer_24/nasal.pt"
  }
]